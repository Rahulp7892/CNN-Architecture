{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMVF5HmIuK58"
      },
      "outputs": [],
      "source": [
        "#Q.1 What is a Convolutional Neural Network (CNN), and why is it used for image processing?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What is a Convolutional Neural Network (CNN)?\n",
        "# A Convolutional Neural Network (CNN) is a type of deep learning algorithm designed to process and analyze data with grid-like structures, such as images. It is a specialized form of a neural network, particularly well-suited for image recognition, classification, and other computer vision tasks.\n",
        "\n",
        "# CNNs are composed of multiple layers that automatically learn to extract features from input data, such as edges, textures, shapes, and more complex patterns, as you move deeper into the network. The architecture typically includes the following types of layers:\n",
        "\n",
        "# Convolutional Layers: These are the core building blocks of a CNN. They apply convolution operations to the input, using filters (kernels) to scan the image for specific features. Convolutional layers help the network learn local patterns such as edges, textures, and shapes.\n",
        "\n",
        "# Activation Layers: After the convolution operation, the results are passed through an activation function (typically ReLU), which introduces non-linearity to the network, allowing it to learn more complex patterns.\n",
        "\n",
        "# Pooling Layers: Pooling layers reduce the spatial dimensions (width and height) of the input, making the computation more efficient and reducing the number of parameters in the network. Common types of pooling are max pooling (taking the maximum value) or average pooling.\n",
        "\n",
        "# Fully Connected (FC) Layers: These layers connect every neuron in one layer to every neuron in the next. At this stage, the network starts to combine the learned features from the earlier layers to make final decisions, such as classifying the image.\n",
        "\n",
        "# Softmax Layer: Typically, the last layer in a CNN for classification tasks, softmax normalizes the outputs to represent probabilities of different classes.\n",
        "\n",
        "# Why is a CNN Used for Image Processing?\n",
        "# CNNs are widely used for image processing due to several key advantages:\n",
        "\n",
        "# Automatic Feature Learning: Unlike traditional image processing techniques, where features must be manually designed (such as edge detectors or filters), CNNs automatically learn the most relevant features from the raw image data during training. This reduces the need for domain-specific feature engineering.\n",
        "\n",
        "# Spatial Hierarchy: CNNs take advantage of the spatial relationships between pixels. The convolutional layers preserve the spatial structure of the image, allowing the network to recognize local patterns (such as edges or textures) in the early layers and more complex patterns in deeper layers.\n",
        "\n",
        "# Parameter Sharing: Convolutional layers use the same filter (or kernel) across the entire image. This reduces the number of parameters compared to fully connected layers, making CNNs computationally efficient and less prone to overfitting.\n",
        "\n",
        "# Translation Invariance: Due to the way convolution operations are performed, CNNs are more robust to small translations, rotations, or distortions in the input image. A feature detected in one part of the image can be recognized in another part, making CNNs effective for tasks like object detection and recognition, where the position of the object in the image might vary.\n",
        "\n",
        "# Efficient at Handling High Dimensionality: Images are high-dimensional data (e.g., 2D pixels for grayscale or 3D for color images), and CNNs are particularly efficient at processing such data, as they reduce the complexity through pooling and convolution.\n",
        "\n",
        "# Applications in Image Processing\n",
        "# CNNs have revolutionized the field of image processing and are used in a wide range of applications, including:\n",
        "\n",
        "# Image Classification: Identifying the class or category of an image (e.g., recognizing whether an image contains a cat, dog, etc.).\n",
        "# Object Detection: Locating and classifying multiple objects within an image (e.g., detecting pedestrians or vehicles in a self-driving car scenario).\n",
        "# Image Segmentation: Dividing an image into different regions or segments based on pixel characteristics (e.g., identifying tumor regions in medical imaging).\n",
        "# Face Recognition: Identifying or verifying individuals based on facial features.\n",
        "# Style Transfer and Image Generation: Creating new images based on the features of existing ones (e.g., generating artwork in the style of famous artists)."
      ],
      "metadata": {
        "id": "qLnsgXYCklj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.2 What are the key components of a CNN architecture?"
      ],
      "metadata": {
        "id": "RmTkAZZhk2Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The architecture of a Convolutional Neural Network (CNN) consists of several key components, each of which plays a specific role in feature extraction, transformation, and final decision-making. Here are the main components that make up a CNN architecture:\n",
        "\n",
        "# 1. Input Layer\n",
        "# The input layer is where the image or raw data is fed into the network. For an image, this is usually a matrix of pixel values. The dimensions of the input image are typically represented as:\n",
        "\n",
        "# Height\n",
        "# ğ»\n",
        "# H\n",
        "# Width\n",
        "# ğ‘Š\n",
        "# W\n",
        "# Depth\n",
        "# ğ·\n",
        "# D (for color images,\n",
        "# ğ·\n",
        "# =\n",
        "# 3\n",
        "# D=3 for RGB channels; for grayscale,\n",
        "# ğ·\n",
        "# =\n",
        "# 1\n",
        "# D=1).\n",
        "# For example, a color image of size 224x224 will have a shape of\n",
        "# 224\n",
        "# Ã—\n",
        "# 224\n",
        "# Ã—\n",
        "# 3\n",
        "# 224Ã—224Ã—3.\n",
        "\n",
        "# 2. Convolutional Layers\n",
        "# The convolutional layers are the core building blocks of a CNN. These layers apply convolutional operations using filters (also called kernels), which slide across the image (or previous layerâ€™s output) to detect local patterns such as edges, textures, and simple shapes.\n",
        "\n",
        "# Filters (Kernels): These are small matrices (e.g.,\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3,\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5) that convolve across the image, detecting features like edges or corners.\n",
        "# Stride: The step size with which the filter moves across the image. A stride of 1 means the filter moves one pixel at a time.\n",
        "# Padding: The addition of extra pixels around the border of the input to ensure that the filter can fully cover the edges of the image. Common padding types are valid padding (no padding) and same padding (zero-padding to maintain the same spatial dimensions).\n",
        "# Output: The output of a convolutional layer is typically a 3D matrix with dimensions\n",
        "# ğ»\n",
        "# â€²\n",
        "# Ã—\n",
        "# ğ‘Š\n",
        "# â€²\n",
        "# Ã—\n",
        "# ğ·\n",
        "# â€²\n",
        "# H\n",
        "# â€²\n",
        "#  Ã—W\n",
        "# â€²\n",
        "#  Ã—D\n",
        "# â€²\n",
        "#  , where\n",
        "# ğ»\n",
        "# â€²\n",
        "# H\n",
        "# â€²\n",
        "#  ,\n",
        "# ğ‘Š\n",
        "# â€²\n",
        "# W\n",
        "# â€²\n",
        "#  , and\n",
        "# ğ·\n",
        "# â€²\n",
        "# D\n",
        "# â€²\n",
        "#   are the height, width, and depth (number of filters used) of the resulting feature maps.\n",
        "\n",
        "# 3. Activation Layers (ReLU)\n",
        "# After the convolution operation, the result is passed through an activation function to introduce non-linearity into the model. The most common activation function used in CNNs is the Rectified Linear Unit (ReLU).\n",
        "\n",
        "# ReLU Function:\n",
        "# ğ‘“\n",
        "# (\n",
        "# ğ‘¥\n",
        "# )\n",
        "# =\n",
        "# max\n",
        "# â¡\n",
        "# (\n",
        "# 0\n",
        "# ,\n",
        "# ğ‘¥\n",
        "# )\n",
        "# f(x)=max(0,x)\n",
        "# ReLU helps the network learn complex patterns by allowing it to model non-linear relationships. It also helps avoid the vanishing gradient problem, allowing gradients to flow more effectively during backpropagation.\n",
        "\n",
        "# 4. Pooling Layers\n",
        "# Pooling layers are used to downsample the spatial dimensions of the input, reducing the computational load and the number of parameters in the model. The two most common types of pooling are:\n",
        "\n",
        "# Max Pooling: Takes the maximum value from each patch of the feature map (e.g.,\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2 region). This helps preserve the most prominent features while reducing the size.\n",
        "# Average Pooling: Takes the average value from each patch.\n",
        "# Pooling helps make the model more invariant to small translations, distortions, and other transformations of the image.\n",
        "\n",
        "# Output: The pooled output will have smaller spatial dimensions (height and width), but it retains the important features detected in the previous layers.\n",
        "\n",
        "# 5. Fully Connected Layers (FC Layers)\n",
        "# After several convolutional and pooling layers, the network typically includes one or more fully connected layers. These layers are similar to the layers in a standard neural network, where each neuron is connected to every neuron in the previous layer.\n",
        "\n",
        "# Flattening: The output from the last convolutional or pooling layer is usually flattened (converted from a multi-dimensional tensor to a 1D vector) before being passed to the fully connected layers.\n",
        "# Dense Connections: Each neuron in a fully connected layer is connected to every neuron in the previous layer. The goal of these layers is to combine the learned features from the convolutional layers to make a final prediction.\n",
        "# 6. Output Layer\n",
        "# The output layer is the final layer in a CNN architecture. It produces the final decision or prediction of the network.\n",
        "\n",
        "# Softmax Activation: In classification tasks, a softmax activation function is typically used at the output layer to produce a probability distribution over the possible classes.\n",
        "# Sigmoid Activation: For binary classification tasks, a sigmoid activation function might be used to output a single probability value between 0 and 1.\n",
        "# The output layerâ€™s dimensions depend on the number of classes in the classification task (e.g., for 10-class classification, the output would have 10 nodes).\n",
        "\n",
        "# 7. Normalization Layers (Optional)\n",
        "# Normalization layers help improve the stability and speed of training. These are sometimes included in CNN architectures:\n",
        "\n",
        "# Batch Normalization: Normalizes the output of each layer to have zero mean and unit variance. This helps mitigate issues related to poor initialization, and it can improve convergence.\n",
        "# Layer Normalization: Similar to batch normalization, but applied to individual data points rather than across a batch.\n",
        "# 8. Dropout (Regularization)\n",
        "# To prevent overfitting, CNNs sometimes use dropout regularization. This involves randomly \"dropping\" (setting to zero) a fraction of the neurons during training to prevent the network from becoming overly reliant on certain neurons.\n",
        "\n",
        "# Summary of CNN Layers in Sequence:\n",
        "# Input Layer â€“ Raw image data.\n",
        "# Convolutional Layer(s) â€“ Apply filters to extract features.\n",
        "# Activation Layer â€“ Apply non-linearity (ReLU).\n",
        "# Pooling Layer(s) â€“ Downsample spatial dimensions (Max Pooling or Average Pooling).\n",
        "# Fully Connected Layer(s) â€“ Connect neurons fully to combine features.\n",
        "# Output Layer â€“ Final prediction or classification.\n",
        "# Example of CNN Layer Stacking:\n",
        "# Input:\n",
        "# 224\n",
        "# Ã—\n",
        "# 224\n",
        "# Ã—\n",
        "# 3\n",
        "# 224Ã—224Ã—3 (image size)\n",
        "# Conv Layer:\n",
        "# 224\n",
        "# Ã—\n",
        "# 224\n",
        "# Ã—\n",
        "# 64\n",
        "# 224Ã—224Ã—64 (64 filters,\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 kernel)\n",
        "# ReLU Activation:\n",
        "# 224\n",
        "# Ã—\n",
        "# 224\n",
        "# Ã—\n",
        "# 64\n",
        "# 224Ã—224Ã—64\n",
        "# Pooling:\n",
        "# 112\n",
        "# Ã—\n",
        "# 112\n",
        "# Ã—\n",
        "# 64\n",
        "# 112Ã—112Ã—64 (Max Pooling with stride 2)\n",
        "# Conv Layer:\n",
        "# 112\n",
        "# Ã—\n",
        "# 112\n",
        "# Ã—\n",
        "# 128\n",
        "# 112Ã—112Ã—128 (128 filters,\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 kernel)\n",
        "# ReLU Activation:\n",
        "# 112\n",
        "# Ã—\n",
        "# 112\n",
        "# Ã—\n",
        "# 128\n",
        "# 112Ã—112Ã—128\n",
        "# Pooling:\n",
        "# 56\n",
        "# Ã—\n",
        "# 56\n",
        "# Ã—\n",
        "# 128\n",
        "# 56Ã—56Ã—128\n",
        "# Flatten:\n",
        "# 1\n",
        "# Ã—\n",
        "# 1\n",
        "# Ã—\n",
        "# (\n",
        "# 56\n",
        "# Ã—\n",
        "# 56\n",
        "# Ã—\n",
        "# 128\n",
        "# )\n",
        "# 1Ã—1Ã—(56Ã—56Ã—128)\n",
        "# Fully Connected Layer:\n",
        "# 4096\n",
        "# 4096\n",
        "# Output Layer: Softmax (e.g., 1000 classes for ImageNet)"
      ],
      "metadata": {
        "id": "erSGLn49k7nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.3 What is the role of the convolutional layer in CNNs?"
      ],
      "metadata": {
        "id": "T8qeUu27lGOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Role of the Convolutional Layer in CNNs\n",
        "# The convolutional layer is the foundational component of a Convolutional Neural Network (CNN). It plays a crucial role in feature extraction, enabling the network to automatically learn important patterns and structures in the input data, particularly images. Here's a detailed breakdown of the convolutional layer's role and how it works:\n",
        "\n",
        "# 1. Feature Extraction\n",
        "# The primary function of the convolutional layer is to extract features from the input data. In the case of images, these features can range from simple patterns like edges, corners, and textures, to more complex patterns like shapes, faces, or even objects, as the network goes deeper.\n",
        "\n",
        "# Filters (Kernels): The convolutional layer uses small matrices called filters (or kernels) to scan the input image. Each filter is designed to detect a specific feature. For example, one filter might detect edges, while another might detect vertical or horizontal lines.\n",
        "\n",
        "# A filter typically has a small size, such as\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3,\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5, or\n",
        "# 7\n",
        "# Ã—\n",
        "# 7\n",
        "# 7Ã—7 pixels.\n",
        "# The filter is convolved (slid) over the image, performing a convolution operation where it computes the dot product between the filter and the region of the image it is currently covering.\n",
        "# 2. Local Receptive Field\n",
        "# The convolution operation enables the network to focus on local regions of the input. This is known as a local receptive field. By focusing on smaller parts of the image (or feature map from the previous layer), the convolutional layer is able to capture local dependencies, like edges and textures, that are crucial for higher-level pattern recognition.\n",
        "\n",
        "# In a typical CNN, the receptive field increases as the network deepens (i.e., deeper layers capture increasingly larger regions of the image).\n",
        "# This local focus enables the network to recognize patterns at various levels of abstraction: simple patterns in shallow layers and complex objects in deeper layers.\n",
        "# 3. Feature Map Generation\n",
        "# Each filter produces a feature map. The feature map is a spatial representation of the detected feature across the input image. As the filter slides over the input, it generates an activation (feature) at each position.\n",
        "\n",
        "# Output Size: The size of the feature map depends on several factors, including the size of the input image, the filter size, the stride, and the padding. The stride controls how much the filter moves after each convolution operation, and padding ensures that the filter can cover the edges of the input.\n",
        "# If the filter is smaller than the input image, the convolution operation will reduce the spatial dimensions (height and width) of the output feature map. Padding can be used to preserve the size.\n",
        "# 4. Parameter Sharing\n",
        "# One of the key benefits of convolutional layers is parameter sharing. In traditional fully connected neural networks, each connection between neurons has a unique weight. However, in convolutional layers, the same filter (set of weights) is used across the entire input image.\n",
        "\n",
        "# Efficiency: Instead of learning a different weight for every pixel in the image, the network learns a set of filters (kernels) that can be applied to different parts of the image.\n",
        "# Reduced Parameters: This significantly reduces the number of parameters and computational complexity, making CNNs highly efficient and scalable, even for large images.\n",
        "# Translation Invariance: This parameter-sharing property helps the network become more invariant to the position of features in the image. For example, a feature like a \"nose\" detected in one part of the image can also be detected elsewhere, regardless of the position.\n",
        "# 5. Learning Hierarchical Features\n",
        "# As the convolutional layers stack deeper in the network, the features they detect become increasingly abstract. In the early layers, the network might detect low-level features like edges, textures, and colors. In the middle layers, the network might learn more intermediate features like shapes, corners, or object parts. In the deeper layers, the network can learn high-level features like entire objects or faces.\n",
        "\n",
        "# Shallow Layers: Detect simple features like edges, corners, and gradients.\n",
        "# Deep Layers: Detect complex patterns like textures, objects, or even faces.\n",
        "# This ability to learn hierarchical features is one of the key reasons CNNs are so powerful for image processing tasks.\n",
        "\n",
        "# 6. Non-Linearity via Activation Functions\n",
        "# After the convolution operation, the output is passed through an activation function, usually ReLU (Rectified Linear Unit), to introduce non-linearity into the network. This non-linearity is essential for the network to model complex patterns and relationships in the data.\n",
        "\n",
        "# Without activation functions, the network would behave like a linear model, which is not capable of solving complex tasks.\n",
        "# ReLU helps in making the CNN capable of learning non-linear decision boundaries, enabling it to detect more complex patterns.\n",
        "# 7. Stride and Padding\n",
        "# Stride: The stride defines the step size by which the filter moves as it slides over the image. A larger stride reduces the size of the output feature map, while a smaller stride increases the output size.\n",
        "\n",
        "# Stride 1 means the filter moves one pixel at a time, resulting in a larger output feature map.\n",
        "# Stride 2 means the filter moves two pixels at a time, resulting in a smaller output feature map.\n",
        "# Padding: Padding is the process of adding extra pixels (usually zeros) around the border of the input image to ensure that the filter can process the edges of the image. There are two types of padding:\n",
        "\n",
        "# Valid Padding: No padding is added, and the filter is applied only to valid parts of the image.\n",
        "# Same Padding: Padding is added so that the output feature map has the same dimensions as the input (height and width).\n",
        "# Summary of the Convolutional Layer's Role:\n",
        "# Extracts Local Features: By using filters that convolve over the input image, the convolutional layer extracts local patterns (edges, textures, etc.) from different regions of the image.\n",
        "# Learns Hierarchical Features: The network learns features at different levels of abstraction, from simple patterns in early layers to complex objects in deeper layers.\n",
        "# Parameter Sharing: Using the same filter across the image reduces the number of parameters, making CNNs more efficient and robust.\n",
        "# Translation Invariance: The use of parameter sharing allows the network to detect features regardless of their position in the image.\n",
        "# Efficient Computation: The convolution operation reduces the number of computations compared to fully connected layers, making CNNs suitable for large-scale image data."
      ],
      "metadata": {
        "id": "Ch0_HX5VlNts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.4 What is a filter (kernel) in CNNs?"
      ],
      "metadata": {
        "id": "BsnK3zNklXqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In Convolutional Neural Networks (CNNs), a filter (also called a kernel) is a small matrix or array of numbers that is used to extract features from an input image or feature map. Filters are a fundamental part of the convolution operation in CNNs and are key to the network's ability to learn spatial hierarchies of features.\n",
        "\n",
        "# Key Characteristics of a Filter (Kernel):\n",
        "# Size:\n",
        "# Filters are typically small in spatial dimensions (e.g.,\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3,\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5, or\n",
        "# 7\n",
        "# Ã—\n",
        "# 7\n",
        "# 7Ã—7) but span the entire depth of the input (e.g., if the input has three channels, the filter will have a depth of 3).\n",
        "\n",
        "# Weights:\n",
        "# The numbers in the filter matrix represent learnable parameters that are optimized during training. These weights determine what features (like edges, textures, or patterns) the filter detects.\n",
        "\n",
        "# Sliding Window Operation:\n",
        "# The filter slides over the input image or feature map, computing a dot product between the filter weights and the corresponding region of the input.\n",
        "\n",
        "# Feature Detection:\n",
        "# Filters detect specific patterns in the input. For example:\n",
        "\n",
        "# A filter may detect vertical edges.\n",
        "# Another filter may detect diagonal edges or specific textures.\n",
        "# Deeper layers may use filters to detect more complex features like shapes or objects.\n",
        "# Multiple Filters:\n",
        "# Each layer of a CNN typically uses multiple filters, each detecting a different feature. The outputs of these filters form the feature maps of that layer.\n",
        "\n",
        "# Mathematical Representation:\n",
        "# If the input is\n",
        "# ğ¼\n",
        "# I and the filter is\n",
        "# ğ¾\n",
        "# K, the convolution operation can be expressed as:\n",
        "\n",
        "# ğ‘‚\n",
        "# (\n",
        "# ğ‘–\n",
        "# ,\n",
        "# ğ‘—\n",
        "# )\n",
        "# =\n",
        "# âˆ‘\n",
        "# ğ‘š\n",
        "# âˆ‘\n",
        "# ğ‘›\n",
        "# ğ¼\n",
        "# (\n",
        "# ğ‘–\n",
        "# +\n",
        "# ğ‘š\n",
        "# ,\n",
        "# ğ‘—\n",
        "# +\n",
        "# ğ‘›\n",
        "# )\n",
        "# â‹…\n",
        "# ğ¾\n",
        "# (\n",
        "# ğ‘š\n",
        "# ,\n",
        "# ğ‘›\n",
        "# )\n",
        "# O(i,j)=\n",
        "# m\n",
        "# âˆ‘\n",
        "# â€‹\n",
        "\n",
        "# n\n",
        "# âˆ‘\n",
        "# â€‹\n",
        "#  I(i+m,j+n)â‹…K(m,n)\n",
        "# where\n",
        "# ğ‘‚\n",
        "# (\n",
        "# ğ‘–\n",
        "# ,\n",
        "# ğ‘—\n",
        "# )\n",
        "# O(i,j) is the output feature map, and\n",
        "# ğ‘š\n",
        "# ,\n",
        "# ğ‘›\n",
        "# m,n are indices over the filter dimensions.\n",
        "\n",
        "# Example:\n",
        "# For a\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 filter applied to an image, the filter might look like this:\n",
        "\n",
        "# ğ¾\n",
        "# =\n",
        "# [\n",
        "# 1\n",
        "# 0\n",
        "# âˆ’\n",
        "# 1\n",
        "# 1\n",
        "# 0\n",
        "# âˆ’\n",
        "# 1\n",
        "# 1\n",
        "# 0\n",
        "# âˆ’\n",
        "# 1\n",
        "# ]\n",
        "# K=\n",
        "# â€‹\n",
        "\n",
        "# 1\n",
        "# 1\n",
        "# 1\n",
        "# â€‹\n",
        "\n",
        "# 0\n",
        "# 0\n",
        "# 0\n",
        "# â€‹\n",
        "\n",
        "# âˆ’1\n",
        "# âˆ’1\n",
        "# âˆ’1\n",
        "# â€‹\n",
        "\n",
        "# â€‹\n",
        "\n",
        "# This filter is designed to detect vertical edges.\n",
        "\n",
        "# Importance in CNNs:\n",
        "# Filters allow CNNs to:\n",
        "\n",
        "# Learn hierarchical spatial features, from simple patterns in early layers to complex object parts in deeper layers.\n",
        "# Achieve translation invariance, as the same filter is applied across the entire input.\n",
        "# Reduce computational complexity compared to fully connected layers, by focusing on local regions of the input."
      ],
      "metadata": {
        "id": "Myq1NH07lhDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.5 What is pooling in CNNs, and why is it important?"
      ],
      "metadata": {
        "id": "OIrJFfIylxoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pooling in Convolutional Neural Networks (CNNs) is a downsampling operation used to reduce the spatial dimensions (height and width) of feature maps while retaining the most important features. It is typically applied after convolutional layers to condense the information and make the network more efficient and robust.\n",
        "\n",
        "# Types of Pooling:\n",
        "# Max Pooling:\n",
        "\n",
        "# Takes the maximum value in each region (e.g., a\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2 window).\n",
        "# Focuses on the strongest activations (e.g., edge or feature presence).\n",
        "# Example:\n",
        "# Input:\n",
        "# [\n",
        "# 1\n",
        "# 3\n",
        "# 2\n",
        "# 4\n",
        "# ]\n",
        "# â†’\n",
        "# Max:\n",
        "# 4\n",
        "# Input:Â [\n",
        "# 1\n",
        "# 2\n",
        "# â€‹\n",
        "\n",
        "# 3\n",
        "# 4\n",
        "# â€‹\n",
        "#  ]â†’Max:Â 4\n",
        "# Average Pooling:\n",
        "\n",
        "# Takes the average of all values in each region.\n",
        "# Retains spatial smoothing and overall feature intensity.\n",
        "# Example:\n",
        "# Input:\n",
        "# [\n",
        "# 1\n",
        "# 3\n",
        "# 2\n",
        "# 4\n",
        "# ]\n",
        "# â†’\n",
        "# Average:\n",
        "# 2.5\n",
        "# Input:Â [\n",
        "# 1\n",
        "# 2\n",
        "# â€‹\n",
        "\n",
        "# 3\n",
        "# 4\n",
        "# â€‹\n",
        "#  ]â†’Average:Â 2.5\n",
        "# Global Pooling:\n",
        "\n",
        "# Reduces each feature map to a single value by applying max or average pooling across the entire feature map.\n",
        "# Commonly used before fully connected layers in classification tasks.\n",
        "# Why Pooling is Important:\n",
        "# Reduces Dimensionality:\n",
        "\n",
        "# Pooling reduces the size of feature maps, lowering the computational cost and memory usage in subsequent layers.\n",
        "# Controls Overfitting:\n",
        "\n",
        "# By reducing the number of parameters, pooling minimizes the risk of overfitting.\n",
        "# Improves Translation Invariance:\n",
        "\n",
        "# Pooling focuses on the presence of features rather than their exact locations, making the model robust to small translations or distortions in the input.\n",
        "# Enhances Feature Hierarchies:\n",
        "\n",
        "# By gradually reducing spatial dimensions, pooling allows CNNs to capture hierarchical features (e.g., edges, shapes, objects) effectively.\n",
        "# Example of Pooling in Action:\n",
        "# Consider a\n",
        "# 4\n",
        "# Ã—\n",
        "# 4\n",
        "# 4Ã—4 feature map:\n",
        "\n",
        "# [\n",
        "# 1\n",
        "# 3\n",
        "# 2\n",
        "# 4\n",
        "# 5\n",
        "# 6\n",
        "# 8\n",
        "# 7\n",
        "# 9\n",
        "# 2\n",
        "# 0\n",
        "# 3\n",
        "# 4\n",
        "# 6\n",
        "# 5\n",
        "# 1\n",
        "# ]\n",
        "# â€‹\n",
        "\n",
        "# 1\n",
        "# 5\n",
        "# 9\n",
        "# 4\n",
        "# â€‹\n",
        "\n",
        "# 3\n",
        "# 6\n",
        "# 2\n",
        "# 6\n",
        "# â€‹\n",
        "\n",
        "# 2\n",
        "# 8\n",
        "# 0\n",
        "# 5\n",
        "# â€‹\n",
        "\n",
        "# 4\n",
        "# 7\n",
        "# 3\n",
        "# 1\n",
        "# â€‹\n",
        "\n",
        "# â€‹\n",
        "\n",
        "# Using\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2 Max Pooling with a stride of 2:\n",
        "\n",
        "# Divide the feature map into\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2 regions.\n",
        "# Take the maximum value in each region.\n",
        "# Result:\n",
        "\n",
        "# [\n",
        "# 6\n",
        "# 8\n",
        "# 9\n",
        "# 6\n",
        "# ]\n",
        "# [\n",
        "# 6\n",
        "# 9\n",
        "# â€‹\n",
        "\n",
        "# 8\n",
        "# 6\n",
        "# â€‹\n",
        "#  ]\n",
        "# Practical Implications:\n",
        "# Pooling layers help CNNs generalize better by distilling the essence of detected features.\n",
        "# They are often combined with convolutional layers in modern architectures, contributing to both efficiency and accuracy."
      ],
      "metadata": {
        "id": "RaBwOWTUl5dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.6 What are the common types of pooling used in CNNs?"
      ],
      "metadata": {
        "id": "AThIjb3fmEqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Max Pooling\n",
        "# Definition: Takes the maximum value from each patch of the feature map.\n",
        "# Purpose: Captures the most prominent feature (highest activation) in each region.\n",
        "# Advantages:\n",
        "# Effective for feature detection.\n",
        "# Reduces noise by focusing on the strongest signals.\n",
        "# Example: For a\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2 region:\n",
        "# Input:\n",
        "# [\n",
        "# 1\n",
        "# 3\n",
        "# 2\n",
        "# 4\n",
        "# ]\n",
        "# â†’\n",
        "# Max:\n",
        "# 4\n",
        "# Input:Â [\n",
        "# 1\n",
        "# 2\n",
        "# â€‹\n",
        "\n",
        "# 3\n",
        "# 4\n",
        "# â€‹\n",
        "#  ]â†’Max:Â 4\n",
        "# 2. Average Pooling\n",
        "# Definition: Computes the average of all values in each patch of the feature map.\n",
        "# Purpose: Retains the overall intensity of features by smoothing the information.\n",
        "# Advantages:\n",
        "# Useful when the emphasis is on preserving feature averages rather than peak values.\n",
        "# Reduces spatial variance in feature maps.\n",
        "# Example: For a\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2 region:\n",
        "# Input:\n",
        "# [\n",
        "# 1\n",
        "# 3\n",
        "# 2\n",
        "# 4\n",
        "# ]\n",
        "# â†’\n",
        "# Average:\n",
        "# 2.5\n",
        "# Input:Â [\n",
        "# 1\n",
        "# 2\n",
        "# â€‹\n",
        "\n",
        "# 3\n",
        "# 4\n",
        "# â€‹\n",
        "#  ]â†’Average:Â 2.5\n",
        "# 3. Global Pooling\n",
        "# Definition: Applies pooling over the entire feature map, reducing each feature map to a single value.\n",
        "# Purpose: Often used before the fully connected layer in classification networks.\n",
        "# Types:\n",
        "# Global Max Pooling: Takes the maximum value of the entire feature map.\n",
        "# Global Average Pooling: Takes the average of the entire feature map.\n",
        "# Advantages:\n",
        "# Reduces spatial dimensions to a single value per feature map.\n",
        "# Helps prevent overfitting by reducing parameters.\n",
        "# Example: A\n",
        "# 4\n",
        "# Ã—\n",
        "# 4\n",
        "# 4Ã—4 feature map becomes a single value using Global Average Pooling.\n",
        "# 4. Mixed Pooling (Stochastic Pooling)\n",
        "# Definition: Combines max and average pooling, or uses a probabilistic approach to select pooling values.\n",
        "# Purpose: Introduces randomness or balance to pooling for better generalization.\n",
        "# Advantages:\n",
        "# Combines the strengths of max and average pooling.\n",
        "# Reduces overfitting further with stochastic sampling.\n",
        "# 5. L2 Pooling\n",
        "# Definition: Computes the root mean square of values in each patch:\n",
        "# ğ¿\n",
        "# 2\n",
        "# =\n",
        "# 1\n",
        "# ğ‘\n",
        "# âˆ‘\n",
        "# ğ‘¥\n",
        "# ğ‘–\n",
        "# 2\n",
        "# L2=\n",
        "# N\n",
        "# 1\n",
        "# â€‹\n",
        "#  âˆ‘x\n",
        "# i\n",
        "# 2\n",
        "# â€‹\n",
        "\n",
        "# â€‹\n",
        "\n",
        "# Purpose: Retains information about the energy or magnitude of features.\n",
        "# Advantages:\n",
        "# Useful when feature energy is more important than exact values.\n",
        "# Summary Table:\n",
        "# Pooling Type\tOperation\tUse Case\n",
        "# Max Pooling\tMaximum value\tDetects prominent features\n",
        "# Average Pooling\tAverage value\tSmoothing and feature intensity\n",
        "# Global Pooling\tSingle max or average\tTransition to classification\n",
        "# Mixed Pooling\tCombined or stochastic\tReduces overfitting\n",
        "# L2 Pooling\tRoot mean square\tFeature energy or magnitude\n",
        "# Practical Considerations:\n",
        "# Max Pooling is the most common and effective for most applications, especially in object detection and recognition.\n",
        "# Average Pooling is less commonly used in modern architectures but still relevant in tasks requiring smooth feature representations.\n",
        "# Global Pooling is widely used in architectures like ResNet and Inception before classification layers."
      ],
      "metadata": {
        "id": "9N1OGKiWnSDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.7 How does the backpropagation algorithm work in CNNs?"
      ],
      "metadata": {
        "id": "F5OZ3V0_ndPh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The backpropagation algorithm in Convolutional Neural Networks (CNNs) is an extension of the backpropagation process used in standard neural networks. It is employed to update the weights and biases of the network to minimize the error during training. Below is a step-by-step explanation of how it works in the context of CNNs:\n",
        "\n",
        "# 1. Forward Propagation\n",
        "# The input data is passed through the network, layer by layer.\n",
        "# Each layer performs its computations (e.g., convolution, activation, pooling).\n",
        "# The final output is compared with the ground truth to compute the loss using a loss function (e.g., cross-entropy or mean squared error).\n",
        "# 2. Loss Computation\n",
        "# The loss function quantifies the difference between the predicted output and the actual target.\n",
        "# This loss is the value that needs to be minimized during training.\n",
        "# 3. Backward Propagation (Gradient Computation)\n",
        "# The goal of backpropagation is to compute the gradients of the loss function with respect to the trainable parameters (weights and biases) of the network.\n",
        "\n",
        "# a) Compute Gradients for the Output Layer\n",
        "# The gradient of the loss with respect to the output of the last layer is computed first.\n",
        "# For classification tasks, this often involves computing the derivative of the loss function with respect to the softmax or sigmoid activation outputs.\n",
        "# b) Propagate Gradients Backward Through Layers\n",
        "# Gradients are propagated from the output layer to earlier layers using the chain rule of calculus.\n",
        "# Each type of layer (e.g., fully connected, convolutional, pooling) has specific operations for gradient computation:\n",
        "# Convolutional Layers: Gradients with respect to the filter weights and input feature maps are computed.\n",
        "# Pooling Layers: Only the gradients with respect to the input feature maps are computed (since pooling has no trainable parameters).\n",
        "# Activation Functions: Gradients are adjusted based on the derivative of the activation function (e.g., ReLU, sigmoid).\n",
        "# 4. Weight and Bias Updates\n",
        "# After computing the gradients, weights and biases are updated using an optimization algorithm like Stochastic Gradient Descent (SGD), Adam, or RMSProp.\n",
        "# The update rule typically looks like this:\n",
        "# ğ‘¤\n",
        "# (\n",
        "# ğ‘¡\n",
        "# +\n",
        "# 1\n",
        "# )\n",
        "# =\n",
        "# ğ‘¤\n",
        "# (\n",
        "# ğ‘¡\n",
        "# )\n",
        "# âˆ’\n",
        "# ğœ‚\n",
        "# â‹…\n",
        "# âˆ‚\n",
        "# ğ¿\n",
        "# âˆ‚\n",
        "# ğ‘¤\n",
        "# w\n",
        "# (t+1)\n",
        "#  =w\n",
        "# (t)\n",
        "#  âˆ’Î·â‹…\n",
        "# âˆ‚w\n",
        "# âˆ‚L\n",
        "# â€‹\n",
        "\n",
        "# where:\n",
        "# ğ‘¤\n",
        "# w: weight parameter,\n",
        "# ğœ‚\n",
        "# Î·: learning rate,\n",
        "# âˆ‚\n",
        "# ğ¿\n",
        "# âˆ‚\n",
        "# ğ‘¤\n",
        "# âˆ‚w\n",
        "# âˆ‚L\n",
        "# â€‹\n",
        "#  : gradient of the loss with respect to\n",
        "# ğ‘¤\n",
        "# w.\n",
        "# 5. Iteration Until Convergence\n",
        "# Forward and backward passes are repeated for all training examples in mini-batches or epochs.\n",
        "# The training continues until the loss converges to a sufficiently low value or another stopping criterion is met.\n",
        "# Key Considerations in CNNs\n",
        "# Weight Sharing: In convolutional layers, filters are shared across spatial dimensions, reducing the number of parameters and making gradient computation more efficient.\n",
        "# Sparsity of Connections: Convolutional layers connect only local regions of the input, resulting in sparse gradients.\n",
        "# Pooling Layers: These typically do not have trainable parameters, but gradients are propagated to adjust upstream layers."
      ],
      "metadata": {
        "id": "kXVMdBe5Zh30"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.8 What is the role of activation functions in CNNs?"
      ],
      "metadata": {
        "id": "oeoEPLMvZ1VJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Activation functions play a critical role in Convolutional Neural Networks (CNNs) by introducing non-linearity into the network. This non-linearity allows CNNs to learn and model complex patterns in the data. Without activation functions, the network would behave like a linear model, regardless of its depth, severely limiting its representational power. Hereâ€™s an explanation of their roles in detail:\n",
        "\n",
        "# 1. Introducing Non-linearity\n",
        "# CNNs consist of linear operations like convolutions and matrix multiplications.\n",
        "# Activation functions apply a non-linear transformation to the outputs of these operations, enabling the network to learn non-linear mappings.\n",
        "# This is essential for tasks like image recognition or object detection, where the relationships between inputs and outputs are inherently non-linear.\n",
        "# 2. Enabling Deep Learning\n",
        "# Non-linear activation functions allow multiple layers in a CNN to build upon each other, learning hierarchical feature representations.\n",
        "# For example:\n",
        "# Early layers may detect simple features like edges or textures.\n",
        "# Deeper layers may combine these to detect complex patterns like shapes or objects.\n",
        "# 3. Enhancing Feature Discrimination\n",
        "# Activation functions help amplify relevant features and suppress irrelevant ones.\n",
        "# This enhances the networkâ€™s ability to discriminate between different classes or patterns in the data.\n",
        "# 4. Controlling Signal Flow\n",
        "# Activation functions control how much information is passed from one layer to the next.\n",
        "# Functions like ReLU (Rectified Linear Unit) allow only positive values to pass through, introducing sparsity and making the network computationally efficient.\n",
        "# 5. Preventing Gradient Vanishing\n",
        "# Some activation functions are designed to mitigate the vanishing gradient problem, which can hinder training in deep networks.\n",
        "# For example:\n",
        "# ReLU avoids vanishing gradients by maintaining a constant gradient for positive inputs.\n",
        "# Variants like Leaky ReLU and ELU address issues where ReLU outputs zeros for all negative inputs.\n",
        "# Common Activation Functions in CNNs\n",
        "# ReLU (Rectified Linear Unit):\n",
        "\n",
        "# Formula:\n",
        "# ğ‘“\n",
        "# (\n",
        "# ğ‘¥\n",
        "# )\n",
        "# =\n",
        "# max\n",
        "# â¡\n",
        "# (\n",
        "# 0\n",
        "# ,\n",
        "# ğ‘¥\n",
        "# )\n",
        "# f(x)=max(0,x)\n",
        "# Characteristics: Simple, computationally efficient, introduces sparsity.\n",
        "# Role: Commonly used in CNNs due to its effectiveness and ease of use.\n",
        "# Sigmoid:\n",
        "\n",
        "# Formula:\n",
        "# ğ‘“\n",
        "# (\n",
        "# ğ‘¥\n",
        "# )\n",
        "# =\n",
        "# 1\n",
        "# 1\n",
        "# +\n",
        "# ğ‘’\n",
        "# âˆ’\n",
        "# ğ‘¥\n",
        "# f(x)=\n",
        "# 1+e\n",
        "# âˆ’x\n",
        "\n",
        "# 1\n",
        "# â€‹\n",
        "\n",
        "# Characteristics: Outputs values between 0 and 1.\n",
        "# Role: Used in the output layer for binary classification.\n",
        "# Tanh (Hyperbolic Tangent):\n",
        "\n",
        "# Formula:\n",
        "# ğ‘“\n",
        "# (\n",
        "# ğ‘¥\n",
        "# )\n",
        "# =\n",
        "# tanh\n",
        "# â¡\n",
        "# (\n",
        "# ğ‘¥\n",
        "# )\n",
        "# =\n",
        "# ğ‘’\n",
        "# ğ‘¥\n",
        "# âˆ’\n",
        "# ğ‘’\n",
        "# âˆ’\n",
        "# ğ‘¥\n",
        "# ğ‘’\n",
        "# ğ‘¥\n",
        "# +\n",
        "# ğ‘’\n",
        "# âˆ’\n",
        "# ğ‘¥\n",
        "# f(x)=tanh(x)=\n",
        "# e\n",
        "# x\n",
        "#  +e\n",
        "# âˆ’x\n",
        "\n",
        "# e\n",
        "# x\n",
        "#  âˆ’e\n",
        "# âˆ’x\n",
        "\n",
        "# â€‹\n",
        "\n",
        "# Characteristics: Outputs values between -1 and 1, centered around zero.\n",
        "# Role: Occasionally used in hidden layers, though less common in modern CNNs.\n",
        "# Softmax:\n",
        "\n",
        "# Formula:\n",
        "# ğ‘“\n",
        "# (\n",
        "# ğ‘¥\n",
        "# ğ‘–\n",
        "# )\n",
        "# =\n",
        "# ğ‘’\n",
        "# ğ‘¥\n",
        "# ğ‘–\n",
        "# âˆ‘\n",
        "# ğ‘—\n",
        "# ğ‘’\n",
        "# ğ‘¥\n",
        "# ğ‘—\n",
        "# f(x\n",
        "# i\n",
        "# â€‹\n",
        "#  )=\n",
        "# âˆ‘\n",
        "# j\n",
        "# â€‹\n",
        "#  e\n",
        "# x\n",
        "# j\n",
        "# â€‹\n",
        "\n",
        "\n",
        "# e\n",
        "# x\n",
        "# i\n",
        "# â€‹\n",
        "\n",
        "\n",
        "# â€‹\n",
        "\n",
        "# Characteristics: Converts logits into probabilities summing to 1.\n",
        "# Role: Used in the output layer for multi-class classification.\n",
        "# Leaky ReLU:\n",
        "\n",
        "# Formula:\n",
        "# ğ‘“\n",
        "# (\n",
        "# ğ‘¥\n",
        "# )\n",
        "# =\n",
        "# ğ‘¥\n",
        "# f(x)=x if\n",
        "# ğ‘¥\n",
        "# >\n",
        "# 0\n",
        "# x>0,\n",
        "# ğ›¼\n",
        "# ğ‘¥\n",
        "# Î±x if\n",
        "# ğ‘¥\n",
        "# â‰¤\n",
        "# 0\n",
        "# xâ‰¤0, where\n",
        "# ğ›¼\n",
        "# Î± is a small constant.\n",
        "# Role: Addresses the \"dying ReLU\" problem by allowing small gradients for negative inputs.\n",
        "# ELU (Exponential Linear Unit):\n",
        "\n",
        "# Formula:\n",
        "# ğ‘“\n",
        "# (\n",
        "# ğ‘¥\n",
        "# )\n",
        "# =\n",
        "# ğ‘¥\n",
        "# f(x)=x if\n",
        "# ğ‘¥\n",
        "# >\n",
        "# 0\n",
        "# x>0,\n",
        "# ğ›¼\n",
        "# (\n",
        "# ğ‘’\n",
        "# ğ‘¥\n",
        "# âˆ’\n",
        "# 1\n",
        "# )\n",
        "# Î±(e\n",
        "# x\n",
        "#  âˆ’1) if\n",
        "# ğ‘¥\n",
        "# â‰¤\n",
        "# 0\n",
        "# xâ‰¤0.\n",
        "# Role: Provides smoother gradients compared to ReLU.\n",
        "# 6. Computational Efficiency\n",
        "# Efficient activation functions, like ReLU, contribute to faster training and inference times, making them ideal for large-scale datasets and real-time applications."
      ],
      "metadata": {
        "id": "JWC3YWx8Z7BA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.9 What is the concept of receptive fields in CNNs?"
      ],
      "metadata": {
        "id": "8Vx9gb-IaPuI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The receptive field in Convolutional Neural Networks (CNNs) refers to the region of the input image that a particular feature in a feature map is influenced by. It is a fundamental concept that helps explain how CNNs process and understand spatial hierarchies in data.\n",
        "\n",
        "# Hereâ€™s a detailed explanation:\n",
        "\n",
        "# 1. Definition\n",
        "# The receptive field of a neuron (or feature) in a CNN layer is the area of the input image that the neuron is \"looking at\" or is influenced by.\n",
        "# As data propagates through successive layers of the CNN, the receptive field grows, encompassing larger portions of the input image.\n",
        "# 2. Key Characteristics\n",
        "# Local Receptive Field: In early layers, the receptive field is small and corresponds to local regions of the input. This helps detect fine details like edges or textures.\n",
        "# Global Receptive Field: In deeper layers, the receptive field becomes larger as it aggregates information from broader regions. This enables the detection of complex patterns like shapes or objects.\n",
        "# 3. Factors Influencing Receptive Field\n",
        "# Several factors determine the size of the receptive field:\n",
        "\n",
        "# Filter Size (Kernel Size):\n",
        "\n",
        "# Larger kernels increase the receptive field of a neuron.\n",
        "# For example, a\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 kernel has a smaller receptive field compared to a\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5 kernel.\n",
        "# Stride:\n",
        "\n",
        "# Stride determines the step size of the kernel during convolution.\n",
        "# A larger stride increases the spacing between receptive fields of adjacent neurons, indirectly affecting the perceived receptive field.\n",
        "# Pooling Layers:\n",
        "\n",
        "# Pooling layers (e.g., max pooling or average pooling) reduce spatial dimensions while increasing the receptive field by summarizing information over a region.\n",
        "# Number of Layers:\n",
        "\n",
        "# The receptive field grows as more convolutional or pooling layers are stacked.\n",
        "# For instance, applying a\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 kernel in two consecutive layers results in a larger effective receptive field than a single\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5 kernel.\n",
        "# 4. Calculation of Receptive Field\n",
        "# To compute the receptive field for a specific layer, you can use the following formula recursively:\n",
        "\n",
        "# ğ‘…\n",
        "# ğ‘™\n",
        "# =\n",
        "# ğ‘…\n",
        "# ğ‘™\n",
        "# âˆ’\n",
        "# 1\n",
        "# +\n",
        "# (\n",
        "# ğ¾\n",
        "# ğ‘™\n",
        "# âˆ’\n",
        "# 1\n",
        "# )\n",
        "# â‹…\n",
        "# ğ‘†\n",
        "# ğ‘™\n",
        "# R\n",
        "# l\n",
        "# â€‹\n",
        "#  =R\n",
        "# lâˆ’1\n",
        "# â€‹\n",
        "#  +(K\n",
        "# l\n",
        "# â€‹\n",
        "#  âˆ’1)â‹…S\n",
        "# l\n",
        "# â€‹\n",
        "\n",
        "# Where:\n",
        "\n",
        "# ğ‘…\n",
        "# ğ‘™\n",
        "# R\n",
        "# l\n",
        "# â€‹\n",
        "#  : Receptive field of the current layer.\n",
        "# ğ‘…\n",
        "# ğ‘™\n",
        "# âˆ’\n",
        "# 1\n",
        "# R\n",
        "# lâˆ’1\n",
        "# â€‹\n",
        "#  : Receptive field of the previous layer.\n",
        "# ğ¾\n",
        "# ğ‘™\n",
        "# K\n",
        "# l\n",
        "# â€‹\n",
        "#  : Kernel size of the current layer.\n",
        "# ğ‘†\n",
        "# ğ‘™\n",
        "# S\n",
        "# l\n",
        "# â€‹\n",
        "#  : Stride of the current layer.\n",
        "# For example:\n",
        "\n",
        "# If the input image has a size of\n",
        "# 32\n",
        "# Ã—\n",
        "# 32\n",
        "# 32Ã—32, and a\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 kernel with stride 1 is applied, the receptive field at the first layer is\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3.\n",
        "# If a second\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 kernel is applied with stride 1, the receptive field of the second layer is\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5.\n",
        "# 5. Importance of Receptive Fields\n",
        "# Feature Extraction:\n",
        "\n",
        "# Smaller receptive fields in initial layers focus on simple, local features like edges or corners.\n",
        "# Larger receptive fields in deeper layers capture global patterns and context.\n",
        "# Hierarchical Understanding:\n",
        "\n",
        "# Receptive fields enable CNNs to build a hierarchy of features, starting from low-level features (textures) to high-level concepts (objects).\n",
        "# Designing CNN Architectures:\n",
        "\n",
        "# Understanding receptive fields helps in choosing appropriate kernel sizes, strides, and network depth to capture the desired spatial information.\n",
        "# For tasks requiring global context (e.g., object detection), larger receptive fields are essential.\n",
        "# Trade-offs:\n",
        "\n",
        "# Very large receptive fields may lose fine details.\n",
        "# Too small receptive fields may miss global patterns.\n",
        "# 6. Visual Intuition\n",
        "# Imagine an image of a face:\n",
        "\n",
        "# A neuron in the first layer might \"see\" only a small patch of the image, detecting edges or textures.\n",
        "# A neuron in a deeper layer might \"see\" an eye or nose by combining features from the previous layers.\n",
        "# A neuron in the final layers might \"see\" the entire face by aggregating information from all preceding layers."
      ],
      "metadata": {
        "id": "A5-P4QwTaXAY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.10 Explain the concept of tensor space in CNNs"
      ],
      "metadata": {
        "id": "iy7Ttar4aiWA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The concept of tensor space in Convolutional Neural Networks (CNNs) relates to the multi-dimensional arrays, or tensors, used to represent and manipulate data at different stages of the network. CNNs rely heavily on tensor operations to perform computations, making tensor space a foundational concept. Below is a detailed explanation:\n",
        "\n",
        "# 1. What is a Tensor?\n",
        "# A tensor is a multi-dimensional array that generalizes scalars (0D), vectors (1D), and matrices (2D) to higher dimensions.\n",
        "# In the context of CNNs, tensors are used to represent input data, weights, biases, and outputs at various layers.\n",
        "# 2. Tensor Space in CNNs\n",
        "# Tensor space refers to the mathematical space in which these tensors reside, encompassing their dimensionality, structure, and transformations. Each tensor in a CNN operates within this space to represent different types of data.\n",
        "\n",
        "# 3. Common Types of Tensors in CNNs\n",
        "# a) Input Tensor\n",
        "# Represents the input image or data.\n",
        "# Typically has dimensions\n",
        "# [\n",
        "# ğ»\n",
        "# ,\n",
        "# ğ‘Š\n",
        "# ,\n",
        "# ğ¶\n",
        "# ]\n",
        "# [H,W,C], where:\n",
        "# ğ»\n",
        "# H: Height of the image.\n",
        "# ğ‘Š\n",
        "# W: Width of the image.\n",
        "# ğ¶\n",
        "# C: Number of channels (e.g., 3 for RGB images, 1 for grayscale).\n",
        "# b) Weight Tensor\n",
        "# Represents the filters (kernels) used in convolutional layers.\n",
        "# Has dimensions\n",
        "# [\n",
        "# ğ¾\n",
        "# ğ»\n",
        "# ,\n",
        "# ğ¾\n",
        "# ğ‘Š\n",
        "# ,\n",
        "# ğ¶\n",
        "# in\n",
        "# ,\n",
        "# ğ¶\n",
        "# out\n",
        "# ]\n",
        "# [K\n",
        "# H\n",
        "# â€‹\n",
        "#  ,K\n",
        "# W\n",
        "# â€‹\n",
        "#  ,C\n",
        "# in\n",
        "# â€‹\n",
        "#  ,C\n",
        "# out\n",
        "# â€‹\n",
        "#  ], where:\n",
        "# ğ¾\n",
        "# ğ»\n",
        "# ,\n",
        "# ğ¾\n",
        "# ğ‘Š\n",
        "# K\n",
        "# H\n",
        "# â€‹\n",
        "#  ,K\n",
        "# W\n",
        "# â€‹\n",
        "#  : Kernel height and width.\n",
        "# ğ¶\n",
        "# in\n",
        "# C\n",
        "# in\n",
        "# â€‹\n",
        "#  : Number of input channels.\n",
        "# ğ¶\n",
        "# out\n",
        "# C\n",
        "# out\n",
        "# â€‹\n",
        "#  : Number of output channels (number of filters).\n",
        "# c) Feature Map Tensor\n",
        "# Represents the output of a convolutional or pooling operation.\n",
        "# Dimensions depend on the input size, kernel size, stride, and padding.\n",
        "# d) Intermediate Tensors\n",
        "# Represent activations and other temporary outputs at different layers.\n",
        "# e) Output Tensor\n",
        "# Represents the final predictions or probabilities.\n",
        "# Dimensions depend on the task (e.g.,\n",
        "# [\n",
        "# ğ‘\n",
        "# ,\n",
        "# ğ¶\n",
        "# ]\n",
        "# [N,C] for classification, where\n",
        "# ğ‘\n",
        "# N is the batch size and\n",
        "# ğ¶\n",
        "# C is the number of classes).\n",
        "# 4. Tensor Transformations in CNNs\n",
        "# As data flows through the CNN, it undergoes various transformations in tensor space. These include:\n",
        "\n",
        "# a) Convolution\n",
        "# Applies filters to input tensors, generating feature maps.\n",
        "# Transforms the input tensor size depending on the kernel size, stride, and padding.\n",
        "# b) Pooling\n",
        "# Reduces spatial dimensions (height and width) while retaining depth (channels).\n",
        "# Operates on feature map tensors.\n",
        "# c) Activation\n",
        "# Applies element-wise non-linear transformations to tensors.\n",
        "# Preserves the tensor's shape but changes its values.\n",
        "# d) Flattening\n",
        "# Converts high-dimensional tensors (e.g., feature maps) into 1D tensors for use in fully connected layers.\n",
        "# e) Batch Normalization\n",
        "# Normalizes tensors along specific dimensions to stabilize and accelerate training.\n",
        "# 5. Dimensionality of Tensors in CNNs\n",
        "# Single Image\n",
        "# Input tensor:\n",
        "# [\n",
        "# ğ»\n",
        "# ,\n",
        "# ğ‘Š\n",
        "# ,\n",
        "# ğ¶\n",
        "# ]\n",
        "# [H,W,C]\n",
        "# After convolution:\n",
        "# [\n",
        "# ğ»\n",
        "# â€²\n",
        "# ,\n",
        "# ğ‘Š\n",
        "# â€²\n",
        "# ,\n",
        "# ğ¶\n",
        "# out\n",
        "# ]\n",
        "# [H\n",
        "# â€²\n",
        "#  ,W\n",
        "# â€²\n",
        "#  ,C\n",
        "# out\n",
        "# â€‹\n",
        "#  ]\n",
        "# After pooling:\n",
        "# [\n",
        "# ğ»\n",
        "# â€²\n",
        "# â€²\n",
        "# ,\n",
        "# ğ‘Š\n",
        "# â€²\n",
        "# â€²\n",
        "# ,\n",
        "# ğ¶\n",
        "# out\n",
        "# ]\n",
        "# [H\n",
        "# â€²â€²\n",
        "#  ,W\n",
        "# â€²â€²\n",
        "#  ,C\n",
        "# out\n",
        "# â€‹\n",
        "#  ]\n",
        "# Batch of Images\n",
        "# Input tensor:\n",
        "# [\n",
        "# ğ‘\n",
        "# ,\n",
        "# ğ»\n",
        "# ,\n",
        "# ğ‘Š\n",
        "# ,\n",
        "# ğ¶\n",
        "# ]\n",
        "# [N,H,W,C], where\n",
        "# ğ‘\n",
        "# N is the batch size.\n",
        "# After convolution:\n",
        "# [\n",
        "# ğ‘\n",
        "# ,\n",
        "# ğ»\n",
        "# â€²\n",
        "# ,\n",
        "# ğ‘Š\n",
        "# â€²\n",
        "# ,\n",
        "# ğ¶\n",
        "# out\n",
        "# ]\n",
        "# [N,H\n",
        "# â€²\n",
        "#  ,W\n",
        "# â€²\n",
        "#  ,C\n",
        "# out\n",
        "# â€‹\n",
        "#  ]\n",
        "# After pooling:\n",
        "# [\n",
        "# ğ‘\n",
        "# ,\n",
        "# ğ»\n",
        "# â€²\n",
        "# â€²\n",
        "# ,\n",
        "# ğ‘Š\n",
        "# â€²\n",
        "# â€²\n",
        "# ,\n",
        "# ğ¶\n",
        "# out\n",
        "# ]\n",
        "# [N,H\n",
        "# â€²â€²\n",
        "#  ,W\n",
        "# â€²â€²\n",
        "#  ,C\n",
        "# out\n",
        "# â€‹\n",
        "#  ]\n",
        "# 6. Operations in Tensor Space\n",
        "# The operations in tensor space are designed to extract meaningful features and represent data in ways suitable for the learning task:\n",
        "\n",
        "# Dot Products: Performed during convolution to compute weighted sums.\n",
        "# Reshaping: Changes tensor dimensions without altering data.\n",
        "# Broadcasting: Allows operations between tensors of different shapes (e.g., adding bias).\n",
        "# 7. Importance of Tensor Space in CNNs\n",
        "# Data Representation:\n",
        "\n",
        "# Tensors provide a structured way to represent data with multiple attributes, such as spatial dimensions and channels.\n",
        "# Scalability:\n",
        "\n",
        "# Tensor operations generalize well to larger datasets and models.\n",
        "# Hardware Optimization:\n",
        "\n",
        "# Modern hardware (GPUs, TPUs) is optimized for tensor operations, enabling efficient training and inference.\n",
        "# Flexibility:\n",
        "\n",
        "# Tensor space allows CNNs to handle diverse tasks, from image classification to object detection and segmentation.\n",
        "# 8. Example: Tensor Transformation\n",
        "# Consider a\n",
        "# 32\n",
        "# Ã—\n",
        "# 32\n",
        "# 32Ã—32 RGB image:\n",
        "\n",
        "# Input Tensor:\n",
        "# [\n",
        "# 32\n",
        "# ,\n",
        "# 32\n",
        "# ,\n",
        "# 3\n",
        "# ]\n",
        "# [32,32,3]\n",
        "# Convolution (with\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5 kernel, 16 filters, stride 1, no padding):\n",
        "# Output Tensor:\n",
        "# [\n",
        "# 28\n",
        "# ,\n",
        "# 28\n",
        "# ,\n",
        "# 16\n",
        "# ]\n",
        "# [28,28,16]\n",
        "# Pooling (e.g.,\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2, stride 2):\n",
        "# Output Tensor:\n",
        "# [\n",
        "# 14\n",
        "# ,\n",
        "# 14\n",
        "# ,\n",
        "# 16\n",
        "# ]\n",
        "# [14,14,16]\n",
        "# Flattening:\n",
        "# Output Tensor:\n",
        "# [\n",
        "# 1\n",
        "# ,\n",
        "# 3136\n",
        "# ]\n",
        "# [1,3136] (if batch size is 1)\n",
        "# Output Layer (10 classes):\n",
        "# Output Tensor:\n",
        "# [\n",
        "# 1\n",
        "# ,\n",
        "# 10\n",
        "# ]\n",
        "# [1,10]"
      ],
      "metadata": {
        "id": "t48YY9OlavqP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.11 What is LeNet-5, and how does it contribute to the development of CNNs?"
      ],
      "metadata": {
        "id": "0qFwHxWsa8Ln"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LeNet-5: Overview\n",
        "# LeNet-5 is a pioneering Convolutional Neural Network (CNN) architecture proposed by Yann LeCun et al. in 1998. It was designed for handwritten digit recognition, specifically for the MNIST dataset, and played a foundational role in the development and adoption of CNNs for computer vision tasks. The architecture demonstrated the power of deep learning for feature extraction and classification tasks, significantly influencing modern CNN designs.\n",
        "\n",
        "# 1. Architecture of LeNet-5\n",
        "# LeNet-5 consists of seven layers (excluding input) that alternate between convolutional and subsampling (pooling) operations, followed by fully connected layers. Below is a layer-by-layer breakdown:\n",
        "\n",
        "# a) Input Layer\n",
        "# Accepts grayscale images of size\n",
        "# 32\n",
        "# Ã—\n",
        "# 32\n",
        "# 32Ã—32.\n",
        "# Reason for size: MNIST digits (\n",
        "# 28\n",
        "# Ã—\n",
        "# 28\n",
        "# 28Ã—28) were padded to\n",
        "# 32\n",
        "# Ã—\n",
        "# 32\n",
        "# 32Ã—32 to maintain consistency during convolution operations.\n",
        "# b) Convolutional Layer 1 (C1)\n",
        "# Applies 6 filters (\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5) to the input.\n",
        "# Produces feature maps of size\n",
        "# 28\n",
        "# Ã—\n",
        "# 28\n",
        "# 28Ã—28 (no padding, stride 1).\n",
        "# Output dimensions:\n",
        "# 6\n",
        "# Ã—\n",
        "# 28\n",
        "# Ã—\n",
        "# 28\n",
        "# 6Ã—28Ã—28.\n",
        "# c) Subsampling Layer 1 (S2)\n",
        "# Averages the values in\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2 regions using a pooling operation.\n",
        "# Reduces the size of feature maps to\n",
        "# 14\n",
        "# Ã—\n",
        "# 14\n",
        "# 14Ã—14.\n",
        "# Output dimensions:\n",
        "# 6\n",
        "# Ã—\n",
        "# 14\n",
        "# Ã—\n",
        "# 14\n",
        "# 6Ã—14Ã—14.\n",
        "# d) Convolutional Layer 2 (C3)\n",
        "# Applies 16 filters (\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5) to the pooled feature maps from S2.\n",
        "# Results in feature maps of size\n",
        "# 10\n",
        "# Ã—\n",
        "# 10\n",
        "# 10Ã—10 (no padding, stride 1).\n",
        "# Output dimensions:\n",
        "# 16\n",
        "# Ã—\n",
        "# 10\n",
        "# Ã—\n",
        "# 10\n",
        "# 16Ã—10Ã—10.\n",
        "# e) Subsampling Layer 2 (S4)\n",
        "# Applies\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2 pooling, reducing the feature map size to\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5.\n",
        "# Output dimensions:\n",
        "# 16\n",
        "# Ã—\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 16Ã—5Ã—5.\n",
        "# f) Fully Connected Layer 1 (F5)\n",
        "# Flattens the feature maps into a single vector.\n",
        "# Connects to 120 neurons (outputs).\n",
        "# g) Fully Connected Layer 2 (F6)\n",
        "# Connects the 120 neurons to 84 neurons.\n",
        "# Serves as a dense layer for learning complex patterns.\n",
        "# h) Output Layer\n",
        "# Contains 10 neurons (one for each class in MNIST).\n",
        "# Uses softmax activation to output probabilities for each class.\n",
        "# 2. Key Features of LeNet-5\n",
        "# Hierarchical Feature Extraction:\n",
        "\n",
        "# The alternating convolutional and pooling layers progressively extract spatial hierarchies of features, from edges to digits.\n",
        "# Weight Sharing:\n",
        "\n",
        "# Convolutional layers use the same weights (filters) across spatial locations, reducing the number of parameters and improving efficiency.\n",
        "# Dimensionality Reduction:\n",
        "\n",
        "# Pooling layers reduce the spatial dimensions of feature maps, enabling the network to focus on salient features and avoid overfitting.\n",
        "# End-to-End Learning:\n",
        "\n",
        "# The network learns feature extraction and classification jointly, eliminating the need for handcrafted features.\n",
        "# 3. Contribution of LeNet-5 to CNN Development\n",
        "# LeNet-5 was revolutionary for its time and contributed significantly to the evolution of deep learning and CNNs:\n",
        "\n",
        "# a) Popularized Convolutional Neural Networks\n",
        "# Demonstrated that CNNs could outperform traditional methods in tasks like image recognition by leveraging spatial hierarchies in data.\n",
        "# b) Established Core Architectural Principles\n",
        "# Introduced key concepts like convolution, pooling, and hierarchical feature extraction, which are now standard in modern CNN architectures.\n",
        "# c) Inspired Modern Architectures\n",
        "# Served as the blueprint for later architectures, such as AlexNet, VGG, ResNet, and beyond, which scaled the ideas of LeNet-5 to larger datasets and deeper networks.\n",
        "# d) Efficient Use of Parameters\n",
        "# Showed that weight sharing and local connections significantly reduce the number of parameters, making CNNs feasible for hardware of that era.\n",
        "# e) Focused on Practical Applications\n",
        "# Validated CNNs as a practical solution for real-world problems, such as digit recognition for postal code sorting in automated mail systems.\n",
        "# 4. Limitations of LeNet-5\n",
        "# While LeNet-5 was groundbreaking, it had limitations:\n",
        "\n",
        "# Small-scale Architecture:\n",
        "\n",
        "# Designed for small datasets like MNIST, it does not scale well to complex datasets such as ImageNet.\n",
        "# Shallow Network:\n",
        "\n",
        "# Limited depth and capacity compared to modern networks.\n",
        "# Manual Design Choices:\n",
        "\n",
        "# Fixed filter sizes and layer configurations, lacking the flexibility of modern automated architecture search methods.\n",
        "# 5. Legacy of LeNet-5\n",
        "# LeNet-5 laid the groundwork for CNN research and development:\n",
        "\n",
        "# Introduced an intuitive understanding of convolutional operations and hierarchical learning.\n",
        "# Encouraged further exploration of deep learning, leading to breakthroughs in fields like computer vision, natural language processing, and autonomous systems."
      ],
      "metadata": {
        "id": "dP9Wnt9dbFjW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.12 What is AlexNet, and why was it a breakthrough in deep learning?"
      ],
      "metadata": {
        "id": "vjZyGwP7bdKu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AlexNet: Overview\n",
        "# AlexNet is a deep Convolutional Neural Network (CNN) architecture that achieved a groundbreaking performance in the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC). It was developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton and marked a significant milestone in the field of deep learning and computer vision.\n",
        "\n",
        "# 1. Architecture of AlexNet\n",
        "# AlexNet has 8 layers (5 convolutional layers and 3 fully connected layers), and it introduced several innovative techniques that addressed challenges in training deep networks. Here's a breakdown:\n",
        "\n",
        "# a) Input Layer\n",
        "# Input image size:\n",
        "# 227\n",
        "# Ã—\n",
        "# 227\n",
        "# Ã—\n",
        "# 3\n",
        "# 227Ã—227Ã—3 (RGB images).\n",
        "# Images from the ImageNet dataset were resized and normalized to this fixed size.\n",
        "# b) Convolutional Layers\n",
        "# Conv1:\n",
        "# 96 filters,\n",
        "# 11\n",
        "# Ã—\n",
        "# 11\n",
        "# 11Ã—11, stride 4.\n",
        "# Produces feature maps of size\n",
        "# 55\n",
        "# Ã—\n",
        "# 55\n",
        "# Ã—\n",
        "# 96\n",
        "# 55Ã—55Ã—96.\n",
        "# Conv2:\n",
        "# 256 filters,\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5, stride 1, with padding.\n",
        "# Produces feature maps of size\n",
        "# 27\n",
        "# Ã—\n",
        "# 27\n",
        "# Ã—\n",
        "# 256\n",
        "# 27Ã—27Ã—256.\n",
        "# Conv3:\n",
        "# 384 filters,\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3, stride 1.\n",
        "# Produces feature maps of size\n",
        "# 13\n",
        "# Ã—\n",
        "# 13\n",
        "# Ã—\n",
        "# 384\n",
        "# 13Ã—13Ã—384.\n",
        "# Conv4:\n",
        "# 384 filters,\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3, stride 1.\n",
        "# Produces feature maps of size\n",
        "# 13\n",
        "# Ã—\n",
        "# 13\n",
        "# Ã—\n",
        "# 384\n",
        "# 13Ã—13Ã—384.\n",
        "# Conv5:\n",
        "# 256 filters,\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3, stride 1.\n",
        "# Produces feature maps of size\n",
        "# 13\n",
        "# Ã—\n",
        "# 13\n",
        "# Ã—\n",
        "# 256\n",
        "# 13Ã—13Ã—256.\n",
        "# c) Pooling Layers\n",
        "# Max pooling (\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3, stride 2) follows Conv1, Conv2, and Conv5.\n",
        "# Pooling layers reduce spatial dimensions while retaining key features.\n",
        "# d) Fully Connected Layers\n",
        "# FC6:\n",
        "# 4096 neurons, fully connected to flattened output of Conv5.\n",
        "# FC7:\n",
        "# 4096 neurons, fully connected.\n",
        "# FC8:\n",
        "# 1000 neurons, corresponding to 1000 ImageNet classes.\n",
        "# e) Output Layer\n",
        "# Softmax activation produces probabilities for 1000 classes.\n",
        "# 2. Key Innovations in AlexNet\n",
        "# AlexNet introduced several advancements that made it a breakthrough in deep learning:\n",
        "\n",
        "# a) Use of GPUs\n",
        "# Leveraged GPUs (NVIDIA GTX 580) for accelerated training, enabling the network to process large datasets like ImageNet.\n",
        "# Significantly reduced training time compared to CPU-based approaches.\n",
        "# b) ReLU Activation\n",
        "# Replaced traditional activation functions like sigmoid or tanh with the Rectified Linear Unit (ReLU).\n",
        "# Benefits:\n",
        "# Faster training due to non-saturating gradients.\n",
        "# Alleviated the vanishing gradient problem.\n",
        "# c) Data Augmentation\n",
        "# Applied techniques like random cropping, horizontal flipping, and RGB channel shifting to artificially increase the size of the training dataset and reduce overfitting.\n",
        "# d) Dropout\n",
        "# Introduced dropout in the fully connected layers, randomly disabling neurons during training.\n",
        "# Helped prevent overfitting by promoting robustness in feature learning.\n",
        "# e) Overlapping Pooling\n",
        "# Used overlapping max pooling (\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 with stride 2) instead of non-overlapping pooling (\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2).\n",
        "# Resulted in smoother feature maps and better generalization.\n",
        "# f) Large Filter Sizes\n",
        "# Used larger filters in early layers (\n",
        "# 11\n",
        "# Ã—\n",
        "# 11\n",
        "# 11Ã—11 in Conv1) to capture global features and reduce dimensionality.\n",
        "# 3. Impact of AlexNet\n",
        "# AlexNet's success revolutionized deep learning and set the stage for subsequent advancements in computer vision:\n",
        "\n",
        "# a) Breakthrough in ImageNet\n",
        "# Achieved a top-5 error rate of 15.3%, compared to the second-best entry's 26.2%.\n",
        "# Demonstrated the power of deep learning to outperform traditional computer vision techniques.\n",
        "# b) Popularized Deep Learning\n",
        "# Sparked widespread interest in deep learning and CNNs, leading to the development of more advanced architectures (e.g., VGG, ResNet, and DenseNet).\n",
        "# c) Leveraged Large Datasets\n",
        "# Successfully showed how deep networks can extract meaningful patterns from massive datasets like ImageNet, proving scalability.\n",
        "# d) Catalyst for Hardware Development\n",
        "# Highlighted the importance of GPUs and parallel computing, inspiring hardware advancements tailored to deep learning tasks (e.g., TPUs).\n",
        "# 4. Challenges Addressed by AlexNet\n",
        "# Training Deep Networks:\n",
        "# AlexNet's use of ReLU and GPUs solved the computational and gradient-based challenges of training deep models.\n",
        "# Overfitting:\n",
        "# Techniques like data augmentation and dropout mitigated overfitting, ensuring generalization on test data.\n",
        "# Scalability:\n",
        "# Demonstrated that deep models could handle high-dimensional data effectively.\n",
        "# 5. Limitations of AlexNet\n",
        "# Resource Intensive:\n",
        "# Required powerful GPUs, which were not universally accessible at the time.\n",
        "# Fixed Input Size:\n",
        "# Required resizing of input images, potentially distorting aspect ratios.\n",
        "# Large Number of Parameters:\n",
        "# Contained 60 million parameters, leading to high memory and computation demands.\n",
        "# 6. Legacy of AlexNet\n",
        "# AlexNet's contributions include:\n",
        "\n",
        "# Establishing deep learning as the dominant paradigm for computer vision tasks.\n",
        "# Influencing the design of modern architectures by introducing techniques like ReLU and dropout.\n",
        "# Inspiring advancements in optimization, hardware, and scalability for neural networks."
      ],
      "metadata": {
        "id": "LHJVs2AgbiLN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.13 What is VGGNet, and how does it differ from AlexNet?"
      ],
      "metadata": {
        "id": "tDdd84debyXN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VGGNet: Overview\n",
        "# VGGNet, developed by the Visual Geometry Group (VGG) at the University of Oxford, was introduced in 2014 by Karen Simonyan and Andrew Zisserman in their paper \"Very Deep Convolutional Networks for Large-Scale Image Recognition.\" It built on the success of AlexNet and introduced a simpler yet highly effective design principle: using smaller convolutional filters (e.g.,\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3) while significantly increasing network depth. VGGNet achieved outstanding performance in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, establishing itself as a key milestone in CNN development.\n",
        "\n",
        "# 1. Architecture of VGGNet\n",
        "# VGGNet is characterized by its uniform architecture, consisting of:\n",
        "\n",
        "# Convolutional layers: Using\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 filters.\n",
        "# Pooling layers: Max pooling (\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2, stride 2) to reduce spatial dimensions.\n",
        "# Fully connected layers: Typically 2-3 dense layers at the end.\n",
        "# Softmax layer: For classification.\n",
        "# Key Variants\n",
        "# VGGNet comes in multiple configurations, with the most notable being:\n",
        "\n",
        "# VGG-16: 16 layers (13 convolutional + 3 fully connected).\n",
        "# VGG-19: 19 layers (16 convolutional + 3 fully connected).\n",
        "# Design Principles\n",
        "# Small Filters:\n",
        "# Uses\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 convolutional filters across all layers.\n",
        "# Advantage: Captures local features with a smaller receptive field, increasing feature granularity.\n",
        "# Increasing Depth:\n",
        "# Stacks more convolutional layers sequentially.\n",
        "# Allows deeper feature extraction and hierarchical learning.\n",
        "# Layer Structure\n",
        "# The network alternates between blocks of convolutional layers and max-pooling layers:\n",
        "\n",
        "# Each convolutional block consists of 2-3 convolutional layers followed by pooling.\n",
        "# The number of filters doubles after each pooling operation, starting from 64.\n",
        "# Fully Connected Layers\n",
        "# Two fully connected layers with 4096 neurons each.\n",
        "# A final fully connected layer with 1000 neurons for ImageNet classification.\n",
        "# 2. How VGGNet Differs from AlexNet\n",
        "# VGGNet introduced several improvements over AlexNet, focusing on depth and simplicity in design.\n",
        "\n",
        "# Aspect\tAlexNet\tVGGNet\n",
        "# Number of Layers\t8 (5 convolutional, 3 fully connected)\t16-19 (13-16 convolutional, 3 fully connected)\n",
        "# Filter Size\tVaried (\n",
        "# 11\n",
        "# Ã—\n",
        "# 11\n",
        "# 11Ã—11,\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5)\tFixed (\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3)\n",
        "# Depth\tRelatively shallow\tSignificantly deeper\n",
        "# Pooling\tOverlapping pooling\tNon-overlapping pooling (\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2)\n",
        "# Parameter Count\t~60 million\t~138 million (VGG-16)\n",
        "# Activation Function\tReLU\tReLU\n",
        "# Model Complexity\tModerate\tHigh due to deeper architecture\n",
        "# Architectural Design\tHeterogeneous\tHomogeneous (repeated\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3)\n",
        "# Key Differences\n",
        "# Filter Size and Stacking:\n",
        "\n",
        "# AlexNet uses larger filters (\n",
        "# 11\n",
        "# Ã—\n",
        "# 11\n",
        "# 11Ã—11,\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5) in the initial layers, which capture global features.\n",
        "# VGGNet employs smaller filters (\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3) stacked sequentially, mimicking the effect of a larger receptive field while adding non-linearities.\n",
        "# Depth:\n",
        "\n",
        "# VGGNet significantly increases the depth, learning more hierarchical features.\n",
        "# This increase in depth was crucial for its performance improvement over AlexNet.\n",
        "# Simplified Design:\n",
        "\n",
        "# AlexNetâ€™s architecture is more varied, with differing filter sizes and strides.\n",
        "# VGGNet employs a simple and uniform design, making it easier to extend or modify.\n",
        "# Computational Complexity:\n",
        "\n",
        "# VGGNet has a larger number of parameters and higher computational requirements than AlexNet.\n",
        "# Performance:\n",
        "\n",
        "# VGGNet achieves better accuracy on large-scale datasets like ImageNet due to its depth and fine-grained feature extraction.\n",
        "# 3. Advantages of VGGNet\n",
        "# Improved Accuracy:\n",
        "# The increased depth and smaller filters contribute to better performance on classification tasks.\n",
        "# Modular Design:\n",
        "# The uniform structure of VGGNet simplifies implementation and understanding.\n",
        "# Hierarchical Feature Extraction:\n",
        "# Captures fine details by stacking multiple small filters.\n",
        "# 4. Limitations of VGGNet\n",
        "# High Computational Cost:\n",
        "# VGGNet has a significantly larger number of parameters (~138 million for VGG-16), making it resource-intensive.\n",
        "# Memory Usage:\n",
        "# Requires substantial GPU memory, limiting its scalability to larger models or datasets.\n",
        "# Training Time:\n",
        "# Longer training time due to increased depth and parameter count.\n",
        "# Not Suitable for Real-Time Applications:\n",
        "# High latency and inference time due to computational complexity.\n",
        "# 5. Legacy and Impact of VGGNet\n",
        "# Inspired Modern Architectures:\n",
        "# Deep networks like ResNet and DenseNet were influenced by VGGNetâ€™s depth-centric design philosophy.\n",
        "# Transfer Learning:\n",
        "# VGGNet became a popular choice for transfer learning tasks due to its robust pre-trained features.\n",
        "# Standardization:\n",
        "# Popularized the use of small filters (\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3) and deep, uniform architectures.\n",
        "# Benchmark for Simplicity:\n",
        "# Set a precedent for clean and interpretable architectural designs."
      ],
      "metadata": {
        "id": "Rwt5QBDjb4f0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.14 What is GoogLeNet, and what is its main innovation?"
      ],
      "metadata": {
        "id": "s5RvXKPacJRk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# GoogLeNet: Overview\n",
        "# GoogLeNet, also known as Inception v1, is a deep Convolutional Neural Network (CNN) developed by researchers at Google and introduced in the paper \"Going Deeper with Convolutions\" in 2014. It won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014 with a top-5 error rate of 6.7%, outperforming other models with its novel architecture and efficient computation.\n",
        "\n",
        "# The main innovation of GoogLeNet lies in the Inception module, which enables the network to extract multi-scale features efficiently while keeping computational costs low.\n",
        "\n",
        "# 1. Architecture of GoogLeNet\n",
        "# GoogLeNet consists of 22 layers (27 if pooling layers are counted) but has significantly fewer parameters (12 million) compared to earlier architectures like VGGNet (138 million). Its key component is the Inception module, which aggregates features from different scales.\n",
        "\n",
        "# a) Inception Module\n",
        "# The Inception module combines convolutional and pooling operations of varying sizes to capture information at multiple scales. It includes:\n",
        "\n",
        "# 1\n",
        "# Ã—\n",
        "# 1\n",
        "# 1Ã—1 convolutions: Reduce dimensionality and perform feature mapping.\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 convolutions: Capture medium-sized features.\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5 convolutions: Capture larger features.\n",
        "# Max pooling (\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3): Retain spatial invariance.\n",
        "# The outputs of these operations are concatenated along the depth (channel) dimension, creating a rich feature representation.\n",
        "\n",
        "# b) Layer Structure\n",
        "# Stem:\n",
        "\n",
        "# The initial layers consist of standard convolutions and max pooling to reduce the spatial dimensions while extracting low-level features.\n",
        "# Inception Blocks:\n",
        "\n",
        "# The core architecture contains 9 Inception modules, organized sequentially with intermediate pooling layers.\n",
        "# Auxiliary Classifiers:\n",
        "\n",
        "# To mitigate the vanishing gradient problem in deep networks, two auxiliary classifiers are added after certain layers. These act as \"side heads\" and provide additional gradient signals during training.\n",
        "# Output Layer:\n",
        "\n",
        "# A fully connected layer followed by a softmax layer for classification.\n",
        "# 2. Main Innovation: Inception Module\n",
        "# The Inception module introduces multi-scale feature extraction within a single block. Its advantages include:\n",
        "\n",
        "# Multi-Scale Processing:\n",
        "\n",
        "# Simultaneously applies filters of different sizes (\n",
        "# 1\n",
        "# Ã—\n",
        "# 1\n",
        "# 1Ã—1,\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3,\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5) and combines their outputs.\n",
        "# Captures features of varying spatial extents.\n",
        "# Dimensionality Reduction:\n",
        "\n",
        "# 1\n",
        "# Ã—\n",
        "# 1\n",
        "# 1Ã—1 convolutions are used for dimensionality reduction before applying\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 or\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5 convolutions. This reduces computational complexity and memory usage.\n",
        "# Efficient Parameter Use:\n",
        "\n",
        "# By reducing dimensions and avoiding dense connections, GoogLeNet has far fewer parameters than VGGNet despite being deeper.\n",
        "# 3. Advantages of GoogLeNet\n",
        "# Improved Accuracy:\n",
        "# Achieved state-of-the-art results in ImageNet 2014.\n",
        "# Efficient Computation:\n",
        "# The use of\n",
        "# 1\n",
        "# Ã—\n",
        "# 1\n",
        "# 1Ã—1 convolutions and modular design reduces computation and memory requirements.\n",
        "# Scalability:\n",
        "# The Inception module design can be extended to more complex networks (e.g., Inception v2, v3).\n",
        "# Deep and Sparse Design:\n",
        "# Deeper than previous architectures but computationally efficient due to sparse connections within the Inception module.\n",
        "# 4. Limitations of GoogLeNet\n",
        "# Complexity in Design:\n",
        "# The architecture of the Inception module is more complex compared to simpler models like VGGNet.\n",
        "# Training Challenges:\n",
        "# Requires careful tuning of hyperparameters and advanced optimization techniques for effective training.\n",
        "# Lack of Interpretability:\n",
        "# The multi-branch structure of the Inception module can make it harder to interpret learned features.\n",
        "# 5. Impact and Legacy of GoogLeNet\n",
        "# Modular Architectures:\n",
        "# Introduced the concept of modular blocks (Inception modules), inspiring the development of modern architectures like ResNet and EfficientNet.\n",
        "# Parameter Efficiency:\n",
        "# Demonstrated that increasing depth doesnâ€™t necessarily require a proportional increase in parameters.\n",
        "# Extended Variants:\n",
        "# Led to more advanced models in the Inception family (e.g., Inception v2, v3, and v4).\n",
        "# Real-World Applications:\n",
        "# GoogLeNet's efficiency made it suitable for deployment in resource-constrained environments.\n",
        "# 6. GoogLeNet vs. Previous Architectures\n",
        "# Aspect\tAlexNet\tVGGNet\tGoogLeNet\n",
        "# Number of Layers\t8\t16-19\t22\n",
        "# Parameter Count\t~60 million\t~138 million\t~12 million\n",
        "# Filter Sizes\n",
        "# 11\n",
        "# Ã—\n",
        "# 11\n",
        "# 11Ã—11,\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5\tFixed (\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3)\n",
        "# 1\n",
        "# Ã—\n",
        "# 1\n",
        "# 1Ã—1,\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3,\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5\n",
        "# Key Innovation\tReLU activation and GPU training\tIncreased depth with small filters\tInception module for multi-scale feature extraction\n",
        "# Efficiency\tModerate\tComputationally expensive\tHighly efficient\n",
        "# 7. Conclusion\n",
        "# GoogLeNet introduced a paradigm shift in deep learning by demonstrating that:\n",
        "\n",
        "# Efficient architectures can achieve high performance without relying on an excessive number of parameters.\n",
        "# Multi-scale feature extraction through the Inception module improves accuracy and robustness."
      ],
      "metadata": {
        "id": "U_gE-a8xcOW7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.15 What is ResNet, and what problem does it solve?"
      ],
      "metadata": {
        "id": "RNmvngASciar"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet: Overview\n",
        "# ResNet (Residual Network) is a groundbreaking deep learning architecture introduced by Kaiming He and colleagues in their paper \"Deep Residual Learning for Image Recognition\" (2015). It won the ILSVRC 2015 competition with a top-5 error rate of 3.57%, outperforming all previous models. ResNet's main innovation is the residual connection, which addresses the degradation problem in deep networks, enabling the training of extremely deep architectures with improved performance.\n",
        "\n",
        "# 1. The Problem ResNet Solves\n",
        "# a) Degradation Problem\n",
        "# As networks become deeper, performance can degrade, even when the model is not overfitting.\n",
        "# This phenomenon occurs because the optimization process struggles to propagate gradients effectively through very deep layers, leading to:\n",
        "# Vanishing/exploding gradients.\n",
        "# Difficulty in learning identity mappings (i.e., copying inputs to outputs in intermediate layers).\n",
        "# b) Key Observation\n",
        "# Instead of directly learning the mapping\n",
        "# ğ»\n",
        "# (\n",
        "# ğ‘¥\n",
        "# )\n",
        "# H(x), it's easier for the network to learn the residual mapping\n",
        "# ğ¹\n",
        "# (\n",
        "# ğ‘¥\n",
        "# )\n",
        "# =\n",
        "# ğ»\n",
        "# (\n",
        "# ğ‘¥\n",
        "# )\n",
        "# âˆ’\n",
        "# ğ‘¥\n",
        "# F(x)=H(x)âˆ’x, where\n",
        "# ğ»\n",
        "# (\n",
        "# ğ‘¥\n",
        "# )\n",
        "# H(x) is the desired mapping.\n",
        "# 2. ResNetâ€™s Main Innovation: Residual Learning\n",
        "# Residual Block\n",
        "# A residual block is the fundamental building block of ResNet. It introduces a shortcut (skip) connection that bypasses one or more layers.\n",
        "\n",
        "# For input\n",
        "# ğ‘¥\n",
        "# x, the output of a residual block is:\n",
        "\n",
        "# ğ‘¦\n",
        "# =\n",
        "# ğ¹\n",
        "# (\n",
        "# ğ‘¥\n",
        "# ,\n",
        "# ğ‘Š\n",
        "# )\n",
        "# +\n",
        "# ğ‘¥\n",
        "# y=F(x,W)+x\n",
        "# ğ¹\n",
        "# (\n",
        "# ğ‘¥\n",
        "# ,\n",
        "# ğ‘Š\n",
        "# )\n",
        "# F(x,W): Residual function (learned by stacked layers, e.g., convolutions).\n",
        "# ğ‘¥\n",
        "# x: Shortcut connection (directly added to the output of\n",
        "# ğ¹\n",
        "# (\n",
        "# ğ‘¥\n",
        "# ,\n",
        "# ğ‘Š\n",
        "# )\n",
        "# F(x,W)).\n",
        "# This addition ensures that the network can learn the residual function\n",
        "# ğ¹\n",
        "# (\n",
        "# ğ‘¥\n",
        "# ,\n",
        "# ğ‘Š\n",
        "# )\n",
        "# F(x,W) instead of the full mapping\n",
        "# ğ»\n",
        "# (\n",
        "# ğ‘¥\n",
        "# )\n",
        "# H(x), making optimization easier.\n",
        "\n",
        "# Advantages of Residual Learning\n",
        "# Easier Gradient Flow:\n",
        "# The shortcut connection ensures gradients flow directly to earlier layers, alleviating vanishing gradients.\n",
        "# Identity Mapping:\n",
        "# If the residual\n",
        "# ğ¹\n",
        "# (\n",
        "# ğ‘¥\n",
        "# ,\n",
        "# ğ‘Š\n",
        "# )\n",
        "# F(x,W) is zero, the network behaves as an identity mapping, avoiding performance degradation.\n",
        "# Efficient Training:\n",
        "# Enables deeper networks to converge faster and achieve better accuracy.\n",
        "# 3. Architecture of ResNet\n",
        "# ResNet models are available in various configurations based on the number of layers, such as:\n",
        "\n",
        "# ResNet-18: 18 layers.\n",
        "# ResNet-34: 34 layers.\n",
        "# ResNet-50: 50 layers.\n",
        "# ResNet-101: 101 layers.\n",
        "# ResNet-152: 152 layers.\n",
        "# Key Components\n",
        "# Convolutional Layers:\n",
        "# Use\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 filters for feature extraction.\n",
        "# Batch normalization (BN) is applied after each convolution.\n",
        "# Residual Blocks:\n",
        "# Two main types:\n",
        "# Basic Block: Used in shallower architectures (e.g., ResNet-18, ResNet-34).\n",
        "# Bottleneck Block: Used in deeper architectures (e.g., ResNet-50, ResNet-101, ResNet-152). Consists of three layers:\n",
        "# 1\n",
        "# Ã—\n",
        "# 1\n",
        "# 1Ã—1 for dimensionality reduction.\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 for feature extraction.\n",
        "# 1\n",
        "# Ã—\n",
        "# 1\n",
        "# 1Ã—1 for dimensionality restoration.\n",
        "# Global Average Pooling:\n",
        "# Replaces fully connected layers to reduce parameters and prevent overfitting.\n",
        "# Softmax Layer:\n",
        "# Outputs class probabilities.\n",
        "# 4. Key Features of ResNet\n",
        "# Skip Connections:\n",
        "# Shortcut connections bypass certain layers, enabling deeper networks.\n",
        "# Depth Scalability:\n",
        "# Successfully trains networks with hundreds or even thousands of layers (e.g., ResNet-1001).\n",
        "# Batch Normalization:\n",
        "# Helps stabilize training and improve convergence.\n",
        "# Reduced Parameters:\n",
        "# Bottleneck blocks reduce computation while maintaining performance.\n",
        "# 5. Advantages of ResNet\n",
        "# Handles Vanishing Gradients:\n",
        "# Allows gradients to propagate more effectively through deep networks.\n",
        "# Enables Deeper Architectures:\n",
        "# Achieves high performance even with very deep networks (e.g., ResNet-152).\n",
        "# Improved Accuracy:\n",
        "# Outperforms previous architectures like VGGNet and GoogLeNet on ImageNet.\n",
        "# Transfer Learning:\n",
        "# Pre-trained ResNet models are widely used for transfer learning in various tasks.\n",
        "# Scalable:\n",
        "# Adaptable to different depths and computational budgets.\n",
        "# 6. Limitations of ResNet\n",
        "# Computational Overhead:\n",
        "# Deeper networks like ResNet-152 require substantial computational resources.\n",
        "# Redundancy:\n",
        "# Some very deep residual networks might learn redundant mappings, offering diminishing returns on accuracy.\n",
        "# 7. Impact and Legacy of ResNet\n",
        "# Milestone in Deep Learning:\n",
        "# ResNet demonstrated that very deep networks could be trained effectively, breaking previous limitations.\n",
        "# Foundation for Modern Architectures:\n",
        "# Inspired newer models like DenseNet, EfficientNet, and ResNeXt.\n",
        "# Versatility:\n",
        "# Used in various fields, including image recognition, object detection, and natural language processing.\n",
        "# 8. Comparison with Earlier Architectures\n",
        "# Aspect\tVGGNet\tGoogLeNet\tResNet\n",
        "# Key Innovation\tIncreased depth with small filters\tInception module for multi-scale features\tResidual learning with skip connections\n",
        "# Number of Parameters\t~138 million\t~12 million\t~25 million (ResNet-50)\n",
        "# Depth\t16-19 layers\t22 layers\t18-152+ layers\n",
        "# Gradient Flow\tProne to vanishing gradients\tImproved, but complex\tExcellent, due to skip connections\n",
        "# 9. Conclusion\n",
        "# ResNet revolutionized deep learning by introducing residual connections to address the challenges of training very deep networks. Its efficient and scalable architecture has made it a cornerstone in the development of modern neural networks, enabling advancements in accuracy and depth that were previously unattainable."
      ],
      "metadata": {
        "id": "51ag2auveJ3I"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.16 What is DenseNet, and how does it differ from ResNet?"
      ],
      "metadata": {
        "id": "sR1jVZuWeZSH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DenseNet: Overview\n",
        "# DenseNet (Dense Convolutional Network) is a deep learning architecture introduced by Gao Huang et al. in the 2017 paper \"Densely Connected Convolutional Networks.\" DenseNet builds on the success of ResNet by proposing an alternative connectivity pattern. Unlike ResNet, which uses skip connections between input and output, DenseNet connects each layer to every subsequent layer in a dense manner. This allows for more efficient feature reuse and gradient flow.\n",
        "\n",
        "# 1. DenseNet Architecture\n",
        "# Key Features\n",
        "# Dense Connectivity:\n",
        "\n",
        "# Each layer receives inputs from all preceding layers and passes its own feature maps to all subsequent layers.\n",
        "# For\n",
        "# ğ‘›\n",
        "# n layers, the\n",
        "# ğ‘™\n",
        "# ğ‘¡\n",
        "# â„\n",
        "# l\n",
        "# th\n",
        "#   layerâ€™s input is:\n",
        "# ğ‘¥\n",
        "# ğ‘™\n",
        "# =\n",
        "# ğ»\n",
        "# ğ‘™\n",
        "# (\n",
        "# [\n",
        "# ğ‘¥\n",
        "# 0\n",
        "# ,\n",
        "# ğ‘¥\n",
        "# 1\n",
        "# ,\n",
        "# .\n",
        "# .\n",
        "# .\n",
        "# ,\n",
        "# ğ‘¥\n",
        "# ğ‘™\n",
        "# âˆ’\n",
        "# 1\n",
        "# ]\n",
        "# )\n",
        "# x\n",
        "# l\n",
        "# â€‹\n",
        "#  =H\n",
        "# l\n",
        "# â€‹\n",
        "#  ([x\n",
        "# 0\n",
        "# â€‹\n",
        "#  ,x\n",
        "# 1\n",
        "# â€‹\n",
        "#  ,...,x\n",
        "# lâˆ’1\n",
        "# â€‹\n",
        "#  ])\n",
        "# where\n",
        "# [\n",
        "# ğ‘¥\n",
        "# 0\n",
        "# ,\n",
        "# ğ‘¥\n",
        "# 1\n",
        "# ,\n",
        "# .\n",
        "# .\n",
        "# .\n",
        "# ,\n",
        "# ğ‘¥\n",
        "# ğ‘™\n",
        "# âˆ’\n",
        "# 1\n",
        "# ]\n",
        "# [x\n",
        "# 0\n",
        "# â€‹\n",
        "#  ,x\n",
        "# 1\n",
        "# â€‹\n",
        "#  ,...,x\n",
        "# lâˆ’1\n",
        "# â€‹\n",
        "#  ] represents the concatenation of feature maps from layers\n",
        "# 0\n",
        "# 0 to\n",
        "# ğ‘™\n",
        "# âˆ’\n",
        "# 1\n",
        "# lâˆ’1, and\n",
        "# ğ»\n",
        "# ğ‘™\n",
        "# H\n",
        "# l\n",
        "# â€‹\n",
        "#   is the transformation (e.g., a convolution).\n",
        "# Feature Reuse:\n",
        "\n",
        "# Every layer uses features from all preceding layers, ensuring efficient usage of learned information and reducing redundancy.\n",
        "# Compact Model:\n",
        "\n",
        "# DenseNet requires fewer parameters than ResNet due to the reduced need for redundant feature learning.\n",
        "# DenseNet Components\n",
        "# Dense Block:\n",
        "\n",
        "# A sequence of densely connected layers.\n",
        "# Each layer produces\n",
        "# ğ‘˜\n",
        "# k feature maps, where\n",
        "# ğ‘˜\n",
        "# k is the growth rate (a hyperparameter).\n",
        "# Transition Layer:\n",
        "\n",
        "# Placed between dense blocks to reduce dimensions and computational complexity.\n",
        "# Consists of:\n",
        "# 1\n",
        "# Ã—\n",
        "# 1\n",
        "# 1Ã—1 convolution for feature compression.\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2 average pooling for down-sampling.\n",
        "# Global Average Pooling and Output:\n",
        "\n",
        "# After the last dense block, global average pooling is applied, followed by a softmax layer for classification.\n",
        "# 2. How DenseNet Differs from ResNet\n",
        "# Aspect\tResNet\tDenseNet\n",
        "# Connection Pattern\tShortcut connections bypass one or more layers.\tDense connections: Each layer connects to every other layer.\n",
        "# Feature Reuse\tPartial: Reuses features indirectly through skip connections.\tFull: Directly reuses all preceding layer outputs.\n",
        "# Gradient Flow\tGood: Shortcut paths ease gradient flow.\tExcellent: Dense connections ensure strong gradient propagation.\n",
        "# Parameter Efficiency\tModerate: Relies on residual blocks.\tHigh: Avoids redundancy through feature reuse.\n",
        "# Number of Parameters\tHigher (e.g., ResNet-50: ~25M)\tLower for equivalent depth (DenseNet-121: ~8M).\n",
        "# Depth Scalability\tCan train networks with hundreds of layers.\tCan train very deep networks but memory usage is a concern.\n",
        "# Architectural Component\tResidual blocks with addition.\tDense blocks with concatenation.\n",
        "# 3. Advantages of DenseNet\n",
        "# Efficient Feature Use:\n",
        "# Maximizes information flow between layers by reusing all features.\n",
        "# Reduced Overfitting:\n",
        "# Fewer parameters reduce the risk of overfitting, especially on small datasets.\n",
        "# Improved Gradient Flow:\n",
        "# Direct connections between all layers make backpropagation more effective.\n",
        "# Compact Model:\n",
        "# Requires fewer parameters compared to ResNet for similar performance.\n",
        "# 4. Limitations of DenseNet\n",
        "# Memory Consumption:\n",
        "# Dense connections result in high memory usage, as all previous feature maps need to be stored for concatenation.\n",
        "# Computational Overhead:\n",
        "# Concatenation operations can slow down training and inference.\n",
        "# Scaling Challenges:\n",
        "# While the model is parameter-efficient, it may struggle with extremely deep architectures due to memory constraints.\n",
        "# 5. DenseNet Variants\n",
        "# DenseNet comes in various configurations depending on the depth and number of layers in each dense block:\n",
        "\n",
        "# DenseNet-121: 121 layers.\n",
        "# DenseNet-169: 169 layers.\n",
        "# DenseNet-201: 201 layers.\n",
        "# DenseNet-264: 264 layers.\n",
        "# 6. Applications of DenseNet\n",
        "# DenseNet has been widely used in:\n",
        "\n",
        "# Image classification (e.g., ImageNet, CIFAR-10/100).\n",
        "# Medical image analysis (e.g., radiology, pathology).\n",
        "# Object detection and semantic segmentation tasks.\n",
        "# 7. Conclusion\n",
        "# DenseNet improves upon ResNet by using dense connections that promote efficient feature reuse and better gradient flow. While it achieves similar or better performance with fewer parameters, its high memory requirements can be a drawback. DenseNetâ€™s innovative approach has inspired other architectures and remains a key milestone in deep learning research."
      ],
      "metadata": {
        "id": "KT-R-ZcmfrsF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.17 What are the main steps involved in training a CNN from scratch?"
      ],
      "metadata": {
        "id": "-pLo74bghG6a"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training a Convolutional Neural Network (CNN) from scratch involves several key steps, ranging from data preparation to model evaluation. Here's an overview of the main steps involved:\n",
        "\n",
        "# 1. Data Collection and Preprocessing\n",
        "# Data Collection:\n",
        "# Gather a labeled dataset relevant to the task (e.g., images for classification).\n",
        "# The dataset can either be collected manually or obtained from existing public datasets (e.g., ImageNet, CIFAR-10, MNIST).\n",
        "# Data Augmentation (optional but recommended):\n",
        "# To improve generalization and prevent overfitting, augment the training data by applying transformations such as:\n",
        "# Rotations, flipping, scaling, cropping, etc.\n",
        "# Normalization/Standardization:\n",
        "# Normalize the pixel values of images (e.g., scaling pixel values to the range [0, 1] or standardizing to have a mean of 0 and standard deviation of 1).\n",
        "# Splitting Data:\n",
        "# Divide the dataset into training, validation, and test sets (e.g., 70% training, 15% validation, 15% testing).\n",
        "# 2. Define the CNN Architecture\n",
        "# Choose Network Depth:\n",
        "# Decide on the number of layers and the overall depth of the network based on the complexity of the problem.\n",
        "# Design the Layers:\n",
        "# Convolutional layers to extract features.\n",
        "# Activation functions (usually ReLU) to introduce non-linearity.\n",
        "# Pooling layers (max or average pooling) for down-sampling.\n",
        "# Fully connected layers for classification or regression tasks.\n",
        "# Output layer with the appropriate activation function (e.g., softmax for classification).\n",
        "# Define Hyperparameters:\n",
        "# Kernel size (e.g.,\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 or\n",
        "# 5\n",
        "# Ã—\n",
        "# 5\n",
        "# 5Ã—5).\n",
        "# Stride and padding for convolutional operations.\n",
        "# Number of filters in each convolutional layer.\n",
        "# Learning rate, batch size, epochs, etc.\n",
        "# 3. Initialize Weights\n",
        "# Initialize the weights of the network using a suitable initialization method (e.g., Xavier initialization or He initialization) to ensure good convergence during training.\n",
        "# 4. Forward Propagation\n",
        "# For each input image, the network performs a forward pass:\n",
        "# The image is passed through each layer (convolutional, pooling, etc.).\n",
        "# The activations from each layer are computed and passed to the next layer.\n",
        "# The output of the network is obtained (e.g., class probabilities for classification tasks).\n",
        "# 5. Define the Loss Function\n",
        "# Loss Function (also called objective or cost function) measures how far the network's predictions are from the actual target values. Common loss functions include:\n",
        "# Cross-Entropy Loss for classification tasks.\n",
        "# Mean Squared Error (MSE) for regression tasks.\n",
        "# The goal is to minimize the loss function by adjusting the weights of the network.\n",
        "# 6. Backpropagation and Optimization\n",
        "# Backpropagation:\n",
        "# Compute the gradients of the loss function with respect to each weight in the network using the chain rule. This process is done by:\n",
        "# Calculating the error at the output layer.\n",
        "# Propagating the error backward through the network, updating the weights of each layer.\n",
        "# Optimization:\n",
        "# Use an optimization algorithm (e.g., Stochastic Gradient Descent (SGD), Adam, or RMSprop) to adjust the weights based on the computed gradients.\n",
        "# The learning rate determines the step size for each update.\n",
        "# 7. Training the Model\n",
        "# Training Loop:\n",
        "# Train the model in mini-batches (not the entire dataset at once) to make the optimization process more efficient.\n",
        "# For each mini-batch:\n",
        "# Perform forward propagation to get predictions.\n",
        "# Compute the loss and backpropagate to calculate gradients.\n",
        "# Update the weights using the optimization algorithm.\n",
        "# This process is repeated for multiple epochs (iterations over the entire dataset).\n",
        "# 8. Hyperparameter Tuning\n",
        "# After training the model, evaluate its performance on the validation set.\n",
        "# Adjust hyperparameters such as the learning rate, number of layers, number of filters, and batch size to improve performance.\n",
        "# Use techniques like grid search, random search, or Bayesian optimization for efficient hyperparameter tuning.\n",
        "# 9. Regularization and Avoiding Overfitting\n",
        "# Implement regularization techniques to prevent overfitting, such as:\n",
        "# Dropout: Randomly deactivating certain neurons during training.\n",
        "# L2 Regularization (weight decay): Adding a penalty term to the loss to constrain the size of the weights.\n",
        "# Early Stopping: Stop training when the validation performance starts to degrade.\n",
        "# 10. Evaluate the Model\n",
        "# After training, evaluate the performance of the CNN on the test set to check how well the model generalizes to new, unseen data.\n",
        "# Common evaluation metrics include:\n",
        "# Accuracy (for classification).\n",
        "# Precision, recall, F1-score (for classification in imbalanced datasets).\n",
        "# Mean Absolute Error (MAE) or Root Mean Squared Error (RMSE) (for regression).\n",
        "# Plot confusion matrices, precision-recall curves, or ROC curves for classification tasks.\n",
        "# 11. Fine-Tuning and Transfer Learning (optional)\n",
        "# If the model is not performing well, consider using transfer learning:\n",
        "# Pretrain the model on a large dataset (e.g., ImageNet).\n",
        "# Fine-tune the model on your specific task by retraining only the top layers or the entire model with a smaller learning rate.\n",
        "# 12. Model Deployment\n",
        "# Once the model achieves satisfactory performance, deploy it to production for inference.\n",
        "# Convert the model into a suitable format (e.g., TensorFlow SavedModel, ONNX, PyTorch model) and integrate it into an application or API.\n",
        "# Summary of Training Steps\n",
        "# Data Collection and Preprocessing: Prepare and augment the data, split into training, validation, and test sets.\n",
        "# Define CNN Architecture: Design the network, including convolutional, pooling, and fully connected layers.\n",
        "# Initialize Weights: Use appropriate initialization for efficient training.\n",
        "# Forward Propagation: Pass the input through the network and compute the output.\n",
        "# Define Loss Function: Measure the difference between predictions and true labels.\n",
        "# Backpropagation and Optimization: Update weights using gradients computed from the loss function.\n",
        "# Training: Train the model using mini-batches and multiple epochs.\n",
        "# Hyperparameter Tuning: Fine-tune hyperparameters to improve performance.\n",
        "# Regularization: Implement techniques like dropout or L2 regularization to avoid overfitting.\n",
        "# Evaluation: Assess the modelâ€™s performance on the test set.\n",
        "# Fine-Tuning/Transfer Learning: If needed, use transfer learning to leverage pretrained models.\n",
        "# Deployment: Deploy the trained model for inference in a real-world application."
      ],
      "metadata": {
        "id": "E17Y19HUhN9i"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Practical"
      ],
      "metadata": {
        "id": "vlc2amhuiBbI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.1 Implement a basic convolution operation using a filter and a 5x5 image (matrix)"
      ],
      "metadata": {
        "id": "Wc94xhdUiEQ5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "image = np.array([[1, 2, 3, 4, 5],\n",
        "                  [6, 7, 8, 9, 10],\n",
        "                  [11, 12, 13, 14, 15],\n",
        "                  [16, 17, 18, 19, 20],\n",
        "                  [21, 22, 23, 24, 25]])\n",
        "\n",
        "filter_kernel = np.array([[1, 0, -1],\n",
        "                          [1, 0, -1],\n",
        "                          [1, 0, -1]])\n",
        "\n",
        "def convolution(image, filter_kernel):\n",
        "    image_height, image_width = image.shape\n",
        "    filter_height, filter_width = filter_kernel.shape\n",
        "\n",
        "    output_height = image_height - filter_height + 1\n",
        "    output_width = image_width - filter_width + 1\n",
        "\n",
        "    output = np.zeros((output_height, output_width))\n",
        "\n",
        "    for i in range(output_height):\n",
        "        for j in range(output_width):\n",
        "            region = image[i:i+filter_height, j:j+filter_width]\n",
        "            output[i, j] = np.sum(region * filter_kernel)\n",
        "\n",
        "    return output\n",
        "\n",
        "output_image = convolution(image, filter_kernel)\n",
        "output_image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFM-Kj3_iLkQ",
        "outputId": "1517634a-4bf7-4777-9487-ca2945e57abd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-6., -6., -6.],\n",
              "       [-6., -6., -6.],\n",
              "       [-6., -6., -6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.2 Implement max pooling on a 4x4 feature map with a 2x2 window"
      ],
      "metadata": {
        "id": "jftdJ9UUj4ZU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map = np.array([[1, 3, 2, 4],\n",
        "                        [5, 6, 7, 8],\n",
        "                        [9, 10, 11, 12],\n",
        "                        [13, 14, 15, 16]])\n",
        "\n",
        "def max_pooling(feature_map, pool_size):\n",
        "    feature_height, feature_width = feature_map.shape\n",
        "    pool_height, pool_width = pool_size\n",
        "\n",
        "    output_height = feature_height // pool_height\n",
        "    output_width = feature_width // pool_width\n",
        "\n",
        "    output = np.zeros((output_height, output_width))\n",
        "\n",
        "    for i in range(output_height):\n",
        "        for j in range(output_width):\n",
        "            region = feature_map[i*pool_height:(i+1)*pool_height, j*pool_width:(j+1)*pool_width]\n",
        "            output[i, j] = np.max(region)\n",
        "\n",
        "    return output\n",
        "\n",
        "pooled_feature_map = max_pooling(feature_map, (2, 2))\n",
        "pooled_feature_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sItCWPJZkJ5s",
        "outputId": "b723285c-f118-459f-d0a0-7d086dc5c0aa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.,  8.],\n",
              "       [14., 16.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.3 Implement the ReLU activation function on a feature map?"
      ],
      "metadata": {
        "id": "aRm_hv40kRbk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_map = np.array([[-1, 2, -3, 4],\n",
        "                        [5, -6, 7, -8],\n",
        "                        [-9, 10, -11, 12]])\n",
        "\n",
        "def relu_activation(feature_map):\n",
        "    return np.maximum(0, feature_map)\n",
        "\n",
        "relu_feature_map = relu_activation(feature_map)\n",
        "relu_feature_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh3CfyW_kjdL",
        "outputId": "a71e5df4-1f15-41b5-851c-ec304ed9d771"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  2,  0,  4],\n",
              "       [ 5,  0,  7,  0],\n",
              "       [ 0, 10,  0, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.4 Create a simple CNN model with one convolutional layer and a fully connected layer, using random data"
      ],
      "metadata": {
        "id": "-esC0fdQkpOz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\n",
        "        self.fc1 = nn.Linear(1 * 6 * 6, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()\n",
        "\n",
        "input_data = torch.randn(1, 1, 8, 8)\n",
        "\n",
        "output = model(input_data)\n",
        "\n",
        "output.shape, output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub5DnD2GlGwy",
        "outputId": "257f8b4a-6c05-43b2-cfc1-93db6873ce1c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 1]), tensor([[0.2390]], grad_fn=<AddmmBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.5 Generate a synthetic dataset using random noise and train a simple CNN model on it"
      ],
      "metadata": {
        "id": "yvtXzNxklJ6S"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# It seems like I canâ€™t do more advanced data analysis right now. Please try again later. However, I can guide you through the process of generating a synthetic dataset and training a simple CNN model on it using Python and libraries like PyTorch. Here's a step-by-step approach you can follow:\n",
        "\n",
        "# 1. Generate Synthetic Dataset Using Random Noise\n",
        "# You can use random noise to create a synthetic dataset. Let's assume we want to generate images of size\n",
        "# 28\n",
        "# Ã—\n",
        "# 28\n",
        "# 28Ã—28 (similar to MNIST) with random noise as the pixel values."
      ],
      "metadata": {
        "id": "LDrwxTEDlixh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "\n",
        "class RandomNoiseDataset(Dataset):\n",
        "    def __init__(self, num_samples, image_size):\n",
        "        self.num_samples = num_samples\n",
        "        self.image_size = image_size\n",
        "        self.data = torch.randn(num_samples, 1, image_size, image_size)\n",
        "        self.labels = torch.randint(0, 2, (num_samples,))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "dataset = RandomNoiseDataset(num_samples=1000, image_size=28)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "sQUvhKrCl8Gg"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define a Simple CNN Model\n",
        "# Now, let's define a simple CNN model with one convolutional layer and one fully connected layer."
      ],
      "metadata": {
        "id": "nr_g6mMtl-7Y"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(16 * 28 * 28, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "I0JF1pNVmKYs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Train the Model\n",
        "# Now that the dataset and model are ready, we can define the loss function and optimizer, and train the model."
      ],
      "metadata": {
        "id": "QMV12XZzmNAA"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCNN()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, target) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xnbc37xDmY0f",
        "outputId": "edd3f9b3-4acc-4fa3-cb7a-468f6a726391"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Batch 0, Loss: 0.7031540274620056\n",
            "Epoch 2/5, Batch 0, Loss: 0.5233748555183411\n",
            "Epoch 3/5, Batch 0, Loss: 0.7297086715698242\n",
            "Epoch 4/5, Batch 0, Loss: 0.2698940634727478\n",
            "Epoch 5/5, Batch 0, Loss: 0.4883400797843933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Evaluate the Model\n",
        "# You can evaluate the model's performance on a separate test set or by splitting the synthetic dataset into training and validation sets."
      ],
      "metadata": {
        "id": "Q9PABYG-mdj_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in dataloader:\n",
        "        output = model(data)\n",
        "        _, predicted = torch.max(output, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqdVf6Womptv",
        "outputId": "f8e61f5d-4ef1-4fbd-e520-411f89a6929f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 93.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.6 Create a simple CNN using Keras with one convolution layer and a max-pooling layer?"
      ],
      "metadata": {
        "id": "KTuoBWvDmskf"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To create a simple Convolutional Neural Network (CNN) using Keras with one convolutional layer and a max-pooling layer, here's the implementation you can follow:\n",
        "\n",
        "# Step-by-Step Code Using Keras"
      ],
      "metadata": {
        "id": "m_jBWlPhm5Jm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "9sVQVyN0nCpP",
        "outputId": "dea38c4c-1157-4d4b-96c7-1234fe713e6c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          â”‚             \u001b[38;5;34m320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5408\u001b[0m)                â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  â”‚          \u001b[38;5;34m54,090\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5408</span>)                â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">54,090</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m54,410\u001b[0m (212.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,410</span> (212.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m54,410\u001b[0m (212.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">54,410</span> (212.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation of Layers:\n",
        "# Conv2D Layer:\n",
        "\n",
        "# The first layer is a convolutional layer that takes an input of shape (28, 28, 1) (e.g., a grayscale 28x28 image).\n",
        "# It uses 32 filters with a kernel size of\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3, and applies the ReLU activation function.\n",
        "# MaxPooling2D Layer:\n",
        "\n",
        "# The max-pooling layer reduces the spatial dimensions (height and width) by taking the maximum value from each\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2 block.\n",
        "# It reduces the image size by half.\n",
        "# Flatten Layer:\n",
        "\n",
        "# The output from the convolution and pooling layers is flattened into a 1D vector to be fed into the fully connected layer.\n",
        "# Dense Layer:\n",
        "\n",
        "# A fully connected layer with 10 units and a softmax activation function is used for classification, assuming the task involves 10 classes (such as digit classification).\n",
        "# Generating Synthetic Data for Training\n",
        "# You can create a synthetic dataset using random noise, as mentioned in the previous answer, and train this model on it. Here's an example:"
      ],
      "metadata": {
        "id": "yim47KtqnEuu"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate random data for training (e.g., 1000 images of size 28x28 with random pixel values)\n",
        "X_train = np.random.random((1000, 28, 28, 1))  # 1000 grayscale images\n",
        "y_train = np.random.randint(0, 10, 1000)  # 1000 random labels (for 10 classes)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLjJ3DznnKk-",
        "outputId": "299de0a0-6fb9-4b50-97d2-a8d965b108e6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.1019 - loss: 2.3270\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1718 - loss: 2.2746\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2554 - loss: 2.1927\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.3622 - loss: 2.0964\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.4128 - loss: 1.9630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f9d894b41f0>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.7 Write a code to add a fully connected layer after the convolution and max-pooling layers in a CNN?"
      ],
      "metadata": {
        "id": "EKuSIwpwnMs-"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To add a fully connected (dense) layer after the convolution and max-pooling layers in a CNN using Keras, here's how you can do it:\n",
        "\n",
        "# Code Example:"
      ],
      "metadata": {
        "id": "ekP0quJloHO0"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "Ja8VzDHYoPPc",
        "outputId": "5a451f44-d0f7-4741-ad1d-496c796e2fba"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          â”‚             \u001b[38;5;34m320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5408\u001b[0m)                â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚         \u001b[38;5;34m692,352\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  â”‚           \u001b[38;5;34m1,290\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5408</span>)                â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">692,352</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m693,962\u001b[0m (2.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">693,962</span> (2.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m693,962\u001b[0m (2.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">693,962</span> (2.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation of the Changes:\n",
        "# Convolution Layer (Conv2D):\n",
        "\n",
        "# We use a 3x3 kernel with 32 filters and ReLU activation to extract features from the input images (e.g., 28x28 grayscale images).\n",
        "# Max-Pooling Layer (MaxPooling2D):\n",
        "\n",
        "# A\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2 max-pooling layer reduces the size of the feature map.\n",
        "# Flatten Layer:\n",
        "\n",
        "# After the convolution and max-pooling layers, the feature maps are flattened into a 1D vector to feed into the fully connected layers.\n",
        "# Fully Connected Layer (Dense):\n",
        "\n",
        "# A fully connected layer with 128 units and ReLU activation is added to process the flattened features.\n",
        "# The number of units in the dense layer can be adjusted based on the complexity of your task.\n",
        "# Output Layer (Dense):\n",
        "\n",
        "# For multi-class classification (e.g., 10 classes), we use a dense layer with 10 units and softmax activation.\n",
        "# Example to Train the Model:"
      ],
      "metadata": {
        "id": "QneP1HGsoRDE"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.random.random((1000, 28, 28, 1))\n",
        "y_train = np.random.randint(0, 10, 1000)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qirSlDXIog1j",
        "outputId": "19c7456a-c0bd-463d-f966-6de237221da1"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.1243 - loss: 2.3200\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1425 - loss: 2.2852\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.2029 - loss: 2.2548\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.2524 - loss: 2.2214\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.2522 - loss: 2.1694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f9d86b06530>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.8 Write a code to add  batch normalization to a simple CNN model"
      ],
      "metadata": {
        "id": "l7tNNQNlojFj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To add Batch Normalization to a simple CNN model in Keras, you can use the BatchNormalization layer. Batch normalization helps improve training speed and stability by normalizing the output of the previous layer.\n",
        "\n",
        "# Here's how you can modify a simple CNN model to include batch normalization:\n",
        "\n",
        "# Code Example:"
      ],
      "metadata": {
        "id": "LohU-8cMow-b"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation=None, input_shape=(28, 28, 1)))\n",
        "\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "5fsXlet9qF7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation of Changes:\n",
        "# Batch Normalization Layer:\n",
        "\n",
        "# After the convolutional layer, we add a BatchNormalization layer. This layer normalizes the output of the convolutional layer.\n",
        "# The activation=None parameter is used in the Conv2D layer so that the batch normalization can be applied before the activation function.\n",
        "# ReLU Activation:\n",
        "\n",
        "# After the batch normalization, we apply the ReLU activation function using Activation('relu'). Batch normalization is typically applied before the activation function.\n",
        "# Rest of the Model:\n",
        "\n",
        "# The rest of the model remains the same as a simple CNN with max-pooling, a flatten layer, and a dense output layer.\n",
        "# Example to Train the Model:"
      ],
      "metadata": {
        "id": "tiVmJl7_qhiG"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.random.random((1000, 28, 28, 1))\n",
        "y_train = np.random.randint(0, 10, 1000)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32)"
      ],
      "metadata": {
        "id": "EPg6L3okqvb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.9 Write a code to add dropout regularization to a simple CNN mode?"
      ],
      "metadata": {
        "id": "Re2lUsY8q6uZ"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# To add Dropout Regularization to a simple CNN model in Keras, you can use the Dropout layer. Dropout helps prevent overfitting by randomly setting a fraction of input units to zero during training.\n",
        "\n",
        "# Hereâ€™s how to modify a simple CNN model to include dropout regularization:\n",
        "\n",
        "# Code Example:"
      ],
      "metadata": {
        "id": "Zb9yYdkrrLmu"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "7ml55-cBrRFO",
        "outputId": "e12874a8-274e-4261-a562-f44329fa670d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          â”‚             \u001b[38;5;34m320\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5408\u001b[0m)                â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚         \u001b[38;5;34m692,352\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  â”‚           \u001b[38;5;34m1,290\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5408</span>)                â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">692,352</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m693,962\u001b[0m (2.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">693,962</span> (2.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m693,962\u001b[0m (2.65 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">693,962</span> (2.65 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation of Changes:\n",
        "# Dropout after Convolutional and Pooling Layers:\n",
        "# A Dropout layer with a dropout rate of 0.25 is added after the convolutional and pooling layers. This means 25% of the neurons in the layer are randomly set to zero during each training step.\n",
        "# Dropout after Fully Connected Layer:\n",
        "# Another Dropout layer with a dropout rate of 0.5 is added after the fully connected layer (Dense layer). This means 50% of the neurons in this layer are dropped during training.\n",
        "# Rest of the Model:\n",
        "# The convolutional layer with 32 filters and ReLU activation remains the same.\n",
        "# The max-pooling and dense layers are unchanged.\n",
        "# The model is compiled using the Adam optimizer and sparse categorical cross-entropy loss for a classification task."
      ],
      "metadata": {
        "id": "fxOXawtUrl19"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.random.random((1000, 28, 28, 1))\n",
        "y_train = np.random.randint(0, 10, 1000)\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8HZ5WE9s107",
        "outputId": "5367d2aa-b8bb-447d-d66d-3b0039949f1e"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.0993 - loss: 2.4422\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0953 - loss: 2.3060\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.0895 - loss: 2.3017\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1221 - loss: 2.2938\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.1529 - loss: 2.2825\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f9d868d2b00>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.10 Write a code to print the architecture of the VGG16 model in Keras?"
      ],
      "metadata": {
        "id": "cvg4xQn7s4dC"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To print the architecture of the VGG16 model in Keras, you can easily load the pre-trained VGG16 model from Keras' applications module and then print the model summary.\n",
        "\n",
        "# Here's the code to do that:\n",
        "\n",
        "# Code Example:"
      ],
      "metadata": {
        "id": "R4Mfk4NBugMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation:\n",
        "# VGG16 Model:\n",
        "\n",
        "# VGG16 is a pre-trained convolutional neural network model that was originally developed for image classification tasks, trained on the ImageNet dataset.\n",
        "# By setting weights='imagenet', you're loading the model with pre-trained weights from ImageNet, which can be fine-tuned for specific tasks.\n",
        "# model.summary():\n",
        "\n",
        "# This method prints out the architecture of the model, including the layers, output shapes, and the number of parameters at each layer.\n",
        "# Sample Output:\n",
        "# The output will look something like this:"
      ],
      "metadata": {
        "id": "wdSpMnVQvKz-"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model: \"vgg16\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #\n",
        "=================================================================\n",
        "input_1 (InputLayer)         [(None, 224, 224, 3)]     0\n",
        "_________________________________________________________________\n",
        "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792\n",
        "_________________________________________________________________\n",
        "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928\n",
        "_________________________________________________________________\n",
        "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0\n",
        "_________________________________________________________________\n",
        "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856\n",
        "_________________________________________________________________\n",
        "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584\n",
        "_________________________________________________________________\n",
        "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0\n",
        "...\n",
        "_________________________________________________________________\n",
        "fc2 (Dense)                  (None, 4096)              33554400\n",
        "_________________________________________________________________\n",
        "predictions (Dense)          (None, 1000)              4097000\n",
        "=================================================================\n",
        "Total params: 138,357,544\n",
        "Trainable params: 138,357,544\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________"
      ],
      "metadata": {
        "id": "dTOB1xxXveId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.11 Write a code to plot the accuracy and loss graphs after training a CNN model?"
      ],
      "metadata": {
        "id": "sNLyTDvwvr1p"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To plot the accuracy and loss graphs after training a CNN model in Keras, you can utilize the matplotlib library to visualize the metrics from the training process. Keras stores the training history (including loss and accuracy) in the history object returned by the fit() function. We can then extract the loss and accuracy values and plot them.\n",
        "\n",
        "# Here's the complete code to train a CNN model and plot the accuracy and loss graphs:\n",
        "\n",
        "# Code Example:"
      ],
      "metadata": {
        "id": "E14nrID5v3KV"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "X_train = np.random.random((1000, 28, 28, 1))\n",
        "y_train = np.random.randint(0, 10, 1000)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "id": "YWNihujFwCu0",
        "outputId": "0fdcab71-87f2-407d-8e1e-de065c1277c5"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.1017 - loss: 2.3614\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1315 - loss: 2.2963\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.1915 - loss: 2.2559\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.2868 - loss: 2.1942\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.3473 - loss: 2.0870\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC9i0lEQVR4nOzdd1xWdf/H8dd1sUWmCIii4N5b0XKVuMsszVmkORqOzKaV2bA0R8MsK8vco2HjNkeKuxC35sytqKCogIKyrvP7w1/cN7lAgcN4Px+P8yi+1/ec632u+06+fq5zPsdiGIaBiIiIiIiIiIhIHrKaHUBERERERERERIoeFaVERERERERERCTPqSglIiIiIiIiIiJ5TkUpERERERERERHJcypKiYiIiIiIiIhInlNRSkRERERERERE8pyKUiIiIiIiIiIikudUlBIRERERERERkTynopSIiIiIiIiIiOQ5FaVEpMCxWCy89dZb2d7v2LFjWCwWZsyYkeOZRERERAozrb9EJDeoKCUid2TGjBlYLBYsFgsbNmy47nXDMAgMDMRisfDAAw+YkDBnLFmyBIvFQkBAADabzew4IiIiUoQV5vXXmjVrsFgs/PDDD2ZHEZE8pKKUiNwVZ2dn5s2bd9342rVriYqKwsnJyYRUOWfu3LkEBQVx5swZVq1aZXYcERERkUK//hKRokNFKRG5Kx07duT7778nLS0t0/i8efNo0KAB/v7+JiW7e4mJifzyyy+MGDGCevXqMXfuXLMj3VRiYqLZEURERCSPFOb1l4gULSpKichd6dWrF+fPn2fFihUZYykpKfzwww/07t37hvskJibywgsvEBgYiJOTE1WqVGHixIkYhpFpXnJyMs8//zwlS5bEzc2Nzp07ExUVdcNjnjp1iieffBI/Pz+cnJyoUaMG06dPv6tz++mnn7hy5QqPPvooPXv2ZNGiRVy9evW6eVevXuWtt96icuXKODs7U6pUKR555BEOHz6cMcdms/HJJ59Qq1YtnJ2dKVmyJO3bt2fLli3Arfst/LuHw1tvvYXFYmHv3r307t0bLy8vmjVrBsCuXbvo27cv5cuXx9nZGX9/f5588knOnz9/w8+sf//+BAQE4OTkRHBwMM888wwpKSkcOXIEi8XCRx99dN1+f/75JxaLhfnz52f3IxUREZEcUJjXX7dz5MgRHn30Uby9vSlWrBhNmjTht99+u27ep59+So0aNShWrBheXl40bNgw09Vlly5dYvjw4QQFBeHk5ISvry9t2rRh27ZtuZpfRDKzNzuAiBRsQUFBNG3alPnz59OhQwcAli5dSnx8PD179mTy5MmZ5huGQefOnVm9ejX9+/enbt26LF++nJdeeolTp05lKoIMGDCAOXPm0Lt3b+655x5WrVpFp06drssQExNDkyZNsFgsDBkyhJIlS7J06VL69+9PQkICw4cPv6Nzmzt3Lvfddx/+/v707NmTV199lf/85z88+uijGXPS09N54IEHCA8Pp2fPnjz33HNcunSJFStWsHv3bipUqABA//79mTFjBh06dGDAgAGkpaWxfv16Nm7cSMOGDe8o36OPPkqlSpV4//33MxaUK1as4MiRI/Tr1w9/f3/27NnDV199xZ49e9i4cSMWiwWA06dP07hxY+Li4hg0aBBVq1bl1KlT/PDDDyQlJVG+fHnuvfde5s6dy/PPP3/d5+Lm5sZDDz10R7lFRETk7hTm9detxMTEcM8995CUlMSwYcMoUaIEM2fOpHPnzvzwww88/PDDAEybNo1hw4bRrVs3nnvuOa5evcquXbuIjIzMKNo9/fTT/PDDDwwZMoTq1atz/vx5NmzYwL59+6hfv36OZxeRmzBERO7At99+awDG5s2bjSlTphhubm5GUlKSYRiG8eijjxr33XefYRiGUa5cOaNTp04Z+/38888GYIwZMybT8bp162ZYLBbj0KFDhmEYxo4dOwzAePbZZzPN6927twEYo0ePzhjr37+/UapUKSM2NjbT3J49exoeHh4ZuY4ePWoAxrfffnvb84uJiTHs7e2NadOmZYzdc889xkMPPZRp3vTp0w3A+PDDD687hs1mMwzDMFatWmUAxrBhw24651bZ/n2+o0ePNgCjV69e183951z/1/z58w3AWLduXcZYWFiYYbVajc2bN98005dffmkAxr59+zJeS0lJMXx8fIwnnnjiuv1EREQkdxXm9dfq1asNwPj+++9vOmf48OEGYKxfvz5j7NKlS0ZwcLARFBRkpKenG4ZhGA899JBRo0aNW76fh4eHMXjw4FvOEZHcp9v3ROSude/enStXrrB48WIuXbrE4sWLb3rp+JIlS7Czs2PYsGGZxl944QUMw2Dp0qUZ84Dr5v37WzfDMPjxxx958MEHMQyD2NjYjK1du3bEx8ff0WXYCxYswGq10rVr14yxXr16sXTpUi5evJgx9uOPP+Lj48PQoUOvO8Y/VyX9+OOPWCwWRo8efdM5d+Lpp5++bszFxSXj369evUpsbCxNmjQByPgcbDYbP//8Mw8++OANr9L6J1P37t1xdnbO1Etr+fLlxMbG8thjj91xbhEREbl7hXH9dTtLliyhcePGGW0LAIoXL86gQYM4duwYe/fuBcDT05OoqCg2b95802N5enoSGRnJ6dOnczyniGSdilIictdKlixJaGgo8+bNY9GiRaSnp9OtW7cbzj1+/DgBAQG4ubllGq9WrVrG6//802q1Ztz+9o8qVapk+vncuXPExcXx1VdfUbJkyUxbv379ADh79my2z2nOnDk0btyY8+fPc+jQIQ4dOkS9evVISUnh+++/z5h3+PBhqlSpgr39ze+GPnz4MAEBAXh7e2c7x60EBwdfN3bhwgWee+45/Pz8cHFxoWTJkhnz4uPjgWufWUJCAjVr1rzl8T09PXnwwQcz9V+YO3cupUuX5v7778/BMxEREZHsKozrr9s5fvz4dVludB6vvPIKxYsXp3HjxlSqVInBgwfzxx9/ZNpn/Pjx7N69m8DAQBo3bsxbb73FkSNHcjyziNyaekqJSI7o3bs3AwcOJDo6mg4dOuDp6Zkn72uz2QB47LHHeOKJJ244p3bt2tk65sGDBzO+WatUqdJ1r8+dO5dBgwZlM+mt3eyKqfT09Jvu879XRf2je/fu/Pnnn7z00kvUrVuX4sWLY7PZaN++fcZnlR1hYWF8//33/Pnnn9SqVYtff/2VZ599FqtV32mIiIiYrTCtv3JStWrVOHDgAIsXL2bZsmX8+OOPfP7557z55pu8/fbbwLU1U/Pmzfnpp5/4/fffmTBhAh988AGLFi3K6NMlIrlPRSkRyREPP/wwTz31FBs3bmThwoU3nVeuXDlWrlzJpUuXMn1bt3///ozX//mnzWbLuBLpHwcOHMh0vH+eDJOenk5oaGiOnMvcuXNxcHBg9uzZ2NnZZXptw4YNTJ48mRMnTlC2bFkqVKhAZGQkqampODg43PB4FSpUYPny5Vy4cOGmV0t5eXkBEBcXl2n8n2/8suLixYuEh4fz9ttv8+abb2aMHzx4MNO8kiVL4u7uzu7du297zPbt21OyZEnmzp1LSEgISUlJPP7441nOJCIiIrmnMK2/sqJcuXLXZYHrzwPA1dWVHj160KNHD1JSUnjkkUd47733GDlyJM7OzgCUKlWKZ599lmeffZazZ89Sv3593nvvPRWlRPKQvuoWkRxRvHhxpk6dyltvvcWDDz5403kdO3YkPT2dKVOmZBr/6KOPsFgsGYuAf/7576fHfPzxx5l+trOzo2vXrvz44483LLKcO3cu2+cyd+5cmjdvTo8ePejWrVum7aWXXgJg/vz5AHTt2pXY2NjrzgfIeCJe165dMQwj45u5G81xd3fHx8eHdevWZXr9888/z3Lufwpoxr8e7fzvz8xqtdKlSxf+85//sGXLlptmArC3t6dXr1589913zJgxg1q1apn6zaeIiIj8V2Faf2VFx44d2bRpExERERljiYmJfPXVVwQFBVG9enUAzp8/n2k/R0dHqlevjmEYpKamkp6entHW4B++vr4EBASQnJycK9lF5MZ0pZSI5JibXb79vx588EHuu+8+Xn/9dY4dO0adOnX4/fff+eWXXxg+fHhGD4O6devSq1cvPv/8c+Lj47nnnnsIDw/n0KFD1x1z3LhxrF69mpCQEAYOHEj16tW5cOEC27ZtY+XKlVy4cCHL5xAZGcmhQ4cYMmTIDV8vXbo09evXZ+7cubzyyiuEhYUxa9YsRowYwaZNm2jevDmJiYmsXLmSZ599loceeoj77ruPxx9/nMmTJ3Pw4MGMW+nWr1/Pfffdl/FeAwYMYNy4cQwYMICGDRuybt06/v777yxnd3d3p0WLFowfP57U1FRKly7N77//ztGjR6+b+/777/P777/TsmVLBg0aRLVq1Thz5gzff/89GzZsyHT5f1hYGJMnT2b16tV88MEHWc4jIiIiua8wrL/+148//phx5dO/z/PVV19l/vz5dOjQgWHDhuHt7c3MmTM5evQoP/74Y0Z7gbZt2+Lv78+9996Ln58f+/btY8qUKXTq1Ak3Nzfi4uIoU6YM3bp1o06dOhQvXpyVK1eyefNmJk2adEe5ReQOmfPQPxEp6P73kcS38u9HEhvGtUf3Pv/880ZAQIDh4OBgVKpUyZgwYYJhs9kyzbty5YoxbNgwo0SJEoarq6vx4IMPGidPnrzukcSGYRgxMTHG4MGDjcDAQMPBwcHw9/c3WrdubXz11VcZc7LySOKhQ4cagHH48OGbznnrrbcMwNi5c6dhGIaRlJRkvP7660ZwcHDGe3fr1i3TMdLS0owJEyYYVatWNRwdHY2SJUsaHTp0MLZu3ZoxJykpyejfv7/h4eFhuLm5Gd27dzfOnj173fmOHj3aAIxz585dly0qKsp4+OGHDU9PT8PDw8N49NFHjdOnT9/wMzt+/LgRFhZmlCxZ0nBycjLKly9vDB482EhOTr7uuDVq1DCsVqsRFRV1089FREREcldhXX8ZhmGsXr3aAG66rV+/3jAMwzh8+LDRrVs3w9PT03B2djYaN25sLF68ONOxvvzyS6NFixZGiRIlDCcnJ6NChQrGSy+9ZMTHxxuGYRjJycnGSy+9ZNSpU8dwc3MzXF1djTp16hiff/75LTOKSM6zGMa/7vMQERH5l3r16uHt7U14eLjZUUREREREpJBQTykREbmlLVu2sGPHDsLCwsyOIiIiIiIihYiulBIRkRvavXs3W7duZdKkScTGxnLkyJGMp9WIiIiIiIjcLV0pJSIiN/TDDz/Qr18/UlNTmT9/vgpSIiIiIiKSo3SllIiIiIiIiIiI5DldKSUiIiIiIiIiInlORSkRERGRAm7s2LE0atQINzc3fH196dKlCwcOHLjlPosWLaJhw4Z4enri6upK3bp1mT17dqY5ffv2xWKxZNrat2+fm6ciIiIiRYi92QEKKpvNxunTp3Fzc8NisZgdR0RERPKIYRhcunSJgIAArNb88f3e2rVrGTx4MI0aNSItLY3XXnuNtm3bsnfvXlxdXW+4j7e3N6+//jpVq1bF0dGRxYsX069fP3x9fWnXrl3GvPbt2/Ptt99m/Ozk5JTlXFoviYiIFE1ZXS+pp9QdioqKIjAw0OwYIiIiYpKTJ09SpkwZs2Pc0Llz5/D19WXt2rW0aNEiy/vVr1+fTp068e677wLXrpSKi4vj559/vqMcWi+JiIgUbbdbL+lKqTvk5uYGXPuA3d3dTU4jIiIieSUhIYHAwMCMtUB+FB8fD1y7GiorDMNg1apVHDhwgA8++CDTa2vWrMHX1xcvLy/uv/9+xowZQ4kSJbJ0XK2XREREiqasrpdUlLpD/1yC7u7urkWWiIhIEZRfb0ez2WwMHz6ce++9l5o1a95ybnx8PKVLlyY5ORk7Ozs+//xz2rRpk/F6+/bteeSRRwgODubw4cO89tprdOjQgYiICOzs7K47XnJyMsnJyRk/X7p0CdB6SUREpKi63XpJRSkRERGRQmTw4MHs3r2bDRs23Haum5sbO3bs4PLly4SHhzNixAjKly9Pq1atAOjZs2fG3Fq1alG7dm0qVKjAmjVraN269XXHGzt2LG+//XaOnYuIiIgUbvmjO6eIiIiI3LUhQ4awePFiVq9enaV+V1arlYoVK1K3bl1eeOEFunXrxtixY286v3z58vj4+HDo0KEbvj5y5Eji4+MztpMnT97xuYiIiEjhpyulRERERAo4wzAYOnQoP/30E2vWrCE4OPiOjmOz2TLdfvdvUVFRnD9/nlKlSt3wdScnp2w9nU9ERESKNhWlRERERAq4wYMHM2/ePH755Rfc3NyIjo4GwMPDAxcXFwDCwsIoXbp0xpVQY8eOpWHDhlSoUIHk5GSWLFnC7NmzmTp1KgCXL1/m7bffpmvXrvj7+3P48GFefvllKlasSLt27cw5URERESlUVJQSERERKeD+KST90wvqH99++y19+/YF4MSJE1it/+3ckJiYyLPPPktUVBQuLi5UrVqVOXPm0KNHDwDs7OzYtWsXM2fOJC4ujoCAANq2bcu7776rq6FEREQkR1gMwzDMDlEQJSQk4OHhQXx8vJ4mIyIiUoRoDZB1+qxERESKpqyuAdToXERERERERERE8pyKUiIiIiIiIiIikudUlBIRERERERERkTynopSIiIiIiIiIiOQ5FaVERERERERERCTPqSglIiIiIiIiIiJ5TkUpERERERERERHJcypKiYiIiIiIiIhInlNRSkRERERERERE8pyKUiIiIiIiIiIikudUlBIRERERERERkTynopSIiIiIiIiIiOQ5FaVERESk0Em3GaTbDLNjSC5KS7eRnJZudgwRERG5CypKiYiISKFxJSWd2RuP03rSGhbvOm12HMlFn4Qf5JHP/+RobKLZUUREROQO2ZsdQERERORunb+czKyI48zeeJwLiSkALNh0kofqljY5meSGhKupzN90ktjLyTwweT3vP1JL/1uLiIgUQCpKiYiISIF15Nxlvt5wlB+3RpGcZgOgjJcLA5oF82jDQJPTSW5xd3bgt2HNGDZ/O5FHL/Dcgh38cSiWtzrXoJijlrciIiIFhX5ri4iISIGz5dgFvlp3hBX7YjD+v3VU7TIeDGpRnvY1/LG3U4eCws7P3Zl5A5swOfwgk1cd5LstUWw/EcdnfepT2c/N7HgiIiKSBSpKiYiISIGQbjNYsTear9YdYduJuIzx1lV9GdSiPI2DvbFYLOYFlDxnZ7XwfJvKhJT3ZviCHRw8e5nOUzbw1oM16NEoUP9/EBERyedUlBIREZF87UpKOj9si+Kb9Uc4dj4JAEc7Kw/XK83AFsFU9NVVMUXdPRV8WPJcc174bidr/z7Hq4v+4o/D53n/4Zq4OTuYHU9ERERuIl9c2/7ZZ58RFBSEs7MzISEhbNq06aZzFy1aRMOGDfH09MTV1ZW6desye/bsTHMMw+DNN9+kVKlSuLi4EBoaysGDBzPNuXDhAn369MHd3R1PT0/69+/P5cuXc+X8REREJPtiLyfz4Yq/uWdcOKN+3s2x80l4uDgw5L6KbHj1Pj7oVlsFKcngU9yJb/s2YmSHqthbLfxn52ke+HQDf0XFmx1NREREbsL0otTChQsZMWIEo0ePZtu2bdSpU4d27dpx9uzZG8739vbm9ddfJyIigl27dtGvXz/69evH8uXLM+aMHz+eyZMn88UXXxAZGYmrqyvt2rXj6tWrGXP69OnDnj17WLFiBYsXL2bdunUMGjQo189XREREbu3Iucu89tNf3DtuFZPDD3IxKZUyXi689WB1Ikbez4vtquDr5mx2TMmHrFYLT7WswMKnmlLa04Xj55N4ZOoffPvHUYx/mo+JiIhIvmExTP4NHRISQqNGjZgyZQoANpuNwMBAhg4dyquvvpqlY9SvX59OnTrx7rvvYhgGAQEBvPDCC7z44osAxMfH4+fnx4wZM+jZsyf79u2jevXqbN68mYYNGwKwbNkyOnbsSFRUFAEBAbd9z4SEBDw8PIiPj8fd3f0Oz15ERET+UVCal2sNkHVmflbxSam8/ONOlu+JAaBNdT8mdKuNZzHHPM0hIiJSFGV1DWDq6i4lJYWtW7cSGhqaMWa1WgkNDSUiIuK2+xuGQXh4OAcOHKBFixYAHD16lOjo6EzH9PDwICQkJOOYEREReHp6ZhSkAEJDQ7FarURGRt7wvZKTk0lISMi0iYiIyN1Jtxks232GRz7/g25fRPD73msFqdBqviwc1IRfBt/LA7UD8k1BSgoOj2IOfPFYA97uXANHOysr9sbQ8ZP1bD1+wexoIiIi8v9MbXQeGxtLeno6fn5+mcb9/PzYv3//TfeLj4+ndOnSJCcnY2dnx+eff06bNm0AiI6OzjjGv4/5z2vR0dH4+vpmet3e3h5vb++MOf82duxY3n777eydoIiIiNzQlZR0fth6kq83HOX4/zQvf6R+aQY0V/NyyRkWi4Un7gmiQTkvhszbxrHzSXT/ciMvtK3M0y0qYLXq6XwiIiJmKpBP33Nzc2PHjh1cvnyZ8PBwRowYQfny5WnVqlWuvefIkSMZMWJExs8JCQkEBgbm2vuJiIgURrGXk5kVcZzZEce4mJQKgIeLA483KUfYPeXUK0pyRc3SHiwe1pw3fvqLn3ecZvyyA0QcPs+H3etS0s3J7HgiIiJFlqlFKR8fH+zs7IiJick0HhMTg7+//033s1qtVKxYEYC6deuyb98+xo4dS6tWrTL2i4mJoVSpUpmOWbduXQD8/f2va6SelpbGhQsXbvq+Tk5OODlp0SIiInInjpy7zNcbjvLj1iiS02wABHq70P/eYLo3CqSYY4H8nkwKkOJO9nzUoy73VPThzV92s/5gLB0nr+eT/x8TERGRvGdqgwZHR0caNGhAeHh4xpjNZiM8PJymTZtm+Tg2m43k5GQAgoOD8ff3z3TMhIQEIiMjM47ZtGlT4uLi2Lp1a8acVatWYbPZCAkJudvTEhEREa71ftxy7AKDZm2h9YdrmRd5guQ0G3XKePBZ7/qsfqEVfe8NVkFK8ozFYqF7w0B+HdKMyn7FOXcpmT7fRPLh7wdIS7eZHU9ERKTIMX0VOGLECJ544gkaNmxI48aN+fjjj0lMTKRfv34AhIWFUbp0acaOHQtc6+3UsGFDKlSoQHJyMkuWLGH27NlMnToVuLbYGD58OGPGjKFSpUoEBwczatQoAgIC6NKlCwDVqlWjffv2DBw4kC+++ILU1FSGDBlCz549s/TkPREREbm5dJvB73ui+Wr9EbafiMsYD63my8Dm5Wkc7I3Fol4+Yp7Kfm78MrgZ7yzew/xNJ5m86hAbj1zgk151KeXhYnY8ERGRIsP0olSPHj04d+4cb775JtHR0dStW5dly5ZlNCo/ceIEVut/L+hKTEzk2WefJSoqChcXF6pWrcqcOXPo0aNHxpyXX36ZxMREBg0aRFxcHM2aNWPZsmU4O/+3T8XcuXMZMmQIrVu3xmq10rVrVyZPnpx3Jy4iIlLIqHm5FCQujnaMfaQ2TSv48Nqiv9h07AIdP1nPpO51uL+q3+0PICIiInfNYhiGYXaIgighIQEPDw/i4+Nxd3c3O46IiIhpilrzcq0Bsq6gfFbHYhMZMn8bu08lADCweTAvtauKo72pnS5EREQKrKyuAUy/UkpEREQKpiPnLjNt/VF+3BZFyv80Lx/QrDyPNiyjXlFSYAT5uPLjM/cwbul+vv3jGNPWH2XTsYtM6VWPQO9iZscTEREptLRaFBERkSwzDIOtxy/y5bojrNwXwz/XW9cp48GgFhVoV8MPeztdXSIFj5O9HaMfrEHT8iV46Ydd7DwZR8fJ6/mga2061ip1+wOIiIhItqkoJSIiIrel5uVSVLSt4U+N0h4Mm7+drccv8uzcbTzWpCxvdKqOs4Od2fFEREQKFRWlRERE5KZu3by8PBV9i5ucUCTnlfZ0YcGgJny04m8+X3OYORtPsOXYRab0rq//z4uIiOQgFaVERETkOkWtebnIvznYWXm5fVWalC/BiO92sD/6Ep2nbODdh2rStUEZs+OJiIgUCipKiYiISAY1LxfJrEXlkiwZ1pzhC3fw5+HzvPD9Tv48fJ53HqqBq5P+exAREbkb+k0qIiJSxN2ueXn7mv7YWdUvSoouX3dnZvcP4fPVh/ho5d/8uC2KHSev3c5XrdTNH3MtIiIit6ailIiISBGl5uUiWWdntTC0dSUaB3szbMF2Dp9L5KHP/uDNB6rTJ6Ss/lsRERG5AypKiYiIFDE3bF5ub6Vr/dL0b6bm5SK3ElK+BEufa8GL3+9k1f6zvPHzbiIOn2ds11q4OzuYHU9ERKRAUVFKRESkiLhR83LPYv/fvLxpECXdnExOKFIweLs68nVYQ6b/cZRxS/fz219n2HUqjim96lMn0NPseCIiIgWGilIiIiKF3OFzl/lazctFcpTVamFA8/I0DPJm6PxtnLxwhW5f/Mkr7avSv1mwbucTERHJAq1CRURECiHDMNhy/CJf/bt5eaAnT7UoT7saal4ukhPqBnqyeGhzRi7axZK/ohnz2z4iDp9n4qN18HJ1NDueiIhIvqailIiISCFy8+blfgxqUZ5GQV66gkMkh3m4OPBZ7/rMjTzBO4v3Er7/LB0nr+eTnvVoHOxtdjwREZF8S0UpERGRQkDNy0XMZbFYeKxJOeqX9WLIvG0ciU2k51cRPB9amWfvq6grE0VERG5ARSkREZECLPZyMrP+PMbsjcfVvFwkH6ge4M5/hjZj1C+7WbTtFJNW/M3Go+f5qEddfN2czY4nIiKSr6goJSIiUgDdqHl5We9iDGgeTLcGal4uYiZXJ3s+7F6Xeyr4MOrn3fxx6DwdP1nPRz3q0rxSSbPjiYiI5BtasYqIiBQQal4uUrB0a1CGuoGeDJm3jf3RlwibvolnWlZgRJvK2NtZzY4nIiJiOhWlRERE8jk1LxcpuCr6Fufnwffy7uK9zI08wedrDrPp6AUm96pHgKeL2fFERERMpaKUiIhIPnUlJZ3vt57k6/VHOXFBzctFCipnBzvee7gW91Tw4dUfd7Hl+EU6Tl7PhG51aFPdz+x4IiIiplFRSkREJJ9R83KRwqlT7VLUKu3BkPnb2BUVz8BZW+h3bxCvdqiKk72d2fFERETynIpSIiIi+YSal4sUfmVLFOOHp+9h/LL9fL3hKN/+cYwtxy4ypXc9ypVwNTueiIhIntLqVkRExERqXi5S9DjaW3njgeo0rVCCF77fyV+n4uk0eQPvP1KLznUCzI4nIiKSZ1SUEhERMcE/zcu/XHeEHSfjMsbVvFyk6GhdzY+lzzVn2PztbD52kWHztxNxOJY3H6iBi6Nu5xMRkcJPRSkREZE8dPPm5WXo3yxYzctFiphSHi7MH9iET8IPMmX1IeZvOsm243FM6V2PSn5uZscTERHJVSpKiYiI5IFzl5KZHXF98/KwJuV4XM3LRYo0ezsrL7StQkhwCYYv3MGBmEt0nvIHbz9Ug0cblNFVkyIiUmipKCUiIpKL1LxcRLKqWSUflj7XnBHf7WD9wVhe/mEXfx6KZczDtSjupD8rRESk8NFvNxERkRz2T/PyL9dea17+DzUvF5HbKenmxMx+jZm69jAfrvibn3ecZmdUPFN616NGgIfZ8URERHKUilIiIiI55FbNy59qWZ6G5dS8XERuz2q1MPi+ioQEezNs/naOxiby8Gd/8sYD1Xi8STn9OSIiIoWGilIiIiJ3KSkljR+2Rt2wefmA5sFUKKnm5SKSfQ2DvPltWHNe+mEnK/ed5c1f9vDHoVjGd62DRzEHs+OJiIjcNRWlRERE7tA/zctnbTxOnJqXi0gu8HJ1ZFpYQ6b/cYxxS/exfE8Mu0+t59Pe9ahf1svseCIiIndFRSkREZFsUvNyEclLFouF/s2CaRTkxZB52zlxIYnuX0TwUrsqDGxeHqt61ImISAGlVbOIiEgWGIbB5mMX+Wpd5ubldf+/eXlbNS8XkVxWu4wni4c147VFf7F41xnGLt1PxJHzTHq0DiWK68pMEREpeFSUEhERuYV0m8HyPdF89T/Nyy2Wa83LB7VQ83IRyVvuzg582qse91b04a1f97DmwDk6Tl7Pxz3q0bRCCbPjiYiIZIuKUiIiIjeg5uUikl9ZLBZ6NS5LvbKeDJm3nUNnL9Pn640Ma12JofdX0lWbIiJSYKgoJSIi8j9u1bw87J4gfHSLjIjkE1X93fl1yL2M/mUP32+N4uOVB9l45Dyf9KyHn7uz2fFERERuS0UpERER/mlefoQft53KaF5erkQxBjQLpqual4tIPlXM0Z4Jj9bhnooleP2n3Ww8coEOn6znw+51aFXF1+x4IiIit6QVtoiIFGnpNoOXftjJom2nMsbUvFxECpqH65WhTplrt/PtPZNA328381TL8rzYtgoOdlaz44mIiNyQfkOJiEiR9t2WkyzadgqLBdpU9+P7p5vy07P30KFWKRWkRKRAKV+yOIuevYewpuUA+HLtEbp/GcHJ/++LJyIikt+oKCUiIkXW5eQ0Jv1+AIA3OlVnWlhDGgV562l6IlJgOTvY8c5DNfnisfq4Oduz/UQcnSavZ9nuaLOjiYiIXEdFKRERKbKmrjlE7OUUgn1cebxJObPjiIjkmPY1S7FkWHPqBnqScDWNp+dsZfQvu7mamm52NBERkQwqSomISJEUdTGJaeuPAjCyQ1Uc7fUrUUQKl0DvYnz/dFOealEegJkRx3nk8z85cu6yyclERESu0QpcRESKpAnLD5CSZqNJeW/aVPczO46ISK5wsLMysmM1vu3XCG9XR/aeSeDBTzfw8/ZTt99ZREQkl6koJSIiRc72Exf5ZcdpLJZrvaTUQ0pECrv7qviyZFhzQoK9SUxJZ/jCHbz8w06SUtLMjiYiIkWYilIiIlKkGIbBmN/2AdC1fhlqlvYwOZGISN7w93Bm3sAmPNe6EhYLfLclioem/MGB6EtmRxMRkSJKRSkRESlSlvwVzdbjF3FxsOPFtlXMjiMikqfsrBaeb1OZuQNC8HVz4uDZy3SesoH5m05gGIbZ8UREpIhRUUpERIqMq6npjFt27Sqpp1qWx9/D2eREIiLmuKeCD0uea06LyiVJTrMxctFfDFuwg0tXU82OJiIiRYiKUiIiUmTM/PMYJy9cwc/diUH//zQqEZGiyqe4EzP6NuLVDlWxs1r4z87TPPDpBv6Kijc7moiIFBH5oij12WefERQUhLOzMyEhIWzatOmmc6dNm0bz5s3x8vLCy8uL0NDQ6+ZbLJYbbhMmTMiYExQUdN3r48aNy7VzFBERc52/nMyUVYcAeKldVYo52pucSETEfFarhadbVuC7p5pS2tOF4+eTeGTqH0zfcFS384mISK4zvSi1cOFCRowYwejRo9m2bRt16tShXbt2nD179obz16xZQ69evVi9ejUREREEBgbStm1bTp3672Ntz5w5k2mbPn06FouFrl27ZjrWO++8k2ne0KFDc/VcRUTEPB+vPMil5DRqlnbnkXqlzY4jIpKvNCjnxZJhzWlXw4/UdIN3Fu9l4KytxCWlmB1NREQKMYth8lcgISEhNGrUiClTpgBgs9kIDAxk6NChvPrqq7fdPz09HS8vL6ZMmUJYWNgN53Tp0oVLly4RHh6eMRYUFMTw4cMZPnz4HeVOSEjAw8OD+Ph43N3d7+gYIiKSNw6dvUS7j9eTbjOYP7AJTSuUMDuSFGBaA2SdPquCxzAMZkUc573f9pGSbiPAw5lPe9ejQTlvs6OJiEgBktU1gKlXSqWkpLB161ZCQ0MzxqxWK6GhoURERGTpGElJSaSmpuLtfeNflDExMfz222/079//utfGjRtHiRIlqFevHhMmTCAtLe2m75OcnExCQkKmTURECob3l+wn3WbQtrqfClIiIrdgsVh44p4gFj17D0ElinE6/irdv9zIZ6sPYbPpdj4REclZphalYmNjSU9Px8/PL9O4n58f0dHRWTrGK6+8QkBAQKbC1v+aOXMmbm5uPPLII5nGhw0bxoIFC1i9ejVPPfUU77//Pi+//PJN32fs2LF4eHhkbIGBgVnKJyIi5lp/8Byr9p/F3mphZMdqZscRyRVjx46lUaNGuLm54evrS5cuXThw4MAt91m0aBENGzbE09MTV1dX6taty+zZszPNMQyDN998k1KlSuHi4kJoaCgHDx7MzVORfKJmaQ8WD2vOQ3UDSLcZTFh+gCe+3cS5S8lmRxMRkULE9J5Sd2PcuHEsWLCAn376CWfnGz/We/r06fTp0+e610eMGEGrVq2oXbs2Tz/9NJMmTeLTTz8lOfnGv2hHjhxJfHx8xnby5MkcPx8REclZ6TaD937bB0BY0yCCfVxNTiSSO9auXcvgwYPZuHEjK1asIDU1lbZt25KYmHjTfby9vXn99deJiIhg165d9OvXj379+rF8+fKMOePHj2fy5Ml88cUXREZG4urqSrt27bh69WpenJaYrLiTPR/3qMv4rrVxdrCy/mAsHSev549DsWZHExGRQsLURw/5+PhgZ2dHTExMpvGYmBj8/f1vue/EiRMZN24cK1eupHbt2jecs379eg4cOMDChQtvmyUkJIS0tDSOHTtGlSpVrnvdyckJJyen2x5HRETyj++3nGR/9CU8XBwY1rqi2XFEcs2yZcsy/Txjxgx8fX3ZunUrLVq0uOE+rVq1yvTzc889x8yZM9mwYQPt2rXDMAw+/vhj3njjDR566CEAZs2ahZ+fHz///DM9e/bMlXOR/MVisdC9USB1y3oyZN42/o65zGPfRDLkvoo817oS9nYF+jtuERExmam/RRwdHWnQoEGmBuQ2m43w8HCaNm160/3Gjx/Pu+++y7Jly2jYsOFN533zzTc0aNCAOnXq3DbLjh07sFqt+Pr6Zu8kREQkX7qcnMbE3/8G4LnWlfAs5mhyIpG8Ex8fD3DTnpv/ZhgG4eHhHDhwIKOIdfToUaKjozO1SPDw8CAkJOSmvT/Vg7Pwquznxi+Dm9GrcSCGAZ+uOkTvaZGcib9idjQRESnATP9qY8SIEUybNo2ZM2eyb98+nnnmGRITE+nXrx8AYWFhjBw5MmP+Bx98wKhRo5g+fTpBQUFER0cTHR3N5cuXMx03ISGB77//ngEDBlz3nhEREXz88cfs3LmTI0eOMHfuXJ5//nkee+wxvLy8cveERUQkT3yx5jCxl5MJ9nHlsSblzI4jkmdsNhvDhw/n3nvvpWbNmrecGx8fT/HixXF0dKRTp058+umntGnTBiCjv2d2en+qB2fh5uJox9hHavNJz7q4Otqx6dgFOn6ynlX7Y26/s4iIyA2YevseQI8ePTh37hxvvvkm0dHR1K1bl2XLlmUsgE6cOIHV+t/a2dSpU0lJSaFbt26ZjjN69GjeeuutjJ8XLFiAYRj06tXruvd0cnJiwYIFvPXWWyQnJxMcHMzzzz/PiBEjcuckRUQkT52Ku8K09UcAGNmhKo72pn8HI5JnBg8ezO7du9mwYcNt57q5ubFjxw4uX75MeHg4I0aMoHz58tfd2pdVI0eOzLSeSkhIUGGqEHqobmnqlPFkyPxt7D6VwJMztjCgWTAvt9eftyIikj0WwzD0bNc7kJCQgIeHB/Hx8bi7u5sdR0RE/sfwBdv5ecdpmpT3Zv7AJlgsFrMjSSGSn9cAQ4YM4ZdffmHdunUEBwdne/8BAwZw8uRJli9fzpEjR6hQoQLbt2+nbt26GXNatmxJ3bp1+eSTT257vPz8WcndS05LZ+yS/cz48xgAdcp48Gmv+pQtUczcYCIiYrqsrgH0VYaIiBQqO07G8fOO01gs8Ean6ipISZFgGAZDhgzhp59+YtWqVXdUkIJrt/798yTi4OBg/P39M/X+TEhIIDIy8pa9P6XocLK3463ONfjy8QZ4uDiwMyqeTpPX89uuM2ZHExGRAsL02/dERERyimEYjFm8F4BH6pWhZmkPkxOJ5I3Bgwczb948fvnlF9zc3DJ6Pnl4eODi4gJc69NZunRpxo4dC1zr/9SwYUMqVKhAcnIyS5YsYfbs2UydOhW49tS14cOHM2bMGCpVqkRwcDCjRo0iICCALl26mHKekj+1q+FPzdIeDJu/na3HLzJ43jb+PFyWUQ9Ux9nBzux4IiKSj6koJSIihcbS3dFsOX4RZwcrL7WrYnYckTzzTyHp372gvv32W/r27Qtc36czMTGRZ599lqioKFxcXKhatSpz5syhR48eGXNefvllEhMTGTRoEHFxcTRr1oxly5bh7Oyc6+ckBUtpTxcWDGrChyv+Zuqaw8yNPMHW4xeZ0rs+FX2Lmx1PRETyKfWUukPqkSAikr8kp6UT+uFaTl64wnOtK/F8m8pmR5JCSmuArNNnVTSt/fscIxbu4HxiCi4OdozpUpOuDcqYHUtERPKQekqJiEiRMvPPY5y8cAVfNyeealne7DgiIkVWy8olWfpcc+6pUIIrqem88P1ORny3g8TkNLOjiYhIPqOilIiIFHjnLyfzafghAF5qV4Vijro7XUTETL7uzszuH8KINpWxWmDRtlM8OGUD+84kmB1NRETyERWlRESkwPsk/CCXktOoEeBO1/q6RUREJD+ws1oY1roS8wc2wc/diSPnEnnosz+Ys/E46iAiIiKgopSIiBRwh85eYm7kCQBe71QNq9ViciIREflfIeVLsPS5Ftxf1ZeUNBtv/LybwfO2EX8l1exoIiJiMhWlRESkQHt/yX7SbQZtqvtxTwUfs+OIiMgNeLs68nVYQ17vWA17q4Ulf0XTafJ6dpyMMzuaiIiYSEUpEREpsNYfPMeq/Wext1oY2aGq2XFEROQWrFYLA1uU5/unm1LGy4Woi1foNvVPvl5/RLfziYgUUSpKiYhIgZRuM3jvt30APN60HOVLFjc5kYiIZEW9sl78Nqw5HWv5k2YzGPPbPvrP3MKFxBSzo4mISB5TUUpERAqk77ecZH/0JTxcHHiudSWz44iISDZ4uDjwWe/6vNulJo72VlbtP0vHT9bz5+FYs6OJiEgeUlFKREQKnMvJaUz8/W8AhrWuhGcxR5MTiYhIdlksFh5vUo6fn72X8j6uRCdcpfe0SIYv2M7ZhKtmxxMRkTygopSIiBQ4X649TOzlZIJKFOPxJuXMjiMiIneheoA7/xnajD4hZbFY4Ocdp7l/0lq+Xn+E1HSb2fFERCQXqSglIiIFyum4K3y17ggAIztWw9Fev8pERAo6Vyd73nu4Fr8Mvpc6gZ5cTk5jzG/76PjJeiIOnzc7noiI5BKt5EVEpECZsPwAyWk2QoK9aVvdz+w4IiKSg2qX8eSnZ+7hg6618HZ15ODZy/SatpGh87cTHa9b+kREChsVpUREpMDYeTKOn7afwmKBUQ9Ux2KxmB1JRERymNVqoUejsqx6oSWPNymH1QL/2Xma1pPW8OXaw6Sk6ZY+EZHCQkUpEREpEAzDYMxvewF4pF4Zapb2MDmRiIjkJs9ijrzbpSa/DmlG/bKeJKakM3bpfjp8so4/DukpfSIihYGKUiIiUiAs2x3N5mMXcXaw8lK7KmbHERGRPFKztAc/PH0PE7rVpoSrI4fPJdLn60gGz93G6bgrZscTEZG7oKKUiIjke8lp174dB3iqRQX8PZxNTiQiInnJarXwaMNAVr3Yir73BGG1wG9/naH1pLV8tvoQyWnpZkcUEZE7oKKUiIjke7P+PM6JC0n4ujnxVMvyZscRERGTeLg48FbnGiwe2pxGQV5cSU1nwvIDdPh4PWv/Pmd2PBERySYVpUREJF+7kJjC5FUHAXipXRWKOdqbnEhERMxWPcCd755qyofd6+BT3IkjsYk8MX0TT83eQtTFJLPjiYhIFqkoJSIi+donK//m0tU0qpdyp2v9MmbHERGRfMJisfBI/TKserElT94bjJ3VwvI9MYR+uJZPww9yNVW39ImI5HcqSomISL516Oxl5kSeAOCNTtWwWi0mJxIRkfzG3dmBNx+szpJhzWkc7M3VVBuTVvxNu4/XsXr/WbPjiYjILagoJSIi+dbYJftItxmEVvPjnoo+ZscREZF8rIq/GwsHNeGTnnXxdXPi+Pkk+s3YzICZWzh5Qbf0iYjkRypKiYhIvrThYCzh+89ib7UwsmNVs+OIiEgBYLFYeKhuaVa92IpBLcpjb7Wwct+1W/o+Xvm3bukTEclnVJQSEZF8J91mMOa3vQA81qQcFUoWNzmRiIgUJMWd7HmtYzWWPteceyqUIDnNxscrD9Lmo7Ws3BtjdjwREfl/KkqJiEi+88PWk+yPvoS7sz3Pta5kdhwRESmgKvm5MXdACFN618Pf3ZmTF64wYNYWnpyxmePnE82OJyJS5KkoJSIi+crl5DQm/v43AMNaV8LL1dHkRCIiUpBZLBYeqB1A+AstebplBRzsLKzaf5Y2H63jw98PcCVFt/SJiJhFRSkREclXvlx7mHOXkgkqUYywpkFmxxERkULC1cmeVztUZdnwFjSv5ENKmo3Jqw4R+uFalu+JxjAMsyOKiBQ5KkqJiEi+cTruCl+tOwLAqx2q4WivX1MiIpKzKpQszqwnGzO1T30CPJw5FXeFp2Zvpe+3mzkaq1v6RETyklb7IiKSb0xYfoDkNBuNg71pV8PP7DgiIlJIWSwWOtQqxcoXWjL4vgo42llZ+/c52n20jgnL95OUkmZ2RBGRIkFFKRERyRd2nozjp+2nABjVqToWi8XkRCIiUtgVc7TnpXZVWf58C1pWLklKuo3PVh8mdNJalv51Rrf0iYjkMhWlRETEdIZhMOa3vQA8Ur80tcp4mJxIRESKkmAfV2b0a8SXjzegtKcLp+Ov8szcbYRN38Shs5fNjiciUmipKCUiIqZbvieazccu4uxg5aV2VcyOIyIiRZDFYqFdDX9WjmjJsPsr4mhvZf3BWDp8so6xS/eRmKxb+kREcpqKUiIiYqrktHTGLt0PwKAWFSjl4WJyIhERKcpcHO0Y0bYKK55vwf1VfUlNN/hy7RFaT1rLf3ae1i19IiI5SEUpEREx1eyI4xw/n4SvmxNPtShvdhwREREAypVwZXrfRnwd1pBAbxeiE64ydP52+nwdycGYS2bHExEpFFSUEhER01xITOGT8IMAvNiuCq5O9iYnEhERySy0uh8rnm/J86GVcbK38ufh83T4ZD3v/baXy7qlT0TkrqgoJSIippkcfpBLV9OoXsqdrvXLmB1HRETkhpwd7HgutBIrR7SkTXU/0mwG09Yf5f6Ja/hlxynd0icicodUlBIREVMcOnuZ2RuPA/BGp2rYWS0mJxIREbm1QO9iTAtryLd9GxFUohhnLyXz3IId9PxqIweidUufiEh2qSglIiKmGLd0H+k2g9BqftxT0cfsOCIiIll2X1Vflg1vwYttK+PsYCXy6AU6Tl7PO//ZS8LVVLPjiYgUGCpKiYhInvvjUCwr953F3mphZMeqZscRERHJNmcHO4bcf+2WvvY1/Em3GUz/4yj3T1zLom1RuqVPRCQLVJQSEZE8lW4zGPPbPgAea1KOCiWLm5xIRETkzpXxKsYXjzdg1pONKe/jSuzlZEZ8t5PuX0aw93SC2fFERPI1FaVERCRP/bg1in1nEnB3tue51pXMjiMiIpIjWlQuydLhzXm5fRVcHOzYfOwiD3y6nrd+3UP8Fd3SJyJyIypKiYhInklMTmPC7wcAGNa6El6ujiYnEhERyTlO9nY826oi4S+0pFOtUtgMmPHnMVpPWsP3W05is+mWPhGR/6WilIiI5Jkv1x7m3KVkypUoxuNNy5kdR0REJFcEeLrwWZ/6zOkfQoWSrsReTuGlH3bR7Ys/2X0q3ux4IiL5Rr4oSn322WcEBQXh7OxMSEgImzZtuuncadOm0bx5c7y8vPDy8iI0NPS6+X379sVisWTa2rdvn2nOhQsX6NOnD+7u7nh6etK/f38uX76cK+cnIiJwOu4KX60/AsDIDlVxsrczOZGIiEjualbJh6XPtWBkh6oUc7Rj24k4Ok/ZwKifdxOfpFv6RERML0otXLiQESNGMHr0aLZt20adOnVo164dZ8+eveH8NWvW0KtXL1avXk1ERASBgYG0bduWU6dOZZrXvn17zpw5k7HNnz8/0+t9+vRhz549rFixgsWLF7Nu3ToGDRqUa+cpIlLUTVx+gKupNhoHedOuhr/ZcURERPKEo72Vp1pWYNULrXiwTgA2A2ZvPM59k9awcPMJ3dInIkWaxTD5WaUhISE0atSIKVOmAGCz2QgMDGTo0KG8+uqrt90/PT0dLy8vpkyZQlhYGHDtSqm4uDh+/vnnG+6zb98+qlevzubNm2nYsCEAy5Yto2PHjkRFRREQEHDb901ISMDDw4P4+Hjc3d2zeLYiIkXTrqg4Ok/5A4Bfh9xL7TKe5gYSuQtaA2SdPiuR6/15OJbRv+zh4Nlrd2nUCfTk3Ydq6HejiBQqWV0DmHqlVEpKClu3biU0NDRjzGq1EhoaSkRERJaOkZSURGpqKt7e3pnG16xZg6+vL1WqVOGZZ57h/PnzGa9FRETg6emZUZACCA0NxWq1EhkZeZdnJSIi/8swDMYs3gfAI/VKa9EtIiJF2j0VfFjyXHPe6FSN4k727DwZx0Of/cFrP/3FxcQUs+OJiOQpU4tSsbGxpKen4+fnl2ncz8+P6OjoLB3jlVdeISAgIFNhq3379syaNYvw8HA++OAD1q5dS4cOHUhPTwcgOjoaX1/fTMext7fH29v7pu+bnJxMQkJCpk1ERG5v+Z5oNh27gLODlRfbVTE7joiIiOkc7KwMaF6eVS+05OF6pTEMmBd5gvsmrWFu5HHSdUufiBQRpveUuhvjxo1jwYIF/PTTTzg7O2eM9+zZk86dO1OrVi26dOnC4sWL2bx5M2vWrLnj9xo7diweHh4ZW2BgYA6cgYhI4Zacls7YpfsBGNS8PAGeLiYnEhERyT983Z35qEddvnuqKVX93YhLSuX1n3bz8Od/sP3ERbPjiYjkOlOLUj4+PtjZ2RETE5NpPCYmBn//WzfBnThxIuPGjeP333+ndu3at5xbvnx5fHx8OHToEAD+/v7XNVJPS0vjwoULN33fkSNHEh8fn7GdPHnydqcnIlLkzY44zvHzSZR0c+KplhXMjiMiIpIvNQ72ZvHQZox+sDpuTvbsiorn4c//5JUfdnH+crLZ8UREco2pRSlHR0caNGhAeHh4xpjNZiM8PJymTZvedL/x48fz7rvvsmzZskx9oW4mKiqK8+fPU6pUKQCaNm1KXFwcW7duzZizatUqbDYbISEhNzyGk5MT7u7umTYREbm5C4kpfBJ+EICX2lbB1cne5EQiIiL5l72dlX73BrPqxVZ0rV8GgIVbTnL/pLXMjjimW/pEpFAy/fa9ESNGMG3aNGbOnMm+fft45plnSExMpF+/fgCEhYUxcuTIjPkffPABo0aNYvr06QQFBREdHU10dDSXL197esXly5d56aWX2LhxI8eOHSM8PJyHHnqIihUr0q5dOwCqVatG+/btGThwIJs2beKPP/5gyJAh9OzZM0tP3hMRkdubHH6QS1fTqFbKna4NypgdR0REpEAo6ebEpO51+OHpplQv5U78lVRG/bKHzlM2sPW4bukTkcLF9KJUjx49mDhxIm+++SZ169Zlx44dLFu2LKP5+YkTJzhz5kzG/KlTp5KSkkK3bt0oVapUxjZx4kQA7Ozs2LVrF507d6Zy5cr079+fBg0asH79epycnDKOM3fuXKpWrUrr1q3p2LEjzZo146uvvsrbkxcRKaQOn7vMnI3HAXijUzXsrBaTE4mIiBQsDYO8+c/QZrzzUA3cne3ZczqBrlP/5MXvdxKrW/pEpJCwGIah60DvQEJCAh4eHsTHx+tWPhGRfxkwcwsr98UQWs2Xr59oZHYckRylNUDW6bMSyRmxl5MZv2w/322JAsDN2Z4X2lTmsSblsLcz/ToDEZHrZHUNoD/BREQkR/15KJaV+2Kwt1oY2bGa2XFEREQKPJ/iTozvVodFz95DzdLuXLqaxlv/2csDn25g87ELZscTEbljKkqJiEiOSbcZjPltHwCPNSlHhZLFTU4kIiJSeNQv68Uvg5sxpktNPFwc2B99iUe/iGDEwh2cvXTV7HgiItmmopSIiOSYH7dFsfdMAu7O9jzXupLZcURERAodO6uFx5qUY/WLrejVOBCLBRZtP0XriWv5ZsNR0tJtZkcUEckyFaVERCRHJCanMXH5AQCGta6El6ujyYlEREQKL29XR8Y+Upufn72XOmU8uJScxruL99Jp8gY2HjlvdjwRkSxRUUpERHLEl+uOcPZSMuVKFOPxpuXMjiMiIlIk1An05Kdn72XsI7XwKubAgZhL9PxqI88t2E5Mgm7pE5H8TUUpERG5a2fir/DVusMAjOxQFSd7O5MTiYiIFB1Wq4Vejcuy+sVW9Akpi8UCv+w4zf0T1zBt3RFSdUufiORTKkqJiMhdm7D8AFdTbTQO8qZdDX+z44iIiBRJnsUcee/hWvw6uBl1Az1JTEnnvSX76PDJev48FGt2PBGR66goJSIid2VXVByLtp0C4I0HqmGxWExOJCIiUrTVKuPBomfuYXy32ni7OnLo7GV6fx3J4HnbOBN/xex4IiIZVJQSEZE7ZhgGY37bB8DD9UpTu4ynuYFEREQEuHZLX/eGgax+oRVPNC2H1QK/7TpD60lrmbrmMClpuqVPRMynopSIiNyx5Xti2HT0Ak72Vl5qV8XsOCIiIvIvHsUcePuhmvxnaDMalvMiKSWdD5btp/0n61h/8JzZ8USkiFNRSkRE7khKmo2xS69dJTWoRXkCPF1MTiQiIiI3UyPAg++fbsqkR+vgU9yRI+cSefybTTwzZyun4nRLn4iYQ0UpERG5I7MijnH8fBIl3Zx4umUFs+OIiIjIbVgsFro2KEP4C63od28QdlYLS3dHEzppLZ+tPkRyWrrZEUWkiFFRSkREsu1iYgqTww8C8GLbyrg62ZucSERERLLKw8WB0Q/WYPHQZjQO8uZKajoTlh+g/cfrWXPgrNnxRKQIUVFKRESy7ZPwgyRcTaOqvxvdGgSaHUdERETuQLVS7ix8qgkf96hLSTcnjsYm0vfbzQyatYWTF5LMjiciRYCKUiIiki2Hz11mzsbjALzRqTp2VovJiUREROROWSwWutQrzaoXWjKgWTB2Vgu/740h9MO1TA4/yNVU3dInIrlHRSkREcmWsUv2k2YzaF3Vl2aVfMyOIyIiIjnAzdmBNx6oztLnmtOkvDfJaTY+XPE37T5ex6r9MWbHE5FCSkUpERHJsj8PxbJyXwx2VgsjO1YzO46IiIjksMp+bswf2ITJverh5+7E8fNJPDljCwNmbubEed3SJyI5S0UpERHJknSbwZjf9gHwWEhZKvoWNzmRiIiI5AaLxULnOgGEv9CKp1qUx95qYeW+s4R+tJaPVvytW/pEJMeoKCUiIlny47Yo9p5JwM3ZnudCK5sdR0RERHJZcSd7RnasxrLhzbm3YglS0mx8En6QNh+tZcXeGAzDMDuiiBRwKkqJiMhtJSanMXH5AQCG3V8Jb1dHkxOJiIhIXqno68ac/iF81rs+pTycOXnhCgNnbaHfjM0ci000O56IFGAqSomIyG19te4IZy8lU9a7GGH3lDM7joiIiOQxi8VCp9qlCH+hJc+0qoCDnYU1B87R9qN1TPr9AFdSdEufiGSfilIiInJL0fFX+XLdYQBGdqiKk72dyYlERETELMUc7XmlfVWWDW9B80o+pKTb+HTVIUI/XMuy3dG6pU9EskVFKRERuaUJyw9wNdVGoyAv2tf0NzuOiIiI5AMVShZn1pON+eKxBpT2dOFU3BWenrOVsOmbOHLustnxRKSAUFFKRERu6q+oeH7cFgXAG52qY7FYTE4kIiIi+YXFYqF9TX9WjmjJkPsq4mhnZf3BWNp9vI4Plu0nKSXN7Igiks+pKCUiIjdkGAZjftsLwMP1SlMn0NPcQCIiIpIvuTja8WK7Kix/vgWtqpQkNd1g6prDtJ60lm0nLpodT0TyMRWlRETkhn7fG0Pk0Qs42Vt5qV0Vs+OIiIhIPhfs48q3fRsxLawhZbxcOBN/lSe+2cSuqDizo4lIPqWilIiIXCclzcbYJfsAGNSiPAGeLiYnEhERkYLAYrHQprofvz/fgsbB3lxKTuOxryPZczre7Ggikg+pKCUiIteZvfE4x84nUdLNiadbVjA7jojcxtixY2nUqBFubm74+vrSpUsXDhw4cMt9pk2bRvPmzfHy8sLLy4vQ0FA2bdqUaU7fvn2xWCyZtvbt2+fmqYhIIVHM0Z7pfRtRv6wnCVevFaYORF8yO5aI5DMqSomISCZxSSlMDj8IwAttKuPqZG9yIhG5nbVr1zJ48GA2btzIihUrSE1NpW3btiQmJt50nzVr1tCrVy9Wr15NREQEgYGBtG3bllOnTmWa1759e86cOZOxzZ8/P7dPR0QKieJO9sx4sjF1ynhwMSmVPl9v5NBZPZlPRP7LYhiGYXaIgighIQEPDw/i4+Nxd3c3O46ISI55+z97+PaPY1T1d+O3Yc2xs+qJeyL/qyCsAc6dO4evry9r166lRYsWWdonPT0dLy8vpkyZQlhYGHDtSqm4uDh+/vnnO8pRED4rEcl98Ump9Jq2kb1nEvB1c2LhU00J9nE1O5aI5KKsrgF0pZSIiGQ4cu4ysyOOA/BGp+oqSIkUUPHx13q3eHt7Z3mfpKQkUlNTr9tnzZo1+Pr6UqVKFZ555hnOnz+fo1lFpPDzKObAnAEhVPV34+ylZHpP28jJC0lmxxKRfEBFKRERyTB26X7SbAb3V/WlWSUfs+OIyB2w2WwMHz6ce++9l5o1a2Z5v1deeYWAgABCQ0Mzxtq3b8+sWbMIDw/ngw8+YO3atXTo0IH09PQbHiM5OZmEhIRMm4gIgLerI3MGhFDRtzhn4q/S86uNnIq7YnYsETGZilIiIgLAn4djWbE3Bjurhdc6VjU7jojcocGDB7N7924WLFiQ5X3GjRvHggUL+Omnn3B2ds4Y79mzJ507d6ZWrVp06dKFxYsXs3nzZtasWXPD44wdOxYPD4+MLTAw8G5PR0QKEZ/iTswbEEKwjyun4q7Q66uNRMdfNTuWiJhIRSkRESHdZjBm8T4A+oSUpaKvm8mJRORODBkyhMWLF7N69WrKlCmTpX0mTpzIuHHj+P3336ldu/Yt55YvXx4fHx8OHTp0w9dHjhxJfHx8xnby5Mlsn4OIFG6+7s7MGxhCWe9inLiQRO9pGzl7SYUpkaJKRSkREWHRtij2nknAzdme51pXMjuOiGSTYRgMGTKEn376iVWrVhEcHJyl/caPH8+7777LsmXLaNiw4W3nR0VFcf78eUqVKnXD152cnHB3d8+0iYj8WykPF+YNDKG0pwtHYhPpMy2S85eTzY4lIiZQUUpEpIhLSkljwvIDAAy9vyIlijuZnEhEsmvw4MHMmTOHefPm4ebmRnR0NNHR0Vy58t9+LWFhYYwcOTLj5w8++IBRo0Yxffp0goKCMva5fPna49ovX77MSy+9xMaNGzl27Bjh4eE89NBDVKxYkXbt2uX5OYpI4VLGqxjzBobg7+7MwbOX6fN1JBcTU8yOJSJ5TEUpEZEi7su1Rzh7KZlAbxeeuCfI7DgicgemTp1KfHw8rVq1olSpUhnbwoULM+acOHGCM2fOZNonJSWFbt26Zdpn4sSJANjZ2bFr1y46d+5M5cqV6d+/Pw0aNGD9+vU4Oal4LSJ3r1wJV+YNDKGkmxP7oy/x+PRI4q+kmh1LRPKQxTAMw+wQBVFCQgIeHh7Ex8fr0nQRKbCi46/SauJqrqba+LxPfTrWuvEtOSLyX1oDZJ0+KxHJioMxl+j51UbOJ6ZQJ9CTOf0b4+bsYHYsEbkLWV0D6EopEZEibMLyA1xNtdGwnBcdavqbHUdERESKoEp+bswZEIJnMQd2noyj37ebSUxOMzuWiOQBFaVERIqov6Li+XFbFABvPFAdi8ViciIREREpqqqVcmdO/xDcne3Zcvwi/Wdu5kpKutmxRCSXqSglIlIEGYbBmN/2AtClbgB1Az3NDSQiIiJFXs3SHszqH0JxJ3s2HrnAwFlbuJqqwpRIYaailIhIEbRibwyRRy/gZG/lpfZVzY4jIiIiAkDdQE9mPtmIYo52bDgUy9NztpKcpsKUSGGlopSISBGTkmZj7NL9AAxsXp7Sni4mJxIRERH5rwblvJnetxHODlbWHDjH4LnbSUmzmR1LRHKBilIiIkXMnI3HORqbiE9xJ55uVcHsOCIiIiLXaVK+BF+HNcLR3srKfTE8t2A7aekqTIkUNipKiYgUIXFJKXwSfhCAF9tWpriTvcmJRERERG6sWSUfvnq8AY52VpbujmbEdztJtxlmxxKRHKSilIhIETI5/BDxV1Kp6u/Gow0DzY4jIiIickutqvjyeZ/62Fst/LrzNC//sAubClMihYaKUiIiRcSRc5eZFXEMgDc6VcfOajE3kIiIiEgWhFb349Ne9bCzWvhxWxSv//yXClMihUS+KEp99tlnBAUF4ezsTEhICJs2bbrp3GnTptG8eXO8vLzw8vIiNDQ00/zU1FReeeUVatWqhaurKwEBAYSFhXH69OlMxwkKCsJisWTaxo0bl2vnKCJitnFL95NmM7i/qi/NKvmYHUdEREQkyzrUKsWH3etgtcD8TSd56z97MAwVpkQKOtOLUgsXLmTEiBGMHj2abdu2UadOHdq1a8fZs2dvOH/NmjX06tWL1atXExERQWBgIG3btuXUqVMAJCUlsW3bNkaNGsW2bdtYtGgRBw4coHPnztcd65133uHMmTMZ29ChQ3P1XEVEzBJx+Dy/743BzmrhtY5VzY4jIiIikm0P1S3NhG51sFhgVsRxxvy2T4UpkQLOYpj8X3FISAiNGjViypQpANhsNgIDAxk6dCivvvrqbfdPT0/Hy8uLKVOmEBYWdsM5mzdvpnHjxhw/fpyyZcsC166UGj58OMOHD7+j3AkJCXh4eBAfH4+7u/sdHUNEJC/YbAYPTtnAntMJPN6kHO92qWl2JJECTWuArNNnJSK5YcGmE7y66C8Anm5ZgVfaV8FiUVsCkfwkq2sAU6+USklJYevWrYSGhmaMWa1WQkNDiYiIyNIxkpKSSE1Nxdvb+6Zz4uPjsVgseHp6ZhofN24cJUqUoF69ekyYMIG0tLSbHiM5OZmEhIRMm4hIQbBo+yn2nE7Azcme4aGVzI4jIiIicld6Ni7Luw/VAOCLtYf5aOVBkxOJyJ0y9VngsbGxpKen4+fnl2ncz8+P/fv3Z+kYr7zyCgEBAZkKW//r6tWrvPLKK/Tq1StTdW7YsGHUr18fb29v/vzzT0aOHMmZM2f48MMPb3icsWPH8vbbb2fxzERE8oeklDQmLL/25+mQ+ytSoriTyYlERERE7t7jTYNISTd4d/FeJocfxNHOwpD79eWbSEFjalHqbo0bN44FCxawZs0anJ2dr3s9NTWV7t27YxgGU6dOzfTaiBEjMv69du3aODo68tRTTzF27FicnK7/S9vIkSMz7ZOQkEBgoB6nLiL521frjhCTkEygtwtP3BNkdhwRERGRHNO/WTCp6TbGLd3PxN//xtHeyqAWFcyOJSLZYGpRysfHBzs7O2JiYjKNx8TE4O/vf8t9J06cyLhx41i5ciW1a9e+7vV/ClLHjx9n1apVt+1jEBISQlpaGseOHaNKlSrXve7k5HTDYpWISH4VHX+VL9ceAeDV9tVwdrAzOZGIiIhIznq6ZQVS02xMWvE37y/Zj4OdlX73BpsdS0SyyNSeUo6OjjRo0IDw8PCMMZvNRnh4OE2bNr3pfuPHj+fdd99l2bJlNGzY8LrX/ylIHTx4kJUrV1KiRInbZtmxYwdWqxVfX987OxkRkXxm4u8HuJKaToNyXnSsdetCv4iIiEhBNbR1JYbeXxGAt/+zlzkbj5ucSESyyvTb90aMGMETTzxBw4YNady4MR9//DGJiYn069cPgLCwMEqXLs3YsWMB+OCDD3jzzTeZN28eQUFBREdHA1C8eHGKFy9Oamoq3bp1Y9u2bSxevJj09PSMOd7e3jg6OhIREUFkZCT33Xcfbm5uRERE8Pzzz/PYY4/h5eVlzgchIpKDdp+K58dtUQC80amankgjIiIihdqINpVJSbPx5bojvPHzbhztrHRvpHYrIvmd6UWpHj16cO7cOd58802io6OpW7cuy5Yty2h+fuLECazW/17QNXXqVFJSUujWrVum44wePZq33nqLU6dO8euvvwJQt27dTHNWr15Nq1atcHJyYsGCBbz11lskJycTHBzM888/n6lnlIhIQWUYBmN+24thwEN1A6hXVsV2ERERKdwsFguvdqhKSrqNb/84xiuLduFgb+HhemXMjiYit2AxDMMwO0RBlJCQgIeHB/Hx8bftVyUikpd+3xPNoNlbcbK3surFVpT2dDE7kkihojVA1umzEpG8ZhgGo37ZzZyNJ7Ba4JOe9XiwToDZsUSKnKyuAUztKSUiIjkrJc3G2KX7ARjQPFgFKRERESlSLBYL73SuSY+GgdgMGL5wB8t2R5sdS0RuQkUpEZFCZM7G4xyNTcSnuCPPtKpodhwRERGRPGe1Whj7SC0eqVeadJvB0PnbCN8Xc/sdRSTPqSglIlJIxCWl8En4QQBeaFuF4k6mtw0UERERMYXVamHCo3V4sE4AqekGz8zZxtq/z5kdS0T+RUUpEZFCYnL4IeKvpFLV343uDfW0GRERESna7KwWPuxeh/Y1/ElJtzFo1hb+OBRrdiwR+R8qSomIFAJHYxOZFXEMgNc7VcPOajE3kIiIiEg+4GBnZXKveoRW8yU5zcaAmVvYdPSC2bFE5P+pKCUiUgiMW7qPNJvBfVVK0rxSSbPjiIiIiOQbjvZWPutTn5aVS3IlNZ1+325i6/GLZscSEVSUEhEp8DYeOc/yPTHYWS281rGa2XFERERE8h0nezu+fLwB91YsQWJKOn2nb2LnyTizY4kUeSpKiYgUYDabwZjf9gLQu3FZKvm5mZxIREREJH9ydrBjWlhDGgd7cyk5jce/iWT3qXizY4kUaSpKiYgUYD9tP8XuUwm4OdkzPLSS2XFERERE8rVijvZM79uI+mU9Sbh6rTC1PzrB7FgiRZaKUiIiBVRSShoTlh8AYMj9FSlR3MnkRCIiIiL5X3Ene2Y82Zg6ZTy4mJTKY19HcujsJbNjiRRJKkqJiBRQ09YdJTrhKoHeLjxxT5DZcUREREQKDHdnB2Y9GUKNAHdiL6fQe1okR2MTzY4lUuRkuygVFBTEO++8w4kTJ3Ijj4iIZEFMwlW+WHsYgFfbV8PZwc7kRCIiIiIFi0cxB2b3D6GqvxtnLyXTe9pGTpxPMjuWSJGS7aLU8OHDWbRoEeXLl6dNmzYsWLCA5OTk3MgmIiI3MXH5Aa6kptOgnBcda/mbHUdERESkQPJ2dWTOgBAq+hbnTPxVek3bSNRFFaZE8sodFaV27NjBpk2bqFatGkOHDqVUqVIMGTKEbdu25UZGERH5H7tPxfPDtigAXu9UDYvFYnIiERERkYLLp7gT8waEEOzjyqm4K/SeFkl0/FWzY4kUCXfcU6p+/fpMnjyZ06dPM3r0aL7++msaNWpE3bp1mT59OoZh5GROEREBDMPgvd/2YRjQuU4A9ct6mR1JREREpMDzdXdm3sAQynoX48SFJHpP28jZBBWmRHLbHRelUlNT+e677+jcuTMvvPACDRs25Ouvv6Zr16689tpr9OnTJydziogIsHLfWSKOnMfR3srL7auYHUdERESk0Cjl4cK8gSGU9nThSGwifb6O5PxltaoRyU322d1h27ZtfPvtt8yfPx+r1UpYWBgfffQRVatWzZjz8MMP06hRoxwNKiJS1KWk2Xh/yT4ABjQLpoxXMZMTiYiIiBQuZbyKMX9gE7p/GcHBs5fp83Uk8wc2wcvV0exoIoVStq+UatSoEQcPHmTq1KmcOnWKiRMnZipIAQQHB9OzZ88cCykiIjA38jhHYxPxKe7IM60qmB1HREREpFAqW6IY8waGUNLNif3Rl3h8eiTxV1LNjiVSKGW7KHXkyBGWLVvGo48+ioODww3nuLq68u233951OBERuSYuKYWPVx4EYESbKrg53/jPXxERERG5e+VLFmfegBBKuDqy+1QCYdM3cemqClMiOS3bRamzZ88SGRl53XhkZCRbtmzJkVAiIpLZp6sOEX8llSp+bnRvWMbsOCIiIiKFXiU/N+YMCMGzmAM7T8bR99vNJCanmR1LpFDJdlFq8ODBnDx58rrxU6dOMXjw4BwJJSIi/3U0NpFZEccAeL1TNezt7vgZFSIiIiKSDdVKuTOnfwjuzvZsPX6RJ2ds5kpKutmxRAqNbP/NZu/evdSvX/+68Xr16rF3794cCSUiIv81buk+UtMNWlUpSYvKJc2OIyIiIlKk1Cztwaz+IRR3sify6AUGztrC1VQVpkRyQraLUk5OTsTExFw3fubMGezts/0wPxERuYWNR86zfE8MdlYLr3esZnYcERERkSKpbqAnM59sRDFHOzYciuXpOVtJTlNhSuRuZbso1bZtW0aOHEl8fHzGWFxcHK+99hpt2rTJ0XAiIkWZzWYw5rdrV6D2ahxIJT83kxOJiIiIFF0Nynnzbd9GODtYWXPgHIPnbiclzWZ2LJECLdtFqYkTJ3Ly5EnKlSvHfffdx3333UdwcDDR0dFMmjQpNzKKiBRJP20/xe5TCbg52TM8tLLZcURERESKvJDyJfjmiUY42VtZuS+G5xZsJy1dhSmRO5XtolTp0qXZtWsX48ePp3r16jRo0IBPPvmEv/76i8DAwNzIKCJS5FxJSWfC8gMADL6/Ij7FnUxOJCIiIiIA91b04cvHG+BoZ2Xp7mhGfLeTdJthdiyRAumOmkC5uroyaNCgnM4iIiL/b9r6I0QnXKWMlwt97wkyO46IiIiI/I9WVXz5vE99np6zlV93nsbBzsqEbrWxWi1mRxMpUO64M/nevXs5ceIEKSkpmcY7d+5816FERIqymISrTF1zGIBXO1TF2cHO5EQiIiIi8m+h1f34tFc9hszfzo/bonCws/D+w7VUmBLJhmwXpY4cOcLDDz/MX3/9hcViwTCuXaZosVz7Dy89XU8gEBG5G5N+P8CV1HTql/WkU61SZscRERERkZvoUKsUH9kMhi/YzoLNJ3Gws/LOQzUy/n4sIreW7Z5Szz33HMHBwZw9e5ZixYqxZ88e1q1bR8OGDVmzZk0uRBQRKTr2nI7n+61RALzxQHUtaEQKuZMnTxIVFZXx86ZNmxg+fDhfffWVialERCQ7OtcJYEK3OlgsMHvjcd5dvC/j4g0RubVsF6UiIiJ455138PHxwWq1YrVaadasGWPHjmXYsGG5kVFEpEgwDIP3ftuHYVxb3NQv62V2JBHJZb1792b16tUAREdH06ZNGzZt2sTrr7/OO++8Y3I6ERHJqq4NyjDukVoATP/jKB8sO6DClEgWZLsolZ6ejpubGwA+Pj6cPn0agHLlynHgwIGcTSciUoSE7zvLn4fP42hv5eX2VcyOIyJ5YPfu3TRu3BiA7777jpo1a/Lnn38yd+5cZsyYYW44ERHJlh6NyvJul5oAfLH2MB+tPGhyIpH8L9s9pWrWrMnOnTsJDg4mJCSE8ePH4+joyFdffUX58uVzI6OISKGXmm7j/SX7ABjQLJgyXsVMTiQieSE1NRUnJycAVq5cmfHAmKpVq3LmzBkzo4mIyB14vEk5UtNsvLN4L5PDD+JoZ2HI/ZXMjiWSb2X7Sqk33ngDm80GwDvvvMPRo0dp3rw5S5YsYfLkyTkeUESkKJi78ThHYhPxKe7IM60qmB1HRPJIjRo1+OKLL1i/fj0rVqygffv2AJw+fZoSJUqYnE5ERO7Ek82CGdmhKgATf/+br9YdNjmRSP6V7Sul2rVrl/HvFStWZP/+/Vy4cAEvLy815BURuQPxSal8HH7t8u7n21TGzdnB5EQiklc++OADHn74YSZMmMATTzxBnTp1APj1118zbusTEZGC56mWFUhJszFpxd+8v2Q/DnZW+t0bbHYskXwnW0Wp1NRUXFxc2LFjBzVr1swY9/b2zvFgIiJFxaerDhKXlEplv+L0aBhodhwRyUOtWrUiNjaWhIQEvLz++3CDQYMGUayYbuMVESnIhrauREq6jU9XHeLt/+zFwc7KY03KmR1LJF/J1u17Dg4OlC1blvT09NzKIyJSpByLTWRmxDEAXu9UHXu7bN9VLSIF2JUrV0hOTs4oSB0/fpyPP/6YAwcO4Ovra3I6ERG5WyPaVOapltd6L7/x826+23zS5EQi+Uu2//bz+uuv89prr3HhwoXcyCMiUqSMW7qf1HSDlpVL0rJySbPjiEgee+ihh5g1axYAcXFxhISEMGnSJLp06cLUqVNNTiciInfLYrHwavuq9Ls3CIBXFu1i0bYoc0OJ5CPZLkpNmTKFdevWERAQQJUqVahfv36mTUREsibyyHmW7YnGaoHXO1UzO46ImGDbtm00b94cgB9++AE/Pz+OHz/OrFmz9AAZEZFCwmKx8OYD1XmsSVkMA178fif/2Xna7Fgi+UK2G5136dIlF2KIiBQtNpvBmN/2AdCrcVkq+7mZnEhEzJCUlISb27X//n///XceeeQRrFYrTZo04fjx4yanExGRnGKxWHinc03S0g0WbD7J8IU7cLCz0L5mKbOjiZgq20Wp0aNH50YOEZEi5ecdp/jrVDzFnex5vk1ls+OIiEkqVqzIzz//zMMPP8zy5ct5/vnnATh79izu7u4mpxMRkZxktVp4/+FapKTbWLTtFEPnb2dqHyuh1f3MjiZiGnXUFRHJY1dS0hm/7AAAg++riE9xJ5MTiYhZ3nzzTV588UWCgoJo3LgxTZs2Ba5dNVWvXj2T04mISE6zWi1M6FaHB+sEkJpu8Ozcbaw5cNbsWCKmyXZRymq1Ymdnd9NNRERubdr6I0QnXKW0p0tG00sRKZq6devGiRMn2LJlC8uXL88Yb926NR999JGJyUREJLfYWS182L0OHWr6k5Ju46nZW/njUKzZsURMke3b93766adMP6emprJ9+3ZmzpzJ22+/nWPBREQKo5iEq0xdcxiAVztUxdlBxXyRos7f3x9/f3+ioq49jalMmTI0btzY5FQiIpKbHOysfNKzHqlzt7Jy31n6z9zMzH6NCSlfwuxoInkq20Wphx566Lqxbt26UaNGDRYuXEj//v1zJJiISGE06fcDXElNp15ZTx6orcaWIkWdzWZjzJgxTJo0icuXLwPg5ubGCy+8wOuvv47Vqk4LIiKFlaO9lc/61GfQrK2s/fscT87YzKz+ITQo52V2NJE8k2MrnSZNmhAeHp5ThxMRKXT2nI7n+63XroQY9UB1LBaLyYlExGyvv/46U6ZMYdy4cWzfvp3t27fz/vvv8+mnnzJq1Ciz44mISC5zsrfjy8cb0KyiD4kp6fSdvomdJ+PMjiWSZ3KkKHXlyhUmT55M6dKl72j/zz77jKCgIJydnQkJCWHTpk03nTtt2jSaN2+Ol5cXXl5ehIaGXjffMAzefPNNSpUqhYuLC6GhoRw8eDDTnAsXLtCnTx/c3d3x9PSkf//+Gd9QiojkNMMweO+3fRgGPFgngPpl9Q2YiMDMmTP5+uuveeaZZ6hduza1a9fm2WefZdq0acyYMcPseCIikgecHeyYFtaQxsHeXEpO4/FvItl9Kt7sWCJ5IttFKS8vL7y9vTM2Ly8v3NzcmD59OhMmTMh2gIULFzJixAhGjx7Ntm3bqFOnDu3atePs2Rs/gWDNmjX06tWL1atXExERQWBgIG3btuXUqVMZc8aPH8/kyZP54osviIyMxNXVlXbt2nH16tWMOX369GHPnj2sWLGCxYsXs27dOgYNGpTt/CIiWbFq/1n+PHweR3srL7erYnYcEcknLly4QNWqVa8br1q1KhcuXDAhkYiImMHF0Y7pfRvRoJwXCVevFab2RyeYHUsk11kMwzCys8OMGTMy3XJitVopWbIkISEheHll/5v/kJAQGjVqxJQpU4BrvRUCAwMZOnQor7766m33T09Px8vLiylTphAWFoZhGAQEBPDCCy/w4osvAhAfH4+fnx8zZsygZ8+e7Nu3j+rVq7N582YaNmwIwLJly+jYsSNRUVEEBATc9n0TEhLw8PAgPj4ed3f3bJ+3iBQdqek22n28jiPnEnmmVQVeaX/9X0BFpODIyTVASEgIISEhTJ48OdP40KFD2bRpE5GRkXd1fLNpvSQikj0JV1N5/OtIdkbFU8LVkYVPNaGir5vZsUSyLatrgGw3Ou/bt+/d5MokJSWFrVu3MnLkyIwxq9VKaGgoERERWTpGUlISqampeHt7A3D06FGio6MJDQ3NmOPh4UFISAgRERH07NmTiIgIPD09MwpSAKGhoVitViIjI3n44Ydz6AxFRGBe5AmOnEukhKsjz7aqYHYcEclHxo8fT6dOnVi5ciVNmzYFICIigpMnT7JkyRKT04mISF5zd3Zg1pMh9P56I3tOJ9BrWiQLBzWhfMniZkcTyRXZvn3v22+/5fvvv79u/Pvvv2fmzJnZOlZsbCzp6en4+fllGvfz8yM6OjpLx3jllVcICAjIKEL9s9+tjhkdHY2vr2+m1+3t7fH29r7p+yYnJ5OQkJBpExG5nfikVD5e+TcAI9pWxs3ZweREIpKftGzZkr///puHH36YuLg44uLieOSRR9izZw+zZ882O56IiJjAo5gDc/qHUNXfjXOXkuk9LZIT55PMjiWSK7JdlBo7diw+Pj7Xjfv6+vL+++/nSKisGjduHAsWLOCnn37C2dk5V99r7NixeHh4ZGyBgYG5+n4iUjhMWX2Qi0mpVPYrTo+G+nNDRK4XEBDAe++9x48//siPP/7ImDFjuHjxIt98843Z0URExCRero7MGRBCRd/iRCdcpde0jURdVGFKCp9sF6VOnDhBcHDwdePlypXjxIkT2TqWj48PdnZ2xMTEZBqPiYnB39//lvtOnDiRcePG8fvvv1O7du2M8X/2u9Ux/f39r2uknpaWxoULF276viNHjiQ+Pj5jO3nyZNZOUkSKrOPnE5nx5zEAXu9UHXu7HHngqYiIiIgUAT7FnZg3IIRgH1dOxV2h97RIzsRfMTuWSI7K9t+QfH192bVr13XjO3fupESJEtk6lqOjIw0aNCA8PDxjzGazER4entFX4UbGjx/Pu+++y7JlyzL1hQIIDg7G398/0zETEhKIjIzMOGbTpk2Ji4tj69atGXNWrVqFzWYjJCTkhu/p5OSEu7t7pk1E5FbGLd1ParpBy8olaVm5pNlxRERERKSA8XV3Zt7AEMp6F+PEhST6TIvkbMLV2+8oUkBkuyjVq1cvhg0bxurVq0lPTyc9PZ1Vq1bx3HPP0bNnz2wHGDFiBNOmTWPmzJns27ePZ555hsTERPr16wdAWFhYpkboH3zwAaNGjWL69OkEBQURHR1NdHQ0ly9fBsBisTB8+HDGjBnDr7/+yl9//UVYWBgBAQF06dIFgGrVqtG+fXsGDhzIpk2b+OOPPxgyZAg9e/bM0pP3RERuZ9PRCyzdHY3VAq93qmZ2HBEREREpoEp5uDBvYAilPV04EptIn68jib2cbHYskRyR7afvvfvuuxw7dozWrVtjb39td5vNRlhY2B31lOrRowfnzp3jzTffJDo6mrp167Js2bKMRuUnTpzAav1v7Wzq1KmkpKTQrVu3TMcZPXo0b731FgAvv/wyiYmJDBo0iLi4OJo1a8ayZcsy9Z2aO3cuQ4YMoXXr1litVrp27Xrd45hFRO6EzWYw5re9APRsXJbKfnqMr4hk9sgjj9zy9bi4uLwJIiIiBUIZr2LMH9iE7l9GcPDsZR77OpL5A5vg5epodjSRu2IxDMO4kx0PHjzIjh07cHFxoVatWpQrVy6ns+VrCQkJeHh4EB8fr1v5RCSTn7ZH8fzCnRR3smf1i60o6eZkdiQRyUE5sQb454rw2/n222/v6Pj5hdZLIiI568i5y/T4aiPnLiVTI8CdeQOa4FFMT3eW/Cera4A7LkoVdVpkiciNXElJ5/5JazgTf5WX21fh2VYVzY4kIjlMa4Cs02clIpLzDsZcoudXGzmfmEKdQE/m9G+Mm7MKU5K/ZHUNkO2eUl27duWDDz64bnz8+PE8+uij2T2ciEih8vX6I5yJv0ppTxeevPf6J5WKiIiIiNyNSn5uzB0YglcxB3aejKPvt5tJTE4zO5bIHcl2UWrdunV07NjxuvEOHTqwbt26HAklIlIQnU24ytS1hwF4pUNVnB3sTE4kIiIiIoVRVX93ZvcPwd3Znq3HL/LkjM1cSUk3O5ZItmW7KHX58mUcHa9vpubg4EBCQkKOhBIRKYgm/f43SSnp1CvryYO1S5kdR0REREQKsZqlPZjdPwQ3J3sij15g4KwtXE1VYUoKlmwXpWrVqsXChQuvG1+wYAHVq1fPkVAiIgXN3tMJfLf1JABvdKqOxWIxOZGIFCVjx46lUaNGuLm54evrS5cuXThw4MAt95k2bRrNmzfHy8sLLy8vQkND2bRpU6Y5hmHw5ptvUqpUKVxcXAgNDeXgwYO5eSoiIpINdQI9mfFkI4o52rHhUCxPzd5KcpoKU1JwZLsoNWrUKN59912eeOIJZs6cycyZMwkLC2PMmDGMGjUqNzKKiORrhmEw5re9GAY8ULsUDcp5mR1JRIqYtWvXMnjwYDZu3MiKFStITU2lbdu2JCYm3nSfNWvW0KtXL1avXk1ERASBgYG0bduWU6dOZcwZP348kydP5osvviAyMhJXV1fatWvH1atX8+K0REQkCxqU8+bbvo1wdrCy9u9zDJ67jZQ0m9mxRLLkjp6+99tvv/H++++zY8cOXFxcqFOnDqNHj8bb25uaNWvmRs58R0+TEZF/hO+Lof/MLTjaWwkf0ZJA72JmRxKRXFQQ1gDnzp3D19eXtWvX0qJFiyztk56ejpeXF1OmTCEsLAzDMAgICOCFF17gxRdfBCA+Ph4/Pz9mzJhBz549b3vMgvBZiYgUFn8ciuXJGZtJTrPRoaY/n/aqh71dtq9DEckRufb0PYBOnTrxxx9/kJiYyJEjR+jevTsvvvgiderUuePAIiIFUWq6jfeW7APgyXuDVZASkXwhPj4eAG9v7yzvk5SURGpqasY+R48eJTo6mtDQ0Iw5Hh4ehISEEBERkbOBRUTkrt1b0YcvH2+Ao52Vpbujef67naTbsn0NikieuuOy6bp163jiiScICAhg0qRJ3H///WzcuDEns4mI5HvzIk9w5FwiJVwdefa+CmbHERHBZrMxfPhw7r333mxdwf7KK68QEBCQUYSKjo4GwM/PL9M8Pz+/jNf+LTk5mYSEhEybiIjknVZVfPm8T33srRb+s/M0L/2wE5sKU5KP2WdncnR0NDNmzOCbb74hISGB7t27k5yczM8//6wm5yJS5MQnpfLxyr8BeL5NZdydHUxOJCICgwcPZvfu3WzYsCHL+4wbN44FCxawZs0anJ2d7/i9x44dy9tvv33H+4uIyN0Lre7HlN71GDxvO4u2ncLRzsr7D9fCatWDeCT/yfKVUg8++CBVqlRh165dfPzxx5w+fZpPP/00N7OJiORrU1Yf5GJSKpV8i9OzUaDZcUREGDJkCIsXL2b16tWUKVMmS/tMnDiRcePG8fvvv1O7du2McX9/fwBiYmIyzY+Jicl47d9GjhxJfHx8xnby5Mk7PBMREbkb7WuW4qMedbFaYMHmk4z+dQ930E5aJNdl+UqppUuXMmzYMJ555hkqVaqUm5lERPK94+cTmfHnMQBe71RNTSRFxFSGYTB06FB++ukn1qxZQ3BwcJb2Gz9+PO+99x7Lly+nYcOGmV4LDg7G39+f8PBw6tatC1xrWhoZGckzzzxzw+M5OTnh5OR0V+ciIiI5o3OdANLSbbzw/U5mbzyOg52VUQ9Uw2LRFVOSf2T5b1EbNmzg0qVLNGjQgJCQEKZMmUJsbGxuZhMRybc+WLaf1HSDFpVL0qqKr9lxRKSIGzx4MHPmzGHevHm4ubkRHR1NdHQ0V65cyZgTFhbGyJEjM37+4IMPGDVqFNOnTycoKChjn8uXLwNgsVgYPnw4Y8aM4ddff+Wvv/4iLCyMgIAAunTpktenKCIid+CR+mUY90gtAKb/cZRxy/briinJV7JclGrSpAnTpk3jzJkzPPXUUyxYsICAgABsNhsrVqzg0qVLuZlTRCTf2HzsAkv+isZqgdc7VjM7jogIU6dOJT4+nlatWlGqVKmMbeHChRlzTpw4wZkzZzLtk5KSQrdu3TLtM3HixIw5L7/8MkOHDmXQoEE0atSIy5cvs2zZsrvqOyUiInmrR6OyvNvl2oMvvlx7hI9W/G1yIpH/shh3USY9cOAA33zzDbNnzyYuLo42bdrw66+/5mS+fCshIQEPDw/i4+Nxd3c3O46I5JFTcVfo/kUEp+Ku0DukLO8/XMvsSCKSx7QGyDp9ViIi+cf0DUd5Z/FeAF5oU5mhrdWWR3JPVtcAd9UEpUqVKowfP56oqCjmz59/N4cSEcn3zl66ymNfR3Iq7grlfVx5sW0VsyOJiIiIiGTJk82CGdmhKgCTVvzNl2sPm5xI5C6LUv+ws7OjS5cuReYqKREpei4mpvD415s4GptIaU8X5gwIwdvV0exYIiIiIiJZ9lTLCrzQpjIAY5fuZ/qGoyYnkqJOj4sSEbmNhKuphE3fxIGYS/i5OzFvYAgBni5mxxIRERERybahrSsx7P6KALyzeC+zNx43OZEUZSpKiYjcQlJKGk9+u5m/TsXj7erI3AEhlCvhanYsEREREZE79nybyjzVsjwAo37ezcLNJ0xOJEWVilIiIjdxNTWdgbO2sOX4Rdyd7ZndvzEVfd3MjiUiIiIiclcsFguvtq/Kk/cGA/Dqor9YtC3K5FRSFKkoJSJyAylpNgbP3cYfh87j6mjHjCcbUyPAw+xYIiIiIiI5wmKxMOqBajzepByGAS9+v5P/7DxtdiwpYlSUEhH5l3SbwfMLdxC+/yxO9la+6duI+mW9zI4lIiIiIpKjLBYLb3euQc9GgdgMGL5wB8t2nzE7lhQhKkqJiPwPm83g5R928dtfZ3Cws/Dl4w1oUr6E2bFERERERHKF1Wrh/Ydr8Uj90qTbDIbM287KvTFmx5IiQkUpEZH/ZxgGo3/dw4/borCzWvi0V31aVfE1O5aIiIiISK6yWi1M6FaHznUCSLMZPDt3G2sOnDU7lhQBKkqJiHCtIDVu6X5mbzyOxQKTHq1D+5r+ZscSEREREckTdlYLH3avQ4ea/qSk2xg0eyt/HIo1O5YUcipKiYgAk8MP8eW6IwC8/3AtutQrbXIiEREREZG8ZW9n5ZOe9Qit5kdKmo3+MzcTeeS82bGkEFNRSkSKvGnrjvDRyr8BGPVAdXo1LmtyIhERERERczjaW/msTz1aVSnJ1VQb/WZsZuvxC2bHkkJKRSkRKdLmbDzOe0v2AfBi28r0bxZsciIREREREXM52dvxxWMNaFbRh6SUdPpO38zOk3Fmx5JCSEUpESmyftwaxRs/7wbg2VYVGHJ/JZMTiYiIiIjkD84OdkwLa0hIsDeXktN4/JtIdp+KNzuWFDIqSolIkbTkrzO89MNOAPreE8RL7aqYnEhEREREJH9xcbRjet9GNCjnRcLVNMKmb+Lspatmx5JCREUpESlyVu2PYdj87dgM6N6wDG8+UB2LxWJ2LBERERGRfMfVyZ4Z/RpR1d+NC4kpvP2fvWZHkkJERSkRKVL+PBTL03O2kWYzeLBOAGMfqY3VqoKUiIiIiMjNuDk7MPHROthZLfy26wwr98aYHUkKCRWlRKTI2Hr8AgNmbSElzUab6n582P3aL1YREREREbm1mqU9GPD/DwUa9ctuLl1NNTmRFAYqSolIkbD7VDx9p28mKSWd5pV8mNK7Hg52+iNQRERERCSrhodWpqx3Mc7EX2Xi8gNmx5FCQH8jE5FC7++YSzz+TSSXktNoHOTNV483xMnezuxYIiIiIiIFioujHe8/XAuAWRuPs/X4RZMTSUGnopSIFGpHYxPp83UkF5NSqVPGg2/6NsTFUQUpEREREZE70aySD13rl8EwYOSiXaSk2cyOJAWYilIiUmhFXUyiz7SNnLuUTFV/N2Y+2Rg3ZwezY4mIiIiIFGhvdKpGCVdH/o65zBdrD5sdRwowFaVEpFA6m3CVx76O5HT8VcqXdGV2/xA8izmaHUtEREREpMDzcnXkzQerAzBl1SEOnb1sciIpqFSUEpFC50JiCn2+juTY+SQCvV2YOyCEkm5OZscSERERESk0OtcJoFWVkqSk23ht0V/YbIbZkaQAUlFKRAqV+CupPP5NJAfPXsbf3Zl5A5pQysPF7FgiIiIiIoWKxWJhTJeaFHO0Y9OxCyzYfNLsSFIAqSglIoVGYnIa/b7dxJ7TCZRwdWTOgBACvYuZHUtEREREpFAq41WMF9pWAWDskn3EJFw1OZEUNCpKiUihcDU1nQEzt7DtRBweLg7M7h9CRd/iZscSERERESnU+t4TRJ0yHlxKTmP0L3vMjiMFjIpSIlLgpaTZeGbOViKOnMfV0Y6ZTzameoC72bFERERERAo9O6uFcV1rY2+1sGxPNMv3RJsdSQoQFaVEpEBLS7cxfOF2Vh84h7ODlel9G1E30NPsWCIiIiIiRUa1Uu4MalEegDd/2U3C1VSTE0lBoaKUiBRYNpvByz/sYslf0TjaWfny8YaElC9hdiwRERERkSJnWOtKBJUoRkxCMh8s3W92HCkgVJQSkQLJMAxG/bKbRdtPYWe1MKV3PVpWLml2LBERERGRIsnZwY73H6kFwNzIE2w+dsHkRFIQqCglIgWOYRi8v2QfcyNPYLHAh93r0LaGv9mxRERERESKtHsq+NCjYSAAr/64i+S0dJMTSX5nelHqs88+IygoCGdnZ0JCQti0adNN5+7Zs4euXbsSFBSExWLh448/vm7OP6/9exs8eHDGnFatWl33+tNPP50bpyciueDjlQeZtv4oAOMeqcVDdUubnEhERERERABe61gNn+JOHD6XyGerD5sdR/I5U4tSCxcuZMSIEYwePZpt27ZRp04d2rVrx9mzZ284PykpifLlyzNu3Dj8/W98VcTmzZs5c+ZMxrZixQoAHn300UzzBg4cmGne+PHjc/bkRCRXfLn2MJ+EHwRg9IPV6dGorMmJRERERETkHx7FHHirc3UApq45xN8xl0xOJPmZqUWpDz/8kIEDB9KvXz+qV6/OF198QbFixZg+ffoN5zdq1IgJEybQs2dPnJycbjinZMmS+Pv7Z2yLFy+mQoUKtGzZMtO8YsWKZZrn7q7Hx4vkd7MjjjH2/5smvtSuCv3uDTY5kYiIiIiI/FunWqUIreZLarrByEV/YbMZZkeSfMq0olRKSgpbt24lNDT0v2GsVkJDQ4mIiMix95gzZw5PPvkkFosl02tz587Fx8eHmjVrMnLkSJKSknLkPUUkd/ywNYpRv+wBYPB9FRh8X0WTE4mIiIiIyI1YLBbeeagmro52bD1+kbmRx82OJPmUvVlvHBsbS3p6On5+fpnG/fz82L8/Zx4f+fPPPxMXF0ffvn0zjffu3Zty5coREBDArl27eOWVVzhw4ACLFi266bGSk5NJTk7O+DkhISFHMorI7S3edZqXf9gJQL97g3ixbRWTE4mIiIiIyK0EeLrwcvuqjP51Dx8sO0BodT9KebiYHUvyGdOKUnnhm2++oUOHDgQEBGQaHzRoUMa/16pVi1KlStG6dWsOHz5MhQoVbnissWPH8vbbb+dqXhG5Xvi+GIYv2IHNgJ6NAnnzgerXXfkoIiIiIiL5z2NNyvHzjlNsPxHHqJ/3MC2sgdbykolpt+/5+PhgZ2dHTExMpvGYmJibNjHPjuPHj7Ny5Ur+r707D6uyzv8//jrnsCugiCwqirjvGiKhuZQmaZtKU5mlWVY22GR8m2/aoq2DzfhNm8mxJkub0tGs1Eqz1BTL3EJRUNwXcEFRYxGU5Zz790e/YYYUBQVuDjwf13VfF+fmc9/n9eHj0Tdv73OfcePGXXVsZGSkJOnAgQNljpk8ebKys7NLtvT09OvOCODKftx/Rk/O36Zih6G7uzfRG8O78I8YAAAA4CRsVovejOkqV5tFq1NP6ZuUDLMjoYYxrSnl5uam8PBwrVmzpmSfw+HQmjVrFBUVdd3nnzt3rgICAnT77bdfdWxSUpIkKTg4uMwx7u7u8vHxKbUBqDo/Hzmnx/75swqLHRrcMVDTf9dNNisNKQAAAMCZtA301pP9f31H0tQvdyk7v8jkRKhJTP30vbi4OL3//vv66KOPlJqaqieffFJ5eXkaO3asJGn06NGaPHlyyfjCwkIlJSUpKSlJhYWFOn78uJKSki65wsnhcGju3LkaM2aMXFxKv0Px4MGDeu2115SYmKgjR47oyy+/1OjRo9WvXz917dq16icN4Kp2HsvS2LlbdaHIrn5tG+tvD/SQq83Uv64AAAAAXKPf39xaYY3rKTO3QPHfpJodBzWIqfeUuu+++5SZmakpU6YoIyND3bt318qVK0tufp6Wliar9T+/iJ44cUI9evQoeTx9+nRNnz5d/fv317p160r2r169WmlpaXrkkUcueU43NzetXr1aM2fOVF5enkJCQhQTE6MXX3yx6iYKoNz2ZuRq9IdblFtQrF4t/fTeg+Fyd7GZHQsAAADANfJwtWnaiK66972NWrg1XcN6NNWNYY3MjoUawGIYhmF2CGeUk5MjX19fZWdn81Y+oJIcyjyve9/bpDPnC9Q9pIE+GRep+u61+vMYADghaoDy42cFAPhvzy9J1oLNaQrzr6cVT/eVhyv/+VxblbcG4P0wAGqE9HP5GjVns86cL1CHYB99NLYXDSkAAACgFpk0pL0CvN116Eye3vm+7A8aQ91BUwqA6U7lXNSDH2zWyeyLatW4nj5+tJd8vVzNjgUAAACgEvl4uOrVuztJkt5NOKjUkzkmJ4LZaEoBMNXZ8wUaNWezjp7NV4ifp+aPu1H+9d3NjgUAAACgCtzWOViDOwaq2GFo0hfJsju4o1BdRlMKgGmyLxTpoQ+26MDp8wr29dCCcTcqyNfD7FgAAAAAqtCrd3eWt7uLdqRn6Z8bj5gdByaiKQXAFOcLivXw3C3afTJH/vXd9Mm4SIX4eZkdCwAAAEAVC/L10HND2kuS/vLtXh3PumByIpiFphSAanexyK5xH23V9rQs+Xq66uNHI9WqcX2zYwEAAACoJg/0aq6I0IbKL7TrxSXJMgzexlcX0ZQCUK0Kiu0a/0miNh06p/ruLvrnI73UIZiPCQcAAADqEqvVovgRXeRms2rt3kx9tfOk2ZFgAppSAKpNsd2hp/+VpHV7M+XhatWHD0eoW0gDs2MBAAAAMEHrAG/F3txakvTqV7uUlV9ociJUN5pSAKqFw2Hoj5/t1MpdGXKzWfX+6J7q1dLP7FgAAAAATPTkgFZqE1BfZ84X6o3lqWbHQTWjKQWgyhmGoReWpmjJ9uNysVo0a9QN6tumsdmxAAAAAJjMzcWqaTFdZLFIixOPacOBM2ZHQjWiKQWgShmGodeXp+pfW9JksUgz7uuuWzsGmh0LAAAAQA0R3sJPD0a2kCQ9vyRZF4vsJidCdaEpBaBKzVi1Tx/8eFiS9GZMV93ZrYnJiQAAAADUNP97WzsF+Xjo6Nl8zVy93+w4qCY0pQBUmdnrDuqv3x+QJL1yVyfd2zPE5EQAAAAAaiJvD1e9NqyzJOn9Hw5p14lskxOhOtCUAlAlPvrpiN5cuUeS9Nxt7TWmd6i5gQAAAADUaLd2DNTQLkGyOwxN+jxZxXaH2ZFQxWhKAah0n/6crqlf7pIkPXVLaz05oJXJiQAAAAA4g5fv7CRvDxclH8/WvJ+OmB0HVYymFIBK9dWOE5r0+U5J0qM3tVTcrW1NTgQAAADAWQT4eOiFoR0kSf/33T6ln8s3ORGqEk0pAJVm1e5TemZRkhyGNLJXc714ewdZLBazYwEAAABwIvdFhCiypZ8uFNn1wtIUGYZhdiRUEZpSACrFD/szFTt/m4odhob3aKo3hnWmIQUAAACgwiwWi+JHdJGbi1Xr92VqadJxsyOhitCUAnDdthw+p8f++bMK7Q7d1ilIf7mnq6xWGlIAAAAArk1Y4/r6wy2tJUmvfZ2qc3mFJidCVaApBeC67EjP0iPztupikUMD2jXWX0f2kIuNv1oAAAAAXJ/H+7VS+yBvncsr1Otf7zY7DqoAvzkCuGapJ3M0+sMtOl9QrBvD/PTug+Fyc+GvFQAAAADXz83FqvgRXWSxSF9sP671+zLNjoRKxm+PAK7JwczzeuiDzcq+UKQezRtozpgIebjazI4FAAAAoBbp0byhxkSFSpKeX5Ks/MJicwOhUtGUAlBh6efyNer9zTpzvlAdg300b2wv1Xd3MTsWAAAAgFro2eh2auLroWO/XNCMVfvMjoNKRFMKQIVkZF/UqDmblZFzUa0D6uvjR3vJ19PV7FgAAAAAaqn67i56fXhnSdIHPx5W8rFskxOhstCUAlBuZ84XaNScTUo7l6/mfl6aPy5Sjeq7mx0LAAAAQC13S/tA3dmtiRyG9NznO1Vkd5gdCZWAphSAcsnOL9JDH2zRwcw8NfH10PxxkQr08TA7FgAAAIA6YsodHeXr6ardJ3P0wY+HzY6DSkBTCsBVnS8o1pi5W5R6Mkf+9d31ybhIhfh5mR0LAAAAQB3S2NtdL9zeQZI0Y9U+HT2bZ3IiXC+aUgCu6EKhXY/M26qk9Cw18HLV/HGRCmtc3+xYAAAAAOqg34U3U+9WjVRQ7NDzS5JlGIbZkXAdaEoBKFNBsV1PfJKoLYfPydvdRR8/Eql2Qd5mxwIAAABQR1ksFv1peBe5u1i14cBZfZZ4zOxIuA40pQBcVpHdoacWbNf6fZnydLVp7tgIdWnma3YsAAAAAHVcqH89TRzUVpL0xopUnTlfYHIiXCuaUgAuYXcYenbxDn23+5TcXKyaM6aneob6mR0LAAAAACRJ4/q2VIdgH2XlF+nVr3abHQfXiKYUgFIMw9ALS5K1LOmEXKwWzR51g/q09jc7FgAAAACUcLVZ9WZMF1kt0pc7TmjtntNmR8I1oCkFoIRhGHr1691auDVdVos08/7uGtgh0OxYAAAAAHCJrs0a6JE+LSVJLy5NUV5BscmJUFE0pQCU+L/v9mnuhiOSpD/f0013dG1ibiAAAAAAuIK4wW3VrKGnjmdd0PTv9podBxVEUwqAJGnW2gN6Z+0BSdJrd3fSPeHNTE4EAAAAAFfm5eaiN4Z3kSTN++mIktKzzA2ECqEpBUBzNxzWX7799X8VJg9pr4eiQs0NBAAAAADl1L9tYw3v0VSGIU36fKeK7A6zI6GcaEoBddyirWl65f9/WsUfBrbRE/1bmZwIAAAAACrmxds7qKGXq/Zk5Oof6w+ZHQflRFMKqMOWJR3XpC+SJUmP9W2pZwa1MTkRAAAAAFRco/rueumOjpKkt9fs16HM8yYnQnnQlALqqO92ZSju0x0yDGlUZHM9P7SDLBaL2bEAABUUHx+viIgIeXt7KyAgQMOGDdPevVe+0euuXbsUExOj0NBQWSwWzZw585IxL7/8siwWS6mtffv2VTQLAACu3/AeTdW3jb8Kix16fkmyDMMwOxKugqYUUAcl7MvUhAXbZXcYGtGjqV67uzMNKQBwUgkJCYqNjdWmTZu0atUqFRUVafDgwcrLyyvzmPz8fIWFhWnatGkKCgoqc1ynTp108uTJku3HH3+siikAAFApLBaL/jS8izxdbdp06Jw+/Tnd7Ei4ChezAwCoXpsPndUTH/+sQrtDQ7sE6c/3dJXVSkMKAJzVypUrSz2eN2+eAgIClJiYqH79+l32mIiICEVEREiSJk2aVOa5XVxcrti0AgCgpgnx81LcrW31xopUvbE8VTe3D1CAt4fZsVAGrpQC6pCk9Cw9Mm+rLhY5dHO7xpp5Xw+52PhrAABqk+zsbEmSn5/fdZ9r//79atKkicLCwjRq1CilpaVdcXxBQYFycnJKbQAAVLexfULVpamvci4W65Uvd5sdB1fAb6NAHbH7RI5Gf7BZeYV29W7VSLMfDJebC38FAEBt4nA4NHHiRPXp00edO3e+rnNFRkZq3rx5WrlypWbPnq3Dhw+rb9++ys3NLfOY+Ph4+fr6lmwhISHXlQEAgGvhYrMqfkQX2awWLU8+qdW7T5kdCWXgN1KgDjhw+rwe+mCzci4W64bmDfT+6J7ycLWZHQsAUMliY2OVkpKihQsXXve5hgwZot/97nfq2rWroqOjtWLFCmVlZenTTz8t85jJkycrOzu7ZEtP514eAABzdG7qq3F9W0qSXlqWotyLRSYnwuXQlAJqufRz+XpwzmadzStU56Y+mju2l+q5czs5AKhtJkyYoK+//lpr165Vs2bNKv38DRo0UNu2bXXgwIEyx7i7u8vHx6fUBgCAWSYObKvmfl46mX1Rf/n2yp9MC3PQlAJqsZPZF/TAnE3KyLmoNgH19c9HIuXr6Wp2LABAJTIMQxMmTNCSJUv0/fffq2XLllXyPOfPn9fBgwcVHBxcJecHAKCyebrZ9KfhXSRJH286qsSjv5icCL9FUwqopTJzCzRqzmaln7ugFo28NH9cpPzquZkdCwBQyWJjY/XJJ59owYIF8vb2VkZGhjIyMnThwoWSMaNHj9bkyZNLHhcWFiopKUlJSUkqLCzU8ePHlZSUVOoqqGeffVYJCQk6cuSIfvrpJw0fPlw2m00jR46s1vkBAHA9bmrjr3vCm8kwpMlf7FRhscPsSPgvpjelZs2apdDQUHl4eCgyMlJbtmwpc+yuXbsUExOj0NBQWSwWzZw585IxL7/8siwWS6mtffv2pcZcvHhRsbGxatSokerXr6+YmBidOsWNz1B7ZOUX6qEPNutQZp6a+Hpo/rhIBfjwMagAUBvNnj1b2dnZGjBggIKDg0u2RYsWlYxJS0vTyZMnSx6fOHFCPXr0UI8ePXTy5ElNnz5dPXr00Lhx40rGHDt2TCNHjlS7du107733qlGjRtq0aZMaN25crfMDAOB6vTC0gxrVc9O+U+f1bsJBs+Pgv5h6Y5lFixYpLi5O7777riIjIzVz5kxFR0dr7969CggIuGR8fn6+wsLC9Lvf/U7PPPNMmeft1KmTVq9eXfLYxaX0NJ955hktX75cixcvlq+vryZMmKARI0Zow4YNlTc5wCS5F4s05sMt2pORq8be7pr/2I1q1tDL7FgAgCpiGMZVx6xbt67U49DQ0KseVxk3SwcAoCZoWM9NU+7sqKcXJumd7w9oaJcgtQ7wNjsWZPKVUm+99ZYee+wxjR07Vh07dtS7774rLy8vffjhh5cdHxERob/85S+6//775e7uXuZ5XVxcFBQUVLL5+/uXfC87O1sffPCB3nrrLd1yyy0KDw/X3Llz9dNPP2nTpk2VPkegOl0otOvReT9rx7FsNfRy1fxxkWrpX8/sWAAAAABgqru6NdGAdo1VaHdo8hfJcjiu/p86qHqmNaUKCwuVmJioQYMG/SeM1apBgwZp48aN13Xu/fv3q0mTJgoLC9OoUaOUlpZW8r3ExEQVFRWVet727durefPmV3zegoIC5eTklNqAmqSg2K7HP/5ZW46ck7e7iz5+NFJtA+n+AwAAAIDFYtHrwzrLy82mrUd+0b+2pl39IFQ505pSZ86ckd1uV2BgYKn9gYGBysjIuObzRkZGat68eVq5cqVmz56tw4cPq2/fvsrNzZUkZWRkyM3NTQ0aNKjQ88bHx8vX17dkCwkJueaMQGUrsjs0YcF2/bD/jLzcbJr3SIQ6N/U1OxYAAAAA1BjNGnrp2cHtJEnTVuzRqZyLJieC6Tc6r2xDhgzR7373O3Xt2lXR0dFasWKFsrKy9Omnn17XeSdPnqzs7OySLT09vZISA9fH7jAU9+kOrdp9Sm4uVs0Z3VPhLfzMjgUAAAAANc6Y3qHqFtJAuQXFmrIsxew4dZ5pTSl/f3/ZbLZLPvXu1KlTCgoKqrTnadCggdq2bVvyEcdBQUEqLCxUVlZWhZ7X3d1dPj4+pTbAbA6Hoclf7NRXO07I1WbRuw/eoN6t/a9+IAAAAADUQTarRdNGdJGL1aJvd53SypRrf6cWrp9pTSk3NzeFh4drzZo1JfscDofWrFmjqKioSnue8+fP6+DBgwoODpYkhYeHy9XVtdTz7t27V2lpaZX6vEBVMwxDr369W5/+fExWi/T2/T10S/vAqx8IAAAAAHVYh2AfPdE/TJI0ZVmKci4WmZyo7jL17XtxcXF6//339dFHHyk1NVVPPvmk8vLyNHbsWEnS6NGjNXny5JLxhYWFSkpKUlJSkgoLC3X8+HElJSWVXAUlSc8++6wSEhJ05MgR/fTTTxo+fLhsNptGjhwpSfL19dWjjz6quLg4rV27VomJiRo7dqyioqJ04403Vu8PALgOf/l2r+b9dOTXr+/ppqFdgs0NBAAAAABO4qlb2qilfz2dzi3Qm9/sMTtOneVi5pPfd999yszM1JQpU5SRkaHu3btr5cqVJTc/T0tLk9X6n77ZiRMn1KNHj5LH06dP1/Tp09W/f3+tW7dOknTs2DGNHDlSZ8+eVePGjXXTTTdp06ZNaty4cclxM2bMkNVqVUxMjAoKChQdHa2///3v1TNpoBLMWntAf193UJL0+rDOiglvZnIiAAAAAHAeHq42/Wl4F418f5Pmb07T3d2bqldL7s1b3SyGYRhmh3BGOTk58vX1VXZ2NveXQrX64MfDeu3r3ZKkF4Z20GP9wkxOBAB1CzVA+fGzAgDUdM99tlOLfk5Xq8b1tOLpvnJ3sZkdqVYobw1Q6z59D6jN/rUlraQhNXFQGxpSAAAAAHAdnh/aQf713XUwM0+z1h40O06dQ1MKcBJLtx/X80uSJUlP9AvT0wPbmJwIAAAAAJybr5erXrmrkyRp9roD2ncq1+REdQtNKcAJrEzJ0P8s3iHDkB66sYUmDWkvi8VidiwAAAAAcHpDuwRpUIcAFdkNTfp8pxwO7nJUXWhKATXcur2n9dS/tsnuMBRzQzO9clcnGlIAAAAAUEksFotevbuz6rnZtC0tS59sPmp2pDqDphRQg206dFZPfJyoIruh27sE682YLrJaaUgBAAAAQGVq0sBTzw1pL0n688q9Opl9weREdQNNKaCG2pb2ix6dt1UFxQ4NbB+gGfd1l4uNlywAAAAAVIUHI1vohuYNdL6gWC8tTZFh8Da+qsZvuEANtOtEth7+cIvyCu3q07qRZo26QW4uvFwBAAAAoKpYrRZNi+kqV5tFq1NPa0VyhtmRaj1+ywVqmAOnczX6gy3KuVisni0a6v3RPeXhajM7FgAAAADUem0DvfVk/1aSpKlf7lJ2fpHJiWo3mlJADXL0bJ5Gzdmss3mF6tLUVx+OjZCXm4vZsQAAAACgzoi9pbVaNa6nM+cLFP9NqtlxajWaUkANcSLrgh54f7NO5RSoXaC3/vlIL/l4uJodCwAAAADqFHcXm6bFdJUkLdyaro0Hz5qcqPaiKQXUAJm5BXpwzmYdz7qg0EZe+nhcLzWs52Z2LAAAAACokyJC/fRAZHNJ0vNLknWxyG5yotqJphRgsl/yCvXgnM06dCZPTRt4av5jNyrA28PsWAAAAABQp00a0l4B3u46fCZPf/t+v9lxaiWaUoCJci4WaczcLdp7KlcB3u6aPy5STRt4mh0LAAAAAOo8Hw9XvXp3Z0nSewmHlHoyx+REtQ9NKcAk+YXFenTeVu08li2/em6aPy5Sof71zI4FAAAAAPj/buscpOhOgSp2GJr0+U7ZHYbZkWoVmlKACS4W2fX4PxO19cgv8vZw0T8f6aU2gd5mxwIAAAAA/Mard3eWt7uLdhzL1kc/HTE7Tq1CUwqoZkV2hyYs2KYfD5yRl5tN88b2UuemvmbHAgAAAABcRqCPh54b0l6SNP27vTr2S77JiWoPmlJANbI7DD2zKEmrU0/L3cWqD8ZEKLxFQ7NjAQAAAACu4IFezRUR2lD5hXa9tDRFhsHb+CoDTSmgmjgchp77fKe+3nlSrjaL3n0oXFGtGpkdCwAAAABwFVarRfEjusrNZtXavZn6cscJsyPVCjSlgGpgGIZe+WqXPks8JpvVor+N7KGb2wWYHQsAAAAAUE6tA+or9ubWkqRXv9qtX/IKTU7k/GhKAVXMMAy9uXKvPtp4VBaLNP13XXVb52CzYwEAAAAAKujJAa3UJqC+zuYV6o0VqWbHcXo0pYAqdDL7gsZ99LPeTTgoSXpjWBcN79HM5FQAAAAAgGvh5mLVtJiuslikzxKP6cf9Z8yO5NRoSgFVwDAMLdicpsFvrdeaPaflZrPqtbs76YHI5mZHAwAAAABch/AWDfXQjS0kSc8vSdaFQrvJiZwXTSmgkh09m6cH3t+s55ckK7egWN1DGmj5H27SQ1GhZkcDAAAAAFSCP0a3U5CPh9LO5Wvmmn1mx3FaNKWASmJ3GJrzwyFFz1yvjYfOysPVqhdv76DPn+ytNoHeZscDAAAAAFQSbw9XvTassyRpzg+HlXI82+REzommFFAJ9p/K1T3v/qTXl6fqYpFDUWGN9O3EfhrXN0w2q8XseAAAAACASnZrx0Dd3iVYdoehyV8kq9juMDuS06EpBVyHIrtDf1uzX7f/9UdtT8uSt7uL4kd00YLHItWiUT2z4wEAAAAAqtDUuzrKx8NFycezNXfDEbPjOB2aUsA1Sjmerbve2aD/W7VPhXaHbmkfoO/i+mlkr+ayWLg6CgAAAABquwBvDz0/tIMk6a1V+5R+Lt/kRM6FphRQQReL7Hpz5R7dPWuDUk/mqKGXq96+v7s+GNNTwb6eZscDAAAAAFSj+yJCFNnSTxeK7Hp+SbIMwzA7ktOgKQVUwNYj5zT07R80e91B2R2G7ugarFVx/XV396ZcHQUAAAAAdZDFYlH8iC5yc7Hqh/1ntDTpuNmRnAZNKaAc8gqKNXVZiu59b6MOnclTgLe73nsoXO88cIP867ubHQ8AAAAAYKKwxvX19MA2kqRXv9qts+cLTE7kHGhKAVfxw/5MDZ6xXh9tPCrDkO7t2Uyrnumv6E5BZkcDAAAAANQQj/cLU/sgb/2SX6TXl6eaHccp0JQCypCdX6Q/Lt6hhz7YouNZF9S0gac+frSX/nxPN/l6uZodDwAAAABQg7jarIof0UUWi7Rk+3El7Ms0O1KNR1MKuIxvd2Vo0IwELU48JotFerh3qL57pp/6tmlsdjQAAAAAQA3Vo3lDPdw7VJL0wpJk5RcWmxuohqMpBfyXM+cLFLtgm574OFGZuQUKa1xPi5+I0st3dVI9dxez4wEAAAAAarhnB7dT0waeOvbLBb313T6z49RoNKUASYZhaOn247r1rQQt33lSNqtFTw5opRV/6KueoX5mxwMAAAAAOIl67i56fVhnSdKHGw5r57EscwPVYDSlUOedzL6gRz/6WRMXJemX/CJ1CPbRstg+eu629vJwtZkdDwAAAADgZG5uH6A7uzWRw5AmfZ6sIrvD7Eg1Ek0p1FmGYWjB5jQNfmu9vt9zWm42q/7n1rb6ckIfdW7qa3Y8AAAAAIATm3pnRzXwctXukzn64MfDZsepkWhKoU46ejZPD7y/Wc8vSVZuQbF6NG+g5X+4SU8NbCNXGy8LAAAAAMD18a/vrheGdpAkzVi1T0fO5JmcqObht2/UKXaHoTk/HFL0zPXaeOisPFyteumOjvpsfG+1CfQ2Ox4AAAAAoBa5J7yZ+rRupIJih15YmizDMMyOVKPQlEKdse9UrmJm/6TXl6fqYpFDvVs10ncT++vRm1rKZrWYHQ8AAAAAUMtYLBa9MayL3F2s2nDgrD5LPGZ2pBqFphRqvSK7Q39ds193/PVHJaVnydvdRfEjumj+uEg1b+RldjwAAAAAQC0W6l9Pz9zaVpL0+vJUZeYWmJyo5qAphVot+Vi27vzbj3pr1T4V2h0a2D5A38X108hezWWxcHUUAAAAAKDqjbuppToG+yj7QpFe/Xq32XFqDJpSqJUuFtk17Zs9Gvb3DdqTkauGXq56+/7umjOmp4J9Pc2OBwAAAACoQ1xsVr0Z01VWi/TVjhNau+e02ZFqBJpSqHW2HjmnoW//oHcTDsruMHRH12Ctiuuvu7s35eooAAAAAIApujTz1aM3tZQkvbg0RXkFxSYnMh9NKdQaeQXFmrosRfe+t1GHzuQpwNtd/3goXO88cIP867ubHQ8AAAAAUMc9c2tbNWvoqeNZFzT9u71mxzEdTSnUCuv3ZWrwjPX6aONRGYZ0b89mWhXXX4M7BZkdDQAAAAAASZKXm4v+NLyLJGneT0e0Pe0XkxOZy/Sm1KxZsxQaGioPDw9FRkZqy5YtZY7dtWuXYmJiFBoaKovFopkzZ14yJj4+XhEREfL29lZAQICGDRumvXtLdx8HDBggi8VSahs/fnxlTw3VIDu/SH9cvEOjP9yi41kX1Kyhpz5+tJf+fE83+Xq6mh0PAAAAAIBS+rVtrOE9msowpMlfJKvI7jA7kmlMbUotWrRIcXFxmjp1qrZt26Zu3bopOjpap09f/oZf+fn5CgsL07Rp0xQUdPkrYBISEhQbG6tNmzZp1apVKioq0uDBg5WXl1dq3GOPPaaTJ0+WbH/+858rfX6oWt/uytCgGQlanHhMFov0cO9QfTuxn/q2aWx2NAAAAAAAyvTSHR3lV89NezJy9Y/1h8yOYxoXM5/8rbfe0mOPPaaxY8dKkt59910tX75cH374oSZNmnTJ+IiICEVEREjSZb8vSStXriz1eN68eQoICFBiYqL69etXst/Ly6vMxhZqtszcAr385S4tTz4pSQprXE9/jumqnqF+JicDAAAAAODq/Oq56aU7OuiZRTv09pr9GtI5SGGN65sdq9qZdqVUYWGhEhMTNWjQoP+EsVo1aNAgbdy4sdKeJzs7W5Lk51e6YTF//nz5+/urc+fOmjx5svLz8yvtOVE1DMPQku3HdOuMBC1PPimb1aLfD2ilFX/oS0MKAAAAAOBUhnVvqn5tG6uw2KHJXyTL4TDMjlTtTLtS6syZM7Lb7QoMDCy1PzAwUHv27KmU53A4HJo4caL69Omjzp07l+x/4IEH1KJFCzVp0kQ7d+7Uc889p7179+qLL74o81wFBQUqKCgoeZyTk1MpGVE+J7Iu6MWlKfp+z69v7ewQ7KO/3NNVnZv6mpwMAAAAAICKs1gsemNYZw2esV6bD5/Tpz+n6/5ezc2OVa1MffteVYuNjVVKSop+/PHHUvsff/zxkq+7dOmi4OBgDRw4UAcPHlSrVq0ue674+Hi98sorVZoXl3I4DP1ra5riV+zR+YJiudms+sPA1nqifyu52ky/Tz8AAAAAANcsxM9L/zO4rV5fnqo/rUjVLR0CFODtYXasamPab/X+/v6y2Ww6depUqf2nTp2qlHs9TZgwQV9//bXWrl2rZs2aXXFsZGSkJOnAgQNljpk8ebKys7NLtvT09OvOiCs7ejZPD8zZpBeWpOh8QbF6NG+g5X+4SRNuaUNDCgAAAABQKzzcO1Rdmvoq52KxXvlyt9lxqpVpv9m7ubkpPDxca9asKdnncDi0Zs0aRUVFXfN5DcPQhAkTtGTJEn3//fdq2bLlVY9JSkqSJAUHB5c5xt3dXT4+PqU2VA27w9CcHw4peuZ6bTp0Tp6uNr10R0d9Nr632gR6mx0PAAAAAIBK42KzalpMF9msFi1PPqlVu09d/aBawtS378XFxWnMmDHq2bOnevXqpZkzZyovL6/k0/hGjx6tpk2bKj4+XtKvN0ffvXt3ydfHjx9XUlKS6tevr9atW0v69S17CxYs0LJly+Tt7a2MjAxJkq+vrzw9PXXw4EEtWLBAQ4cOVaNGjbRz504988wz6tevn7p27WrCTwH/bd+pXP3vZzuVlJ4lSerdqpGmjeiq5o28zA0GAAAAAEAV6dTEV+P6ttR7CYf00tIU3RjmJ28PV7NjVTmLYRim3t79nXfe0V/+8hdlZGSoe/fu+utf/1rydroBAwYoNDRU8+bNkyQdOXLkslc+9e/fX+vWrZP0643CLmfu3Ll6+OGHlZ6ergcffFApKSnKy8tTSEiIhg8frhdffLFCVz/l5OTI19dX2dnZXDVVCQqLHXo34aD+9v1+FdkNebu76IXbO+i+iJAy1xQAADNQA5QfPysAAMrvQqFdt729XkfP5mt0VAu9enfnqx9UQ5W3BjC9KeWsKLIqT/KxbP3xsx3ak5ErSRrYPkCvD++sYF9Pk5MBAHApaoDy42cFAEDFbDhwRqPmbJbFIn02PkrhLfzMjnRNylsDcLdomOZikV3TvtmjYX/foD0ZuWro5aq37++uOWN60pACAAAAANQ5fVr7657wZjIMadLnySootpsdqUrRlIIpth45p6Fv/6B3Ew7K7jB0Z7cmWhXXX3d3b8rb9QAAAAAAddYLQzuoUT037T99Xu+uO2R2nCpFUwrV6nxBsaYuS9G9723UoTN5CvB21/uje+pvI3vIv7672fEAAAAAADBVw3pumnpXJ0nSrLUHdOB0rsmJqg5NKVSb9fsyFT1jvT7aeFSGId3XM0Sr4vrr1o6BZkcDAAAAAKDGuLNrsG5u11iFdocmfZ4sh6N23g6cphSqXHZ+kZ5dvEOjP9yi41kX1Kyhpz55NFJv3tNVvp61/yMuAQAAAACoCIvFoteHd5GXm00/H/1FC7akmR2pStCUQpVamZKhQTMS9FniMVks0sO9Q/XtxH66qY2/2dEAAAAAAKixmjbw1LOD20mS3vxmjzKyL5qcqPLRlEKVyMwtUOz8bRr/SaIycwsU1rieFj8RpZfv6qR67i5mxwMAAAAAoMYb0ztU3UIaKLegWFO/TDE7TqWjKYVKZRiGlmw/pltnJGh58knZrBbF3txKK/7QVz1D/cyOBwAAAACA07BZLXozpotcrBZ9u+uUVqacNDtSpaIphUpzIuuCHpm3Vc8s2qGs/CJ1DPbRstg++mN0e3m42syOBwAAAACA02kf5KMn+odJkqYs26XsC0UmJ6o8NKVw3RwOQ/M3H9XgGeu1dm+m3GxW/TG6nZZN6KPOTX3NjgcAAAAAgFN76pY2aulfT6dzC/Tmyj1mx6k0NKVwXY6cydMDczbphSUpOl9QrBuaN9CKp29S7M2t5WrjjxcAAAAAANfLw9Wm+BFdJEkLNqdpy+FzJieqHHQNcE3sDkPvrz+k295er02HzsnT1aYpd3TU4vG91TrA2+x4AAAAAADUKjeGNdL9ESGSpElf7NTFIrvJia4fTSlU2L5TuRox+ye9sSJVF4sc6t2qkb6d2E+P3NRSNqvF7HgAAAAAANRKk4d0kH99dx3KzNPf1x4wO851oymFcissdujt1ft1+19/0I70LHm7u2jaiC6aPy5SzRt5mR0PAAAAAIBazdfLVa/c1UmSNDvhoPadyjU50fWhKYVy2XksS3e986NmrN6nIruhQR0CtCquv+7v1VwWC1dHAQBglvj4eEVERMjb21sBAQEaNmyY9u7de8Vjdu3apZiYGIWGhspisWjmzJmXHTdr1iyFhobKw8NDkZGR2rJlSxXMAAAAVMTQLkEa1CFQRXZDz32+U3aHYXaka0ZTCld0sciu+G9SNWzWBu3JyJVfPTe9fX93vT+6p4J8PcyOBwBAnZeQkKDY2Fht2rRJq1atUlFRkQYPHqy8vLwyj8nPz1dYWJimTZumoKCgy45ZtGiR4uLiNHXqVG3btk3dunVTdHS0Tp8+XVVTAQAA5WCxWPTasE6q7+6i7WlZ+mTTUbMjXTOLYRjO21IzUU5Ojnx9fZWdnS0fHx+z41SJLYfP6bnPd+rwmV+L2ju7NdHLd3ZUo/ruJicDAMA8Nb0GyMzMVEBAgBISEtSvX7+rjg8NDdXEiRM1ceLEUvsjIyMVERGhd955R5LkcDgUEhKip556SpMmTSpXlpr+swIAwJn9c+MRTVm2S/XcbFoV119NGniaHalEeWsArpTCJc4XFGvKshTd+95GHT6TpwBvd70/uqf+NrIHDSkAAGq47OxsSZKfn981n6OwsFCJiYkaNGhQyT6r1apBgwZp48aN150RAABcvwcjW+iG5g2UV2jXlGUpcsZrjmhKoZT1+zIVPWO9/rnx18v/7usZolVx/XVrx0CTkwEAgKtxOByaOHGi+vTpo86dO1/zec6cOSO73a7AwNL//gcGBiojI6PM4woKCpSTk1NqAwAAVcNqtWhaTFe52ixanXpaK5LL/je6pqIpBUlSdn6Rnl28Q6M/3KLjWRcU4uep+eMi9eY9XeXr6Wp2PAAAUA6xsbFKSUnRwoULTXn++Ph4+fr6lmwhISGm5AAAoK5oG+itJwe0liRN/XKXsvOLTE5UMTSloJUpJzVoRoI+Szwmi0Ua2ydU307spz6t/c2OBgAAymnChAn6+uuvtXbtWjVr1uy6zuXv7y+bzaZTp06V2n/q1Kkyb4wuSZMnT1Z2dnbJlp6efl05AADA1cXe3EqtGtfTmfMF+tOKVLPjVAhNqTosM7dAv5+fqPGfbFNmboFaNa6nz8ZHaeqdneTl5mJ2PAAAUA6GYWjChAlasmSJvv/+e7Vs2fK6z+nm5qbw8HCtWbOmZJ/D4dCaNWsUFRVV5nHu7u7y8fEptQEAgKrl7mLTtJiukqRFP6dr48GzJicqPzoPdZBhGFqy/bhe/Xq3svKLZLNaNL5/mJ66pY08XG1mxwMAABUQGxurBQsWaNmyZfL29i6555Ovr688PX/9FJ7Ro0eradOmio+Pl/Trjcx3795d8vXx48eVlJSk+vXrq3XrX98CEBcXpzFjxqhnz57q1auXZs6cqby8PI0dO9aEWQIAgCuJCPXTqMjmmr85Tc8vSdY3T/d1it/vaUrVMSeyLuj5JclatzdTktQx2Ed/vqerOjf1NTkZAAC4FrNnz5YkDRgwoNT+uXPn6uGHH5YkpaWlyWr9zwXyJ06cUI8ePUoeT58+XdOnT1f//v21bt06SdJ9992nzMxMTZkyRRkZGerevbtWrlx5yc3PAQBAzfDckPZanXpKh8/k6a9r9ut/b2tvdqSrshjO+JmBNUBOTo58fX2VnZ3tFJemOxyGFmxJ07Rv9uh8QbHcbFY9PaiNHu8XJlcb7+IEAKC8nK0GMBM/KwAAqtfKlAyN/yRRLlaLvnrqJnUINuff3/LWAHQj6oAjZ/I08v1NenFpis4XFOuG5g204umbFHtzaxpSAAAAAADUErd1DlJ0p0AVOwxN+nyn7I6afR0SHYlazO4w9P76Q7rt7fXafPicPF1tmnJHRy0e31utA7zNjgcAAAAAACrZq3d3lre7i3Ycy9ZHPx0xO84V0ZSqpfZm5GrE7J/0xopUXSxyqE/rRvp2Yj89clNL2awWs+MBAAAAAIAqEOjjoUlDf72f1PTv9urYL/kmJyobTalaprDYobdX79cdf/tBO9Kz5O3uomkjuuiTRyPVvJGX2fEAAAAAAEAVGxnRXL1C/ZRfaNeLS1NUU28nTlOqFtl5LEt3vfOjZqzepyK7oUEdArQqrr/u79VcFgtXRwEAAAAAUBdYrRb9aUQXudmsWrc3U1/uOGF2pMuiKVULXCyyK35FqobN2qA9Gbnyq+emv47sofdH91SQr4fZ8QAAAAAAQDVrHVBfE25pLUl69avd+iWv0OREl6Ip5eS2HD6nIW//oPfWH5LDkO7q1kSrnumnu7o14eooAAAAAADqsPH9W6ltYH2dzSvU68tTzY5zCZpSTup8QbFeWpqie9/bqMNn8hTo4645o3vqryN7qFF9d7PjAQAAAAAAk7m5WBU/oqssFunzbcf04/4zZkcqhaaUE0rYl6noGev18aajkqT7I0L03TP9NahjoMnJAAAAAABATRLeoqEeurGFJOn5Jcm6UGg3OdF/0JRyIln5hfqfT3dozIdbdDzrgkL8PDV/XKSmxXSVr6er2fEAAAAAAEAN9Mfodgr29VDauXzNXLPP7DglaEo5iZUpJzXorfX6fNsxWSzS2D6h+nZiP/Vp7W92NAAAAAAAUIN5e7jqtbs7S5Lm/HBYKcezTU70K5pSNVxmboF+Pz9R4z/ZpjPnC9SqcT19Nj5KU+/sJC83F7PjAQAAAAAAJzCoY6Bu7xIsu8PQpC92qtjuMDsSTamayjAMfbHtmG6dkaAVyRmyWS2acHNrLf9DX4W38DM7HgAAAAAAcDJT7+ooHw8XpRzP0dwNR8yOQ1OqJjqRdUFj521V3Kc7lJVfpI7BPloW20fPRreTh6vN7HgAAAAAAMAJBXh76IXbO0iS/m/VXqWdzTc1D02pGib9XL4Gz1ivdXsz5Waz6o/R7bRsQh91buprdjQAAAAAAODk7u0ZohvD/HSxyKEXlibLMAzTstCUqmGaNfRUVKtGCm/RUCue7qvYm1vL1cYyAQAAAACA62exWBQ/oqvqu7uoR0gD2R3mNaW4U3YNY7FY9Na93eTl5iKb1WJ2HAAAAAAAUMu09K+nDZNuka+nq6k5aErVQN4e5v6hAAAAAAAAtZvZDSmJt+8BAAAAAADABDSlAAAAAAAAUO1oSgEAAAAAAKDa0ZQCAAAAAABAtTO9KTVr1iyFhobKw8NDkZGR2rJlS5ljd+3apZiYGIWGhspisWjmzJnXdM6LFy8qNjZWjRo1Uv369RUTE6NTp05V5rQAAAAAAABwBaY2pRYtWqS4uDhNnTpV27ZtU7du3RQdHa3Tp09fdnx+fr7CwsI0bdo0BQUFXfM5n3nmGX311VdavHixEhISdOLECY0YMaJK5ggAAAAAAIBLWQzDMMx68sjISEVEROidd96RJDkcDoWEhOipp57SpEmTrnhsaGioJk6cqIkTJ1bonNnZ2WrcuLEWLFige+65R5K0Z88edejQQRs3btSNN95Yruw5OTny9fVVdna2fHx8KjhzAADgrKgByo+fFQAAdVN5awDTrpQqLCxUYmKiBg0a9J8wVqsGDRqkjRs3Vtk5ExMTVVRUVGpM+/bt1bx58ys+b0FBgXJyckptAAAAAAAAuDamNaXOnDkju92uwMDAUvsDAwOVkZFRZefMyMiQm5ubGjRoUKHnjY+Pl6+vb8kWEhJyTRkBAAAAAABQA2507iwmT56s7Ozski09Pd3sSAAAAAAAAE7Lxawn9vf3l81mu+RT706dOlXmTcwr45xBQUEqLCxUVlZWqaulrva87u7ucnd3v6ZcAAAAAAAAKM20K6Xc3NwUHh6uNWvWlOxzOBxas2aNoqKiquyc4eHhcnV1LTVm7969SktLu+bnBQAAAAAAQMWYdqWUJMXFxWnMmDHq2bOnevXqpZkzZyovL09jx46VJI0ePVpNmzZVfHy8pF9vZL579+6Sr48fP66kpCTVr19frVu3Ltc5fX199eijjyouLk5+fn7y8fHRU089paioqHJ/8h4AAAAAAACuj6lNqfvuu0+ZmZmaMmWKMjIy1L17d61cubLkRuVpaWmyWv9zMdeJEyfUo0ePksfTp0/X9OnT1b9/f61bt65c55SkGTNmyGq1KiYmRgUFBYqOjtbf//736pk0AAAAAAAAZDEMwzA7hDPKycmRr6+vsrOz5ePjY3YcAABQTagByo+fFQAAdVN5awA+fQ8AAAAAAADVjqYUAAAAAAAAqh1NKQAAAAAAAFQ7mlIAAAAAAACodqZ++p4z+/f94XNyckxOAgAAqtO//+3ns2KujnoJAIC6qbz1Ek2pa5SbmytJCgkJMTkJAAAwQ25urnx9fc2OUaNRLwEAULddrV6yGPw33zVxOBw6ceKEvL29ZbFYKvXcOTk5CgkJUXp6eq3++OS6Mk+p7syVedY+dWWuzLP2qcq5Goah3NxcNWnSRFYrd0K4EuqlylFX5so8a5e6Mk+p7syVedY+NaFe4kqpa2S1WtWsWbMqfQ4fH59a/yKQ6s48pbozV+ZZ+9SVuTLP2qeq5soVUuVDvVS56spcmWftUlfmKdWduTLP2sfMeon/3gMAAAAAAEC1oykFAAAAAACAakdTqgZyd3fX1KlT5e7ubnaUKlVX5inVnbkyz9qnrsyVedY+dWmudVVdWuO6MlfmWbvUlXlKdWeuzLP2qQlz5UbnAAAAAAAAqHZcKQUAAAAAAIBqR1MKAAAAAAAA1Y6mFAAAAAAAAKodTSmTzJo1S6GhofLw8FBkZKS2bNlyxfGLFy9W+/bt5eHhoS5dumjFihXVlPT6VGSe8+bNk8ViKbV5eHhUY9prs379et15551q0qSJLBaLli5detVj1q1bpxtuuEHu7u5q3bq15s2bV+U5K0NF57pu3bpL1tRisSgjI6N6Al+D+Ph4RUREyNvbWwEBARo2bJj27t171eOc8TV6LXN1xtfp7Nmz1bVrV/n4+MjHx0dRUVH65ptvrniMM65nRefpjGt5OdOmTZPFYtHEiROvOM4Z1xTUS5fjrK9d6qWyOWO9JNWdmol6qWzOtpYS9VJNrJdoSplg0aJFiouL09SpU7Vt2zZ169ZN0dHROn369GXH//TTTxo5cqQeffRRbd++XcOGDdOwYcOUkpJSzckrpqLzlCQfHx+dPHmyZDt69Gg1Jr42eXl56tatm2bNmlWu8YcPH9btt9+um2++WUlJSZo4caLGjRunb7/9toqTXr+KzvXf9u7dW2pdAwICqijh9UtISFBsbKw2bdqkVatWqaioSIMHD1ZeXl6Zxzjra/Ra5io53+u0WbNmmjZtmhITE/Xzzz/rlltu0d13361du3ZddryzrmdF5yk531r+1tatW/Xee++pa9euVxznrGta11EvUS9RL9XcekmqOzUT9RL1krOt5W/V+HrJQLXr1auXERsbW/LYbrcbTZo0MeLj4y87/t577zVuv/32UvsiIyONJ554okpzXq+KznPu3LmGr69vNaWrGpKMJUuWXHHM//7v/xqdOnUqte++++4zoqOjqzBZ5SvPXNeuXWtIMn755ZdqyVQVTp8+bUgyEhISyhzjrK/R3yrPXGvD69QwDKNhw4bGnDlzLvu92rKehnHleTr7Wubm5hpt2rQxVq1aZfTv3994+umnyxxbm9a0LqFeol6iXnIudaVmol76VW1Yy3+jXvqVWWvKlVLVrLCwUImJiRo0aFDJPqvVqkGDBmnjxo2XPWbjxo2lxktSdHR0meNrgmuZpySdP39eLVq0UEhIyFU71s7KGdfzenXv3l3BwcG69dZbtWHDBrPjVEh2drYkyc/Pr8wxtWVNyzNXyblfp3a7XQsXLlReXp6ioqIuO6Y2rGd55ik591rGxsbq9ttvv2StLqc2rGldQ71EveSM63m9nLlekupOzUS99KvasJbUS6WZtaY0parZmTNnZLfbFRgYWGp/YGBgme8bz8jIqND4muBa5tmuXTt9+OGHWrZsmT755BM5HA717t1bx44dq47I1aas9czJydGFCxdMSlU1goOD9e677+rzzz/X559/rpCQEA0YMEDbtm0zO1q5OBwOTZw4UX369FHnzp3LHOeMr9HfKu9cnfV1mpycrPr168vd3V3jx4/XkiVL1LFjx8uOdeb1rMg8nXUtJWnhwoXatm2b4uPjyzXemde0rqJeol6iXnKeekmqOzUT9dJ/OPNaUi9dnllr6lKlZwcqICoqqlSHunfv3urQoYPee+89vfbaayYmw7Vq166d2rVrV/K4d+/eOnjwoGbMmKGPP/7YxGTlExsbq5SUFP34449mR6ly5Z2rs75O27Vrp6SkJGVnZ+uzzz7TmDFjlJCQUGYB4qwqMk9nXcv09HQ9/fTTWrVqlVPeaBS4Xs762kXZnL1ekupOzUS9VDtQL9UsNKWqmb+/v2w2m06dOlVq/6lTpxQUFHTZY4KCgio0via4lnn+lqurq3r06KEDBw5URUTTlLWePj4+8vT0NClV9enVq5dTFCwTJkzQ119/rfXr16tZs2ZXHOuMr9H/VpG5/pazvE7d3NzUunVrSVJ4eLi2bt2qt99+W++9994lY515PSsyz99ylrVMTEzU6dOndcMNN5Tss9vtWr9+vd555x0VFBTIZrOVOsaZ17Suol6iXqJeco56Sao7NRP1UmnOvJbUSzWrXuLte9XMzc1N4eHhWrNmTck+h8OhNWvWlPk+1qioqFLjJWnVqlVXfN+r2a5lnr9lt9uVnJys4ODgqoppCmdcz8qUlJRUo9fUMAxNmDBBS5Ys0ffff6+WLVte9RhnXdNrmetvOevr1OFwqKCg4LLfc9b1vJwrzfO3nGUtBw4cqOTkZCUlJZVsPXv21KhRo5SUlHRJgSXVrjWtK6iXqJeccT0rU02vl6S6UzNRL1Ev/TdnWUunqpeq9DbquKyFCxca7u7uxrx584zdu3cbjz/+uNGgQQMjIyPDMAzDeOihh4xJkyaVjN+wYYPh4uJiTJ8+3UhNTTWmTp1quLq6GsnJyWZNoVwqOs9XXnnF+Pbbb42DBw8aiYmJxv333294eHgYu3btMmsK5ZKbm2ts377d2L59uyHJeOutt4zt27cbR48eNQzDMCZNmmQ89NBDJeMPHTpkeHl5GX/84x+N1NRUY9asWYbNZjNWrlxp1hTKraJznTFjhrF06VJj//79RnJysvH0008bVqvVWL16tVlTuKonn3zS8PX1NdatW2ecPHmyZMvPzy8ZU1teo9cyV2d8nU6aNMlISEgwDh8+bOzcudOYNGmSYbFYjO+++84wjNqznhWdpzOuZVl++2kytWVN6zrqJeol6qWaWy8ZRt2pmaiXqJecbS3LUlPrJZpSJvnb3/5mNG/e3HBzczN69eplbNq0qeR7/fv3N8aMGVNq/Keffmq0bdvWcHNzMzp16mQsX768mhNfm4rMc+LEiSVjAwMDjaFDhxrbtm0zIXXF/PtjfH+7/XtuY8aMMfr373/JMd27dzfc3NyMsLAwY+7cudWe+1pUdK5vvvmm0apVK8PDw8Pw8/MzBgwYYHz//ffmhC+ny81PUqk1qi2v0WuZqzO+Th955BGjRYsWhpubm9G4cWNj4MCBJYWHYdSe9azoPJ1xLcvy2yKrtqwpqJcMo/a8dqmXale9ZBh1p2aiXvpVbVhLw6Beqon1ksUwDKPyr78CAAAAAAAAysY9pQAAAAAAAFDtaEoBAAAAAACg2tGUAgAAAAAAQLWjKQUAAAAAAIBqR1MKAAAAAAAA1Y6mFAAAAAAAAKodTSkAAAAAAABUO5pSAAAAAAAAqHY0pQCgClksFi1dutTsGAAAADUW9RJQd9GUAlBrPfzww7JYLJdst912m9nRAAAAagTqJQBmcjE7AABUpdtuu01z584ttc/d3d2kNAAAADUP9RIAs3ClFIBazd3dXUFBQaW2hg0bSvr1UvHZs2dryJAh8vT0VFhYmD777LNSxycnJ+uWW26Rp6enGjVqpMcff1znz58vNebDDz9Up06d5O7uruDgYE2YMKHU98+cOaPhw4fLy8tLbdq00ZdfflnyvV9++UWjRo1S48aN5enpqTZt2lxSFAIAAFQl6iUAZqEpBaBOe+mllxQTE6MdO3Zo1KhRuv/++5WamipJysvLU3R0tBo2bKitW7dq8eLFWr16dakiavbs2YqNjdXjjz+u5ORkffnll2rdunWp53jllVd07733aufOnRo6dKhGjRqlc+fOlTz/7t279c033yg1NVWzZ8+Wv79/9f0AAAAAroJ6CUCVMQCglhozZoxhs9mMevXqldreeOMNwzAMQ5Ixfvz4UsdERkYaTz75pGEYhvGPf/zDaNiwoXH+/PmS7y9fvtywWq1GRkaGYRiG0aRJE+OFF14oM4Mk48UXXyx5fP78eUOS8c033xiGYRh33nmnMXbs2MqZMAAAQAVRLwEwE/eUAlCr3XzzzZo9e3apfX5+fiVfR0VFlfpeVFSUkpKSJEmpqanq1q2b6tWrV/L9Pn36yOFwaO/evbJYLDpx4oQGDhx4xQxdu3Yt+bpevXry8fHR6dOnJUlPPvmkYmJitG3bNg0ePFjDhg1T7969r2muAAAA14J6CYBZaEoBqNXq1at3yeXhlcXT07Nc41xdXUs9tlgscjgckqQhQ4bo6NGjWrFihVatWqWBAwcqNjZW06dPr/S8AAAAl0O9BMAs3FMKQJ22adOmSx536NBBktShQwft2LFDeXl5Jd/fsGGDrFar2rVrJ29vb4WGhmrNmjXXlaFx48YaM2aMPvnkE82cOVP/+Mc/rut8AAAAlYl6CUBV4UopALVaQUGBMjIySu1zcXEpuTnm4sWL1bNnT910002aP3++tmzZog8++ECSNGrUKE2dOlVjxozRyy+/rMzMTD311FN66KGHFBgYKEl6+eWXNX78eAUEBGjIkCHKzc3Vhg0b9NRTT5Ur35QpUxQeHq5OnTqpoKBAX3/9dUmRBwAAUB2olwCYhaYUgFpt5cqVCg4OLrWvXbt22rNnj6RfP+ll4cKF+v3vf6/g4GD961//UseOHSVJXl5e+vbbb/X0008rIiJCXl5eiomJ0VtvvVVyrjFjxujixYuaMWOGnn32Wfn7++uee+4pdz43NzdNnjxZR44ckaenp/r27auFCxdWwswBAADKh3oJgFkshmEYZocAADNYLBYtWbJEw4YNMzsKAABAjUS9BKAqcU8pAAAAAAAAVDuaUgAAAAAAAKh2vH0PAAAAAAAA1Y4rpQAAAAAAAFDtaEoBAAAAAACg2tGUAgAAAAAAQLWjKQUAAAAAAIBqR1MKAAAAAAAA1Y6mFAAAAAAAAKodTSkAAAAAAABUO5pSAAAAAAAAqHY0pQAAAAAAAFDt/h+nMkNfAAj3IgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation:\n",
        "# CNN Model:\n",
        "\n",
        "# The code defines a simple CNN model with one convolutional layer, one max-pooling layer, a fully connected (dense) layer, and an output layer.\n",
        "# We compile the model using the Adam optimizer and sparse categorical cross-entropy loss for classification.\n",
        "# Training:\n",
        "\n",
        "# The model is trained on synthetic random data (images of size\n",
        "# 28\n",
        "# Ã—\n",
        "# 28\n",
        "# 28Ã—28 with random pixel values).\n",
        "# The fit() method returns a history object that contains the training loss and accuracy for each epoch.\n",
        "# Plotting:\n",
        "\n",
        "# We use matplotlib to plot two subplots:\n",
        "# Left Plot: The training accuracy (history.history['accuracy']).\n",
        "# Right Plot: The training loss (history.history['loss']).\n",
        "# The tight_layout() function ensures the subplots are neatly arranged.\n",
        "# Sample Output:\n",
        "# The code will generate a plot with two graphs:\n",
        "\n",
        "# One showing the training accuracy over epochs.\n",
        "# Another showing the training loss over epochs.\n",
        "# This is a simple way to visualize the performance of a model during training.\n",
        "\n",
        "# Customization:\n",
        "# You can modify the plot to include validation accuracy and loss (if validation data is provided during training by adding validation_data=(X_val, y_val) in model.fit())."
      ],
      "metadata": {
        "id": "cxLK_j0EwIOc"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.12 Write a code to print the architecture of the ResNet50 model in Keras?"
      ],
      "metadata": {
        "id": "3TdwF7hLxPLq"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To print the architecture of the ResNet50 model in Keras, you can load the pre-trained ResNet50 model from Keras' applications module and then use the model.summary() method to display its architecture.\n",
        "\n",
        "# Hereâ€™s the code to print the architecture of ResNet50:\n",
        "\n",
        "# Code Example:"
      ],
      "metadata": {
        "id": "O-y9HKWSxfw5"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n_CjdfuDxuP5",
        "outputId": "e10246e0-b7ea-43e8-8f24-fce8c6257724"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"resnet50\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"resnet50\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_8             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ -                      â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1_pad (\u001b[38;5;33mZeroPadding2D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m230\u001b[0m, \u001b[38;5;34m230\u001b[0m, \u001b[38;5;34m3\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ input_layer_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1_conv (\u001b[38;5;33mConv2D\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚          \u001b[38;5;34m9,472\u001b[0m â”‚ conv1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1_bn                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚            \u001b[38;5;34m256\u001b[0m â”‚ conv1_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1_relu (\u001b[38;5;33mActivation\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ pool1_pad (\u001b[38;5;33mZeroPadding2D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m114\u001b[0m, \u001b[38;5;34m64\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv1_relu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ pool1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ pool1_pad[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚          \u001b[38;5;34m4,160\u001b[0m â”‚ pool1_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚            \u001b[38;5;34m256\u001b[0m â”‚ conv2_block1_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚         \u001b[38;5;34m36,928\u001b[0m â”‚ conv2_block1_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚            \u001b[38;5;34m256\u001b[0m â”‚ conv2_block1_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_0_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚         \u001b[38;5;34m16,640\u001b[0m â”‚ pool1_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚         \u001b[38;5;34m16,640\u001b[0m â”‚ conv2_block1_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_0_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv2_block1_0_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv2_block1_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_0_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv2_block1_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚         \u001b[38;5;34m16,448\u001b[0m â”‚ conv2_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚            \u001b[38;5;34m256\u001b[0m â”‚ conv2_block2_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2_block2_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚         \u001b[38;5;34m36,928\u001b[0m â”‚ conv2_block2_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚            \u001b[38;5;34m256\u001b[0m â”‚ conv2_block2_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2_block2_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚         \u001b[38;5;34m16,640\u001b[0m â”‚ conv2_block2_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv2_block2_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv2_block2_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2_block2_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚         \u001b[38;5;34m16,448\u001b[0m â”‚ conv2_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚            \u001b[38;5;34m256\u001b[0m â”‚ conv2_block3_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2_block3_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚         \u001b[38;5;34m36,928\u001b[0m â”‚ conv2_block3_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚            \u001b[38;5;34m256\u001b[0m â”‚ conv2_block3_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2_block3_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚         \u001b[38;5;34m16,640\u001b[0m â”‚ conv2_block3_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv2_block3_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv2_block3_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv2_block3_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚         \u001b[38;5;34m32,896\u001b[0m â”‚ conv2_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚            \u001b[38;5;34m512\u001b[0m â”‚ conv3_block1_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚        \u001b[38;5;34m147,584\u001b[0m â”‚ conv3_block1_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚            \u001b[38;5;34m512\u001b[0m â”‚ conv3_block1_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_0_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚        \u001b[38;5;34m131,584\u001b[0m â”‚ conv2_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚         \u001b[38;5;34m66,048\u001b[0m â”‚ conv3_block1_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_0_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚          \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block1_0_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚          \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block1_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_0_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv3_block1_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚         \u001b[38;5;34m65,664\u001b[0m â”‚ conv3_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚            \u001b[38;5;34m512\u001b[0m â”‚ conv3_block2_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block2_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚        \u001b[38;5;34m147,584\u001b[0m â”‚ conv3_block2_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚            \u001b[38;5;34m512\u001b[0m â”‚ conv3_block2_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block2_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚         \u001b[38;5;34m66,048\u001b[0m â”‚ conv3_block2_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚          \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block2_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv3_block2_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block2_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚         \u001b[38;5;34m65,664\u001b[0m â”‚ conv3_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚            \u001b[38;5;34m512\u001b[0m â”‚ conv3_block3_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block3_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚        \u001b[38;5;34m147,584\u001b[0m â”‚ conv3_block3_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚            \u001b[38;5;34m512\u001b[0m â”‚ conv3_block3_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block3_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚         \u001b[38;5;34m66,048\u001b[0m â”‚ conv3_block3_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚          \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block3_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv3_block3_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block3_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚         \u001b[38;5;34m65,664\u001b[0m â”‚ conv3_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚            \u001b[38;5;34m512\u001b[0m â”‚ conv3_block4_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block4_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚        \u001b[38;5;34m147,584\u001b[0m â”‚ conv3_block4_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚            \u001b[38;5;34m512\u001b[0m â”‚ conv3_block4_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block4_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚         \u001b[38;5;34m66,048\u001b[0m â”‚ conv3_block4_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚          \u001b[38;5;34m2,048\u001b[0m â”‚ conv3_block4_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv3_block4_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv3_block4_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m131,328\u001b[0m â”‚ conv3_block4_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block1_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block1_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block1_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_0_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚        \u001b[38;5;34m525,312\u001b[0m â”‚ conv3_block4_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚        \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block1_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_0_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚          \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block1_0_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚          \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block1_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_0_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv4_block1_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block2_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block2_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block2_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block2_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block2_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚        \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block2_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚          \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block2_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv4_block2_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block2_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block3_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block3_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block3_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block3_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block3_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚        \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block3_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚          \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block3_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv4_block3_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block3_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block4_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block4_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block4_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block4_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block4_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚        \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block4_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚          \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block4_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv4_block4_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block4_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block4_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block5_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block5_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block5_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block5_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block5_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚        \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block5_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚          \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block5_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block4_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv4_block5_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block5_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m262,400\u001b[0m â”‚ conv4_block5_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block6_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block6_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚        \u001b[38;5;34m590,080\u001b[0m â”‚ conv4_block6_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m1,024\u001b[0m â”‚ conv4_block6_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block6_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚        \u001b[38;5;34m263,168\u001b[0m â”‚ conv4_block6_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚          \u001b[38;5;34m4,096\u001b[0m â”‚ conv4_block6_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block5_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv4_block6_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m1024\u001b[0m)   â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv4_block6_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚        \u001b[38;5;34m524,800\u001b[0m â”‚ conv4_block6_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚          \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block1_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚      \u001b[38;5;34m2,359,808\u001b[0m â”‚ conv5_block1_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚          \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block1_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_0_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚      \u001b[38;5;34m2,099,200\u001b[0m â”‚ conv4_block6_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚      \u001b[38;5;34m1,050,624\u001b[0m â”‚ conv5_block1_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_0_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚          \u001b[38;5;34m8,192\u001b[0m â”‚ conv5_block1_0_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚          \u001b[38;5;34m8,192\u001b[0m â”‚ conv5_block1_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_0_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv5_block1_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚      \u001b[38;5;34m1,049,088\u001b[0m â”‚ conv5_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚          \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block2_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block2_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚      \u001b[38;5;34m2,359,808\u001b[0m â”‚ conv5_block2_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚          \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block2_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block2_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚      \u001b[38;5;34m1,050,624\u001b[0m â”‚ conv5_block2_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚          \u001b[38;5;34m8,192\u001b[0m â”‚ conv5_block2_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block1_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv5_block2_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block2_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_1_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚      \u001b[38;5;34m1,049,088\u001b[0m â”‚ conv5_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_1_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚          \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block3_1_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_1_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block3_1_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_2_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚      \u001b[38;5;34m2,359,808\u001b[0m â”‚ conv5_block3_1_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_2_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚          \u001b[38;5;34m2,048\u001b[0m â”‚ conv5_block3_2_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_2_relu       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block3_2_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_3_conv       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚      \u001b[38;5;34m1,050,624\u001b[0m â”‚ conv5_block3_2_relu[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mConv2D\u001b[0m)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_3_bn         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚          \u001b[38;5;34m8,192\u001b[0m â”‚ conv5_block3_3_conv[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_add (\u001b[38;5;33mAdd\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block2_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv5_block3_3_bn[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_out          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block3_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mActivation\u001b[0m)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ avg_pool                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           â”‚              \u001b[38;5;34m0\u001b[0m â”‚ conv5_block3_out[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ predictions (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           â”‚      \u001b[38;5;34m2,049,000\u001b[0m â”‚ avg_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)              </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">        Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to           </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_8             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1_pad (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">9,472</span> â”‚ conv1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1_bn                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1_relu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ pool1_pad (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">114</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ pool1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ pool1_pad[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚ pool1_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block1_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚ conv2_block1_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block1_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_0_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚ pool1_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚ conv2_block1_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_0_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2_block1_0_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2_block1_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_0_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv2_block1_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block1_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚ conv2_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block2_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block2_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚ conv2_block2_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block2_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block2_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚ conv2_block2_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2_block2_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv2_block2_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block2_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> â”‚ conv2_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block3_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block3_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚ conv2_block3_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv2_block3_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block3_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> â”‚ conv2_block3_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv2_block3_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv2_block3_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv2_block3_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv2_block3_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚ conv2_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block1_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ conv3_block1_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block1_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_0_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> â”‚ conv2_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚ conv3_block1_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_0_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block1_0_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block1_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_0_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv3_block1_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block1_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> â”‚ conv3_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block2_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block2_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ conv3_block2_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block2_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block2_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚ conv3_block2_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block2_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv3_block2_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block2_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> â”‚ conv3_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block3_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block3_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ conv3_block3_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block3_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block3_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚ conv3_block3_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block3_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv3_block3_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block3_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block3_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> â”‚ conv3_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block4_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block4_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> â”‚ conv3_block4_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv3_block4_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block4_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> â”‚ conv3_block4_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv3_block4_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv3_block4_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv3_block4_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv3_block4_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚ conv3_block4_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block1_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block1_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block1_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_0_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> â”‚ conv3_block4_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block1_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_0_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block1_0_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block1_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_0_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv4_block1_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block1_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block2_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block2_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block2_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block2_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block2_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block2_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block2_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv4_block2_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block2_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block3_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block3_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block3_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block3_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block3_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block3_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block3_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv4_block3_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block3_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block3_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block4_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block4_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block4_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block4_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block4_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block4_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block4_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv4_block4_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block4_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block4_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block4_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block5_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block5_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block5_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block5_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block5_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block5_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block5_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block4_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv4_block5_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block5_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block5_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> â”‚ conv4_block5_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block6_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block6_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> â”‚ conv4_block6_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv4_block6_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block6_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> â”‚ conv4_block6_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> â”‚ conv4_block6_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block5_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv4_block6_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv4_block6_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)   â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv4_block6_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> â”‚ conv4_block6_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block1_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> â”‚ conv5_block1_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block1_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_0_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> â”‚ conv4_block6_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> â”‚ conv5_block1_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_0_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ conv5_block1_0_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ conv5_block1_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_0_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv5_block1_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block1_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> â”‚ conv5_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block2_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block2_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> â”‚ conv5_block2_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block2_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block2_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> â”‚ conv5_block2_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ conv5_block2_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block1_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv5_block2_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block2_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_1_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> â”‚ conv5_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_1_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block3_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_1_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block3_1_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_2_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> â”‚ conv5_block3_1_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_2_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ conv5_block3_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_2_relu       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block3_2_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_3_conv       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> â”‚ conv5_block3_2_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_3_bn         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> â”‚ conv5_block3_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block2_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”‚                           â”‚                        â”‚                â”‚ conv5_block3_3_bn[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv5_block3_out          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block3_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ avg_pool                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           â”‚              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ conv5_block3_out[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  â”‚                        â”‚                â”‚                        â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,049,000</span> â”‚ avg_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,636,712\u001b[0m (97.80 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,636,712</span> (97.80 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,583,592\u001b[0m (97.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,583,592</span> (97.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,120\u001b[0m (207.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,120</span> (207.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation:\n",
        "# ResNet50 Model:\n",
        "\n",
        "# The ResNet50 model is a pre-trained deep residual network with 50 layers, trained on the ImageNet dataset. It's commonly used for image classification tasks.\n",
        "# By setting weights='imagenet', you're loading the model with pre-trained weights from ImageNet.\n",
        "# model.summary():\n",
        "\n",
        "# This method prints out a summary of the model, including the layers, output shapes, and the number of parameters at each layer.\n",
        "# Sample Output:\n",
        "# The output will be a summary of the ResNet50 architecture, which could look like this (note that the actual architecture may vary depending on the specific version of Keras or TensorFlow you are using):"
      ],
      "metadata": {
        "id": "jWYgWRowxxzp"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model: \"resnet50\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #\n",
        "=================================================================\n",
        "input_1 (InputLayer)         [(None, 224, 224, 3)]     0\n",
        "_________________________________________________________________\n",
        "conv1_pad (ZeroPadding2D)    (None, 230, 230, 3)       0\n",
        "_________________________________________________________________\n",
        "conv1_conv (Conv2D)          (None, 112, 112, 64)      9408\n",
        "_________________________________________________________________\n",
        "conv1_bn (BatchNormalization (None, 112, 112, 64)      256\n",
        "_________________________________________________________________\n",
        "conv1_relu (Activation)      (None, 112, 112, 64)      0\n",
        "...\n",
        "_________________________________________________________________\n",
        "fc1000 (Dense)               (None, 1000)              2048000\n",
        "=================================================================\n",
        "Total params: 25,636,712\n",
        "Trainable params: 25,603,784\n",
        "Non-trainable params: 32,928\n",
        "_________________________________________________________________"
      ],
      "metadata": {
        "id": "NSTzl40wyUHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q.13 Write a code to train a basic CNN model and print the training loss and accuracy after each epoch?"
      ],
      "metadata": {
        "id": "7jNt0OR4ywbs"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To train a basic CNN model and print the training loss and accuracy after each epoch, you can utilize the fit() method in Keras. This method provides a history object that contains the loss and accuracy for each epoch. Additionally, you can also monitor the training process in real-time using Keras callbacks or simply print the loss and accuracy values at the end of each epoch.\n",
        "\n",
        "# Hereâ€™s the code to train a basic CNN model and print the training loss and accuracy after each epoch:\n",
        "\n",
        "# Code Example:"
      ],
      "metadata": {
        "id": "LN4_RNZV0M00"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import numpy as np\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "X_train = np.random.random((1000, 28, 28, 1))\n",
        "y_train = np.random.randint(0, 10, 1000)\n",
        "\n",
        "class PrintMetricsCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print(f\"Epoch {epoch+1}: Loss = {logs['loss']:.4f}, Accuracy = {logs['accuracy']:.4f}\")\n",
        "\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=32, callbacks=[PrintMetricsCallback()])"
      ],
      "metadata": {
        "id": "XKzpjeYc17uQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explanation:\n",
        "# Model Definition:\n",
        "\n",
        "# The CNN model consists of one convolutional layer (32 filters,\n",
        "# 3\n",
        "# Ã—\n",
        "# 3\n",
        "# 3Ã—3 kernel), a max-pooling layer (\n",
        "# 2\n",
        "# Ã—\n",
        "# 2\n",
        "# 2Ã—2), a flatten layer, and two fully connected layers. The final layer uses softmax activation for multi-class classification (10 classes).\n",
        "# Compile the Model:\n",
        "\n",
        "# The model is compiled using the Adam optimizer and sparse categorical cross-entropy loss for multi-class classification. Accuracy is tracked as a metric.\n",
        "# Training Data:\n",
        "\n",
        "# We generate random data as a placeholder for real image data. The data is in the shape (1000, 28, 28, 1) representing 1000 grayscale images of size\n",
        "# 28\n",
        "# Ã—\n",
        "# 28\n",
        "# 28Ã—28 with random pixel values, and labels are random integers between 0 and 9.\n",
        "# Custom Callback (PrintMetricsCallback):\n",
        "\n",
        "# A custom callback PrintMetricsCallback is created by inheriting from tf.keras.callbacks.Callback. This callback overrides the on_epoch_end method, which is called at the end of each epoch. It prints the loss and accuracy values after every epoch.\n",
        "# Training the Model:\n",
        "\n",
        "# The model is trained using the model.fit() method. The custom callback is passed to the callbacks argument to print the loss and accuracy after each epoch.\n",
        "# Sample Output:\n",
        "# The output will print the loss and accuracy values after each epoch. For example:"
      ],
      "metadata": {
        "id": "fMECcnyq2ZWM"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Epoch 1: Loss = 2.3023, Accuracy = 0.1110\n",
        "Epoch 2: Loss = 2.3019, Accuracy = 0.1130\n",
        "Epoch 3: Loss = 2.3015, Accuracy = 0.1150\n",
        "Epoch 4: Loss = 2.3012, Accuracy = 0.1170\n",
        "Epoch 5: Loss = 2.3009, Accuracy = 0.1200"
      ],
      "metadata": {
        "id": "3Gkayunq5C4i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}